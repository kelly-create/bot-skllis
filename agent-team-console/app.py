#!/usr/bin/env python3
import json
import os
import re
import sqlite3
import subprocess
import threading
import time
import shutil
import signal
import urllib.error
import urllib.request
from contextlib import contextmanager
from datetime import datetime, timedelta
from functools import wraps

from flask import Flask, abort, flash, g, jsonify, redirect, render_template, request, send_from_directory, session, url_for
from werkzeug.utils import secure_filename

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.getenv("ATC_DB_PATH", os.path.join(BASE_DIR, "data", "tasks.db"))
ADMIN_USERNAME = os.getenv("ATC_ADMIN_USERNAME", "root")
ADMIN_PASSWORD = os.getenv("ATC_ADMIN_PASSWORD", "k5348988")
APP_SECRET = os.getenv("ATC_APP_SECRET", "change-me-now")
WORKDIR = os.getenv("ATC_WORKDIR", BASE_DIR)
DEFAULT_MAX_CONCURRENT = int(os.getenv("ATC_MAX_CONCURRENT", "4"))
ARTIFACT_ROOT = os.getenv("ATC_ARTIFACT_ROOT", os.path.join(BASE_DIR, "artifacts"))
ROLE_DEFAULT_API_BASE = os.getenv("ATC_ROLE_DEFAULT_API_BASE", "").strip()
ROLE_DEFAULT_API_KEY = os.getenv("ATC_ROLE_DEFAULT_API_KEY", "").strip()
ROLE_DEFAULT_TIMEOUT = int(os.getenv("ATC_ROLE_TIMEOUT_SECONDS", "180"))
ROLE_MAX_REWORK_ROUNDS = max(0, min(5, int(os.getenv("ATC_MAX_REWORK_ROUNDS", "5"))))
ROLE_STAGE_REVIEW_MAX_RETRIES = max(0, min(5, int(os.getenv("ATC_STAGE_REVIEW_MAX_RETRIES", "5"))))
ROLE_MAX_TOOL_ROUNDS = max(1, min(10, int(os.getenv("ATC_ROLE_MAX_TOOL_ROUNDS", "5"))))
ROLE_REASONING_EFFORT = (os.getenv("ATC_ROLE_REASONING_EFFORT", "high") or "high").strip()
ROLE_CROSS_REVIEW_ROUNDS = max(0, min(6, int(os.getenv("ATC_ROLE_CROSS_REVIEW_ROUNDS", "3"))))
ROLE_HISTORY_LIMIT = max(8, min(50, int(os.getenv("ATC_ROLE_HISTORY_LIMIT", "20"))))

os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
os.makedirs(ARTIFACT_ROOT, exist_ok=True)

app = Flask(__name__)
app.secret_key = APP_SECRET
app.config["MAX_CONTENT_LENGTH"] = 200 * 1024 * 1024  # 200MB

running_processes = {}
task_run_context = {}


class ConcurrencyLimiter:
    def __init__(self, limit: int):
        self._limit = max(1, int(limit))
        self._running = 0
        self._lock = threading.Lock()
        self._cond = threading.Condition(self._lock)

    @contextmanager
    def acquire(self):
        with self._cond:
            while self._running >= self._limit:
                self._cond.wait(timeout=1)
            self._running += 1
        try:
            yield
        finally:
            with self._cond:
                self._running -= 1
                self._cond.notify_all()

    def set_limit(self, limit: int):
        with self._cond:
            self._limit = max(1, int(limit))
            self._cond.notify_all()

    def get_limit(self) -> int:
        with self._lock:
            return self._limit

    def get_running(self) -> int:
        with self._lock:
            return self._running


limiter = ConcurrencyLimiter(DEFAULT_MAX_CONCURRENT)


def now_str():
    return datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")


def to_beijing_time(ts_text: str) -> str:
    raw = (ts_text or "").strip()
    if not raw:
        return "-"
    try:
        if raw.endswith(" UTC"):
            dt = datetime.strptime(raw, "%Y-%m-%d %H:%M:%S UTC")
        else:
            dt = datetime.strptime(raw, "%Y-%m-%d %H:%M:%S")
        dt_bj = dt + timedelta(hours=8)
        return dt_bj.strftime("%Y-%m-%d %H:%M:%S Âåó‰∫¨Êó∂Èó¥")
    except Exception:
        return raw


def epoch_to_beijing(ts_epoch: float) -> str:
    try:
        dt_bj = datetime.utcfromtimestamp(ts_epoch) + timedelta(hours=8)
        return dt_bj.strftime("%Y-%m-%d %H:%M:%S Âåó‰∫¨Êó∂Èó¥")
    except Exception:
        return "-"


app.jinja_env.filters["bjt"] = to_beijing_time


def format_size(num_bytes: int) -> str:
    size = float(num_bytes)
    for unit in ["B", "KB", "MB", "GB", "TB"]:
        if size < 1024 or unit == "TB":
            return f"{size:.1f}{unit}" if unit != "B" else f"{int(size)}B"
        size /= 1024


def list_artifacts(max_items: int = 300):
    out = []
    for root, _, files in os.walk(ARTIFACT_ROOT):
        for name in files:
            full = os.path.join(root, name)
            rel = os.path.relpath(full, ARTIFACT_ROOT)
            try:
                st = os.stat(full)
            except FileNotFoundError:
                continue
            out.append(
                {
                    "name": name,
                    "rel_path": rel,
                    "size": st.st_size,
                    "size_human": format_size(st.st_size),
                    "mtime": epoch_to_beijing(st.st_mtime),
                    "ts": st.st_mtime,
                }
            )
    out.sort(key=lambda x: x["ts"], reverse=True)
    return out[:max_items]


def task_artifact_dirs(task_id: int):
    base = os.path.join(ARTIFACT_ROOT, f"task_{task_id}")
    in_dir = os.path.join(base, "input")
    out_dir = os.path.join(base, "output")
    os.makedirs(in_dir, exist_ok=True)
    os.makedirs(out_dir, exist_ok=True)
    return base, in_dir, out_dir


def build_task_run_id(task_id: int) -> str:
    return f"run-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}-{task_id}-{int(time.time()*1000)%100000}"


def clear_dir_contents(path: str) -> int:
    if not os.path.isdir(path):
        return 0
    removed = 0
    for name in os.listdir(path):
        p = os.path.join(path, name)
        try:
            if os.path.isfile(p) or os.path.islink(p):
                os.remove(p)
            else:
                shutil.rmtree(p, ignore_errors=True)
            removed += 1
        except Exception:
            continue
    return removed


def clear_role_session_messages(task_id: int) -> int:
    with db_conn() as conn:
        cur = conn.execute("DELETE FROM role_session_messages WHERE task_id=?", (task_id,))
        return int(cur.rowcount or 0)


def list_task_files(task_id: int, kind: str):
    base, in_dir, out_dir = task_artifact_dirs(task_id)
    target = in_dir if kind == "input" else out_dir
    out = []
    if not os.path.isdir(target):
        return out
    for name in os.listdir(target):
        full = os.path.join(target, name)
        if not os.path.isfile(full):
            continue
        st = os.stat(full)
        rel = os.path.relpath(full, base)
        out.append(
            {
                "name": name,
                "rel_path": rel,
                "size_human": format_size(st.st_size),
                "mtime": epoch_to_beijing(st.st_mtime),
                "ts": st.st_mtime,
            }
        )
    out.sort(key=lambda x: x["ts"], reverse=True)
    return out


def infer_business_phase(task) -> str:
    status = (task["status"] or "").strip().lower()
    if status in ("pending", "failed"):
        return "ÂæÖÂ§ÑÁêÜ"
    if status == "running":
        return "ÊâßË°å‰∏≠"
    if status == "done":
        return "ÂæÖÁ°ÆËÆ§"
    return "ÂÖ∂‰ªñ"


def classify_output_files(output_files):
    packs, reports, audits, others = [], [], [], []
    for f in output_files:
        name = (f.get("name") or "").lower()
        is_pack = name.endswith(".zip") or name.endswith(".7z") or name.endswith(".tar.gz") or name.endswith(".tgz")
        is_audit = ("audit" in name) or ("ÂÆ°ËÆ°" in name) or name.endswith(".log")
        is_report = name.endswith(".md") or name.endswith(".json") or name.endswith(".txt") or name.endswith(".csv") or name.endswith(".pdf")

        if is_pack:
            packs.append(f)
        elif is_audit:
            audits.append(f)
        elif is_report:
            reports.append(f)
        else:
            others.append(f)
    return {"packs": packs, "reports": reports, "audits": audits, "others": others}


def _latest_run_id_from_logs(logs):
    for row in reversed(logs):
        line = (row["line"] or "")
        m = re.search(r"\[run:([^\]]+)\]", line)
        if m:
            return m.group(1)
    return ""


def _strip_log_meta(line: str) -> str:
    s = (line or "").strip()
    # ‰ªÖÂâ•Á¶ªÂâçÁºÄÂÖÉ‰ø°ÊÅØÔºàÊó∂Èó¥/run/ËßíËâ≤ÔºâÔºå‰øùÁïôÊ≠£Êñá
    for _ in range(4):
        ns = re.sub(r"^\[[^\]]+\]\s*", "", s)
        if ns == s:
            break
        s = ns
    return s.strip()


def _short_line(line: str, max_len: int = 220) -> str:
    s = _strip_log_meta(line)
    if "Â∑•ÂÖ∑ÊâßË°å round=" in s:
        m = re.search(r"(Â∑•ÂÖ∑ÊâßË°å\s+round=\d+/\d+\s+rc=\d+\s+timedOut=(?:True|False))", s)
        if m:
            s = m.group(1)
    if len(s) > max_len:
        s = s[: max_len - 1] + "‚Ä¶"
    return s


def extract_failure_diagnosis(logs):
    reason = ""
    evidences = []
    latest_run_id = _latest_run_id_from_logs(logs)

    scoped_logs = logs
    if latest_run_id:
        scoped = [r for r in logs if f"[run:{latest_run_id}]" in (r["line"] or "")]
        if scoped:
            scoped_logs = scoped

    for row in reversed(scoped_logs):
        line = (row["line"] or "").strip()
        if not line:
            continue
        if ("Â§öAgentÊµÅÁ®ãÂ§±Ë¥•Ôºö" in line) or ("‰ªªÂä°Â§±Ë¥•Ôºö" in line) or ("ÊâßË°åÂºÇÂ∏∏Ôºö" in line):
            reason = line
            break

    if not reason:
        for row in reversed(scoped_logs):
            line = (row["line"] or "").strip()
            if any(k in line for k in ["FAIL", "Â§±Ë¥•", "ÂºÇÂ∏∏", "ÊâìÂõû"]):
                reason = line
                break

    for row in reversed(scoped_logs):
        line = (row["line"] or "").strip()
        if any(
            k in line
            for k in [
                "Â§öAgentÊµÅÁ®ãÂ§±Ë¥•",
                "Èò∂ÊÆµË¥®ÊéßÁªìËÆ∫ÔºöFAIL",
                "Â§çÊ†∏ÁªìËÆ∫ÔºöFAIL",
                "ÊâìÂõûÂΩìÂâçÈò∂ÊÆµÈáçÂÅö",
                "Â∑•ÂÖ∑ÊâßË°å round=",
                "Ê®°ÂûãËØ∑Ê±ÇÂ§±Ë¥•",
                "Êú™ÈÖçÁΩÆ api",
            ]
        ):
            evidences.append(_short_line(line))
        if len(evidences) >= 4:
            break

    # ÂéªÈáç‰ΩÜ‰øùÂ∫è
    seen = set()
    dedup_evidences = []
    for e in evidences:
        if e in seen:
            continue
        seen.add(e)
        dedup_evidences.append(e)
    evidences = dedup_evidences

    reason_plain = _strip_log_meta(reason)
    friendly_reason = reason_plain

    m_retry = re.search(r"Èò∂ÊÆµ\s+(.+?)\s+Ë¥®ÊéßÊú™ÈÄöËøáÔºå‰∏îÂ∑≤ËææÊú¨Èò∂ÊÆµÊúÄÂ§ßÈáçËØï\s*(\d+)", reason_plain)
    m_rework = re.search(r"ÊúÄÂ§ßËøîÂ∑•ËΩÆÊ¨°\s*(\d+)", reason_plain)
    m_http = re.search(r"HTTP\s*(\d{3})", reason_plain)

    if m_retry:
        stage, n = m_retry.group(1), m_retry.group(2)
        friendly_reason = f"{stage}Èò∂ÊÆµËøûÁª≠Ë¥®Êéß‰∏çÈÄöËøáÔºåÂ∑≤ËææÂà∞ÊúÄÂ§ßÈáçËØï {n} Ê¨°Ôºå‰ªªÂä°ÁªàÊ≠¢„ÄÇ"
    elif m_rework:
        friendly_reason = f"Â§çÊ†∏/ËøîÂ∑•ËææÂà∞‰∏äÈôêÔºà{m_rework.group(1)} ËΩÆÔºâÔºå‰ªªÂä°ÁªàÊ≠¢„ÄÇ"
    elif "Êú™ÈÖçÁΩÆ api_base" in reason_plain or "Êú™ÈÖçÁΩÆ api_key" in reason_plain:
        friendly_reason = "ËßíËâ≤ÈÖçÁΩÆ‰∏çÂÆåÊï¥ÔºàÁº∫Â∞ë API Base Êàñ API KeyÔºâÔºå‰ªªÂä°Êó†Ê≥ïÁªßÁª≠„ÄÇ"
    elif m_http and "Ê®°ÂûãËØ∑Ê±ÇÂ§±Ë¥•" in reason_plain:
        friendly_reason = f"Ê®°ÂûãË∞ÉÁî®Â§±Ë¥•ÔºàHTTP {m_http.group(1)}ÔºâÔºåÊµÅÁ®ã‰∏≠Êñ≠„ÄÇ"
    elif "Ë¥®ÊéßÊú™ÈÄöËøá" in reason_plain:
        friendly_reason = "Èò∂ÊÆµË¥®Êéß‰∏çÈÄöËøáÔºåÂΩìÂâç‰∫ßÁâ©Êú™ËææÂà∞È™åÊî∂Ê†áÂáÜ„ÄÇ"

    suggestion = "ËØ∑Ê†πÊçÆÂ§±Ë¥•ÂéüÂõ†‰øÆÊ≠£ÂêéÈáçÁΩÆ‰ªªÂä°ÔºõËã•‰∏çÁ°ÆÂÆöÔºåÂèØÊää‚ÄúÂ§±Ë¥•ÂéüÂõ†+ÊúÄËøë3Êù°ËØÅÊçÆ‚ÄùÂèëÁªôÊàëÔºåÊàë‰ºöÁªôÂá∫ÂÖ∑‰Ωì‰øÆÂ§çÊ≠•È™§„ÄÇ"
    combo = reason_plain + "\n" + "\n".join(evidences)
    if "Êú™ÈÖçÁΩÆ api_base" in combo or "Êú™ÈÖçÁΩÆ api_key" in combo:
        suggestion = "ÂÖàÂà∞ËßíËâ≤‰∏≠ÂøÉË°•ÈΩêËØ•ËßíËâ≤ÁöÑ API Base / API Key / Ê®°ÂûãÔºåÂÜçÈáçÁΩÆ‰ªªÂä°„ÄÇ"
    elif "Ë¥®ÊéßÊú™ÈÄöËøá" in combo and "ÊúÄÂ§ßÈáçËØï" in combo:
        suggestion = "ËøôÊòØ‚ÄúÈò∂ÊÆµË¥®Êéß‰∏çÈÄöËøá + ÈáçËØïËÄóÂ∞Ω‚Äù„ÄÇÂÖàÊòéÁ°ÆËØ•Èò∂ÊÆµÁöÑÂøÖ‰∫§‰ªòÊñá‰ª∂Ôºà‰æãÂ¶ÇÁªüËÆ°JSON/ÊúÄÁªàÊä•ÂëäÔºâÔºåË¶ÅÊ±ÇËßíËâ≤‰∏ÄÊ¨°ÊÄß‰∫ßÂá∫Âπ∂ÈôÑÂÖ≥ÈîÆÊï∞Â≠óÔºåÂÜçÈáçÁΩÆ‰ªªÂä°„ÄÇ"
    elif "Ë¥®ÊéßÊú™ÈÄöËøá" in combo:
        suggestion = "ÂΩìÂâçÈò∂ÊÆµ‰∫ßÂá∫‰∏çÊª°Ë∂≥È™åÊî∂Ê†áÂáÜ„ÄÇËØ∑ÊåâË¥®ÊéßÂéüÂõ†Ë°•ÈΩê‚ÄúÂèØÈ™åÊî∂ÁªìÊûú‚ÄùÔºà‰æãÂ¶ÇÂÆûÈôÖÊï∞ÊçÆ/Êñá‰ª∂/ÁªìËÆ∫ÔºâÔºåÂÜçÈáçÁΩÆ‰ªªÂä°„ÄÇ"
    elif "ÊúÄÂ§ßÈáçËØï" in combo or "ÊúÄÂ§ßËøîÂ∑•ËΩÆÊ¨°" in combo:
        suggestion = "Â∑≤Ëß¶ÂèëÈáçËØï‰∏äÈôê„ÄÇÂª∫ËÆÆÂÖà‰ºòÂåñÂΩìÂâçÈò∂ÊÆµÊèêÁ§∫ËØçÊàñÊîæÂÆΩÈ™åÊî∂Êù°‰ª∂ÔºåÂÜçÈáçÁΩÆ‰ªªÂä°ÔºõÂøÖË¶ÅÊó∂ÊèêÈ´òÈáçËØï‰∏äÈôê„ÄÇ"
    elif "HTTP" in combo or "Ê®°ÂûãËØ∑Ê±ÇÂ§±Ë¥•" in combo:
        suggestion = "Ê®°Âûã/APIË∞ÉÁî®Â§±Ë¥•„ÄÇËØ∑Ê£ÄÊü•ËßíËâ≤ API ÂèØÁî®ÊÄß„ÄÅÂØÜÈí•ÊúâÊïàÊÄß„ÄÅÊ®°ÂûãÂêçÊòØÂê¶Ê≠£Á°ÆÔºõÁΩëÁªúÊ≥¢Âä®Êó∂ÂèØÁõ¥Êé•ÈáçËØï„ÄÇ"

    return {
        "run_id": latest_run_id,
        "reason": friendly_reason or "Êú™ÂÆö‰ΩçÂà∞ÊòéÁ°ÆÂ§±Ë¥•‰∏ªÂõ†ÔºàËØ∑Êü•ÁúãÊó•ÂøóÔºâ",
        "evidences": evidences,
        "suggestion": suggestion,
    }


def build_delivery_overview(task, output_files, logs):
    status = (task["status"] or "").strip().lower()
    rc = task["return_code"]
    if status == "done" and (rc in (0, "0", None) or rc == 0):
        headline = "‚úÖ ‰ªªÂä°Â∑≤ÂÆåÊàêÔºåÂèØÁõ¥Êé•Êü•ÁúãÂπ∂‰∏ãËΩΩ‰∫§‰ªòÁâ©"
        next_action = "‰ºòÂÖà‰∏ãËΩΩ‚Äú‰∫§‰ªòÂéãÁº©ÂåÖ‚ÄùÔºåÁ°ÆËÆ§ÁªìÊûúÂêéÂèØÂΩíÊ°£‰ªªÂä°„ÄÇ"
        progress = 100
    elif status == "running":
        headline = "‚è≥ ‰ªªÂä°ÊâßË°å‰∏≠ÔºåÊ≠£Âú®ÊåÅÁª≠‰∫ßÂá∫"
        next_action = "ÂèØÂÖàÊü•ÁúãÂÆûÊó∂Êó•ÂøóÔºåÁ≠âÂæÖËøõÂÖ•‚ÄúÂæÖ‰Ω†Á°ÆËÆ§‚Äù„ÄÇ"
        progress = 60
    elif status == "failed":
        headline = "‚ùå ‰ªªÂä°ÊâßË°åÂ§±Ë¥•ÔºåÈúÄË¶ÅËøîÂ∑•"
        next_action = "Êü•Áúã‚ÄúÂ§±Ë¥•ËØäÊñ≠‚ÄùÂêéÊåâÂª∫ËÆÆÂ§ÑÁêÜÔºåÂÜçÈáçÁΩÆ‰ªªÂä°„ÄÇ"
        progress = 100
    else:
        headline = "üìù ‰ªªÂä°ÂæÖÊâßË°å"
        next_action = "Á°ÆËÆ§‰ªªÂä°ÊèèËø∞‰∏éÈôÑ‰ª∂ÂêéÔºåÁÇπÂáª‚ÄúÂêØÂä®‚Äù„ÄÇ"
        progress = 12

    latest_line = ""
    for row in reversed(logs):
        line = (row["line"] or "").strip()
        if not line:
            continue
        latest_line = line
        if not line.startswith("[SYSTEM]"):
            break

    groups = classify_output_files(output_files)
    primary_pack = groups["packs"][0] if groups["packs"] else None

    failure = extract_failure_diagnosis(logs) if status == "failed" else None

    return {
        "headline": headline,
        "next_action": next_action,
        "progress": progress,
        "latest_line": latest_line,
        "groups": groups,
        "primary_pack": primary_pack,
        "failure": failure,
    }


def load_multiagent_summary(output_dir: str):
    audit_path = os.path.join(output_dir, "Â§öAgent_‰ºöËØùÂÆ°ËÆ°.json")
    if not os.path.isfile(audit_path):
        return None

    try:
        data = json.load(open(audit_path, "r", encoding="utf-8"))
    except Exception:
        return None

    dynamic = data.get("dynamicAssignments") or {}
    dispatch_items = [{"stage": k, "role": v} for k, v in dynamic.items()]

    review_pass = 0
    review_fail = 0
    quality_fail = 0
    called_roles = []
    role_seen = set()
    stage_tracks = []

    intake_role = "-"
    intake_model = "-"

    for s in data.get("stages") or []:
        role = s.get("role") or "-"
        if role not in role_seen:
            role_seen.add(role)
            called_roles.append(role)

        rd_obj = s.get("reviewDecision") or {}
        rd = rd_obj.get("decision", "")
        if rd == "PASS":
            review_pass += 1
        elif rd == "FAIL":
            review_fail += 1

        q_obj = (s.get("qualityGate") or {}).get("decision") or {}
        qd = q_obj.get("decision", "")
        if qd == "FAIL":
            quality_fail += 1

        if rd:
            track_status = f"Â§çÊ†∏{rd}"
            reason = rd_obj.get("reason", "")
            if rd == "FAIL" and rd_obj.get("send_back_role"):
                reason = f"ÊâìÂõû {rd_obj.get('send_back_role')}ÔΩú{reason}"
        elif qd:
            track_status = f"Ë¥®Êéß{qd}"
            reason = q_obj.get("reason", "")
        else:
            track_status = "ÂÆåÊàê"
            reason = ""

        stage_name = s.get("stage") or "-"
        model_name = s.get("model") or "-"
        if intake_role == "-" and any(k in stage_name for k in ["ÈúÄÊ±ÇÊé•Êî∂", "ÂàÜÂèë", "ÈúÄÊ±ÇÂàÜÊûê", "ÈúÄÊ±ÇÁêÜËß£"]):
            intake_role = role
            intake_model = model_name

        stage_tracks.append(
            {
                "executionNo": s.get("executionNo") or "-",
                "stage": stage_name,
                "role": role,
                "model": model_name,
                "reworkRound": s.get("reworkRound") or 0,
                "duration_sec": s.get("durationSec"),
                "status": track_status,
                "reason": (reason or "")[:180],
            }
        )

    if intake_role == "-" and stage_tracks:
        intake_role = stage_tracks[0].get("role") or "-"
        intake_model = stage_tracks[0].get("model") or "-"

    return {
        "workflow": data.get("workflow") or "-",
        "steps": len(data.get("stages") or []),
        "rework_used": data.get("reworkRoundsUsed") or 0,
        "rework_max": data.get("maxReworkRounds") or 0,
        "dispatch_items": dispatch_items,
        "review_pass": review_pass,
        "review_fail": review_fail,
        "quality_fail": quality_fail,
        "called_roles": called_roles,
        "stage_tracks": stage_tracks,
        "intake_role": intake_role,
        "intake_model": intake_model,
    }


def safe_join_under(root: str, rel_path: str):
    safe_full = os.path.realpath(os.path.join(root, rel_path))
    root_real = os.path.realpath(root)
    if not safe_full.startswith(root_real + os.sep) and safe_full != root_real:
        return None
    return safe_full


@contextmanager
def db_conn():
    conn = sqlite3.connect(DB_PATH, timeout=30)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
        conn.commit()
    finally:
        conn.close()


def ensure_column(conn, table: str, column: str, decl: str):
    cols = [r[1] for r in conn.execute(f"PRAGMA table_info({table})").fetchall()]
    if column not in cols:
        conn.execute(f"ALTER TABLE {table} ADD COLUMN {column} {decl}")


def init_db():
    with db_conn() as conn:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                description TEXT,
                task_type TEXT,
                assignee TEXT,
                priority TEXT DEFAULT 'P2',
                status TEXT DEFAULT 'pending',
                command TEXT,
                created_at TEXT,
                updated_at TEXT,
                started_at TEXT,
                finished_at TEXT,
                return_code INTEGER
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS task_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_id INTEGER NOT NULL,
                ts TEXT,
                line TEXT,
                FOREIGN KEY(task_id) REFERENCES tasks(id)
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS app_settings (
                key TEXT PRIMARY KEY,
                value TEXT,
                updated_at TEXT
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS roles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code TEXT UNIQUE NOT NULL,
                name TEXT NOT NULL,
                description TEXT,
                default_model TEXT,
                enabled INTEGER DEFAULT 1,
                created_at TEXT,
                updated_at TEXT
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS workflows (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code TEXT UNIQUE NOT NULL,
                name TEXT NOT NULL,
                description TEXT,
                stages_json TEXT,
                default_task_type TEXT,
                default_assignee TEXT,
                command_template TEXT,
                enabled INTEGER DEFAULT 1,
                created_at TEXT,
                updated_at TEXT
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS role_session_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_id INTEGER NOT NULL,
                role_code TEXT NOT NULL,
                stage TEXT,
                turn TEXT NOT NULL,
                content TEXT,
                created_at TEXT
            )
            """
        )

        # ÂéÜÂè≤Â∫ìÂÖºÂÆπÔºöÊåâÈúÄË°•Â≠óÊÆµ
        ensure_column(conn, "tasks", "workflow_code", "TEXT")
        ensure_column(conn, "roles", "api_base", "TEXT")
        ensure_column(conn, "roles", "api_key", "TEXT")
        ensure_column(conn, "roles", "system_prompt", "TEXT")
        ensure_column(conn, "roles", "temperature", "REAL DEFAULT 0.3")
        ensure_column(conn, "roles", "max_tokens", "INTEGER DEFAULT 1200")
        ensure_column(conn, "workflows", "stage_roles_json", "TEXT")

        # ÈªòËÆ§ÂÖ®Â±ÄËßíËâ≤ÔºàÂàõÂª∫‰∏ÄÊ¨°ÔºåÂêéÁª≠ÂèØÂú®È°µÈù¢Áª¥Êä§Ôºâ
        default_roles = [
            ("Lead Agent", "Lead Agent", "‰ªªÂä°ÊÄªÊéß‰∏éÁºñÊéí", "gpt-5.3-codex"),
            ("frontend", "ÂâçÁ´Ø Agent", "ÂâçÁ´ØÈ°µÈù¢„ÄÅ‰∫§‰∫í„ÄÅÂèØËßÜÂåñ‰∏é‰ΩìÈ™å‰ºòÂåñ", "MiniMax-M2.5"),
            ("backend", "ÂêéÁ´Ø Agent", "ÂêéÁ´Ø‰∏öÂä°„ÄÅÊï∞ÊçÆÊµÅ„ÄÅÊé•Âè£‰∏éËá™Âä®ÂåñÊâßË°å", "gpt-5.3-codex"),
            ("reviewer", "Â§çÊ†∏ Agent", "ÊåâÈ™åÊî∂Ê†áÂáÜÂ§çÊ†∏Âπ∂ÁªôÂá∫ÊâìÂõûÊÑèËßÅ", "gpt-5.3-codex"),
        ]
        for code, name, desc, model in default_roles:
            conn.execute(
                """
                INSERT OR IGNORE INTO roles(code, name, description, default_model, enabled, created_at, updated_at)
                VALUES(?,?,?,?,1,?,?)
                """,
                (code, name, desc, model, now_str(), now_str()),
            )

        # ÈªòËÆ§ËßíËâ≤ËØçÔºàsystem promptÔºâ
        role_prompts = {
            "Lead Agent": "‰Ω†ÊòØÊÄªÊéßËßíËâ≤„ÄÇË¥üË¥£ËØÑ‰º∞ÈúÄÊ±Ç„ÄÅÂà∂ÂÆöÊâßË°åËÆ°Âàí„ÄÅË∞ÉÂ∫¶ÂâçÂêéÁ´ØËßíËâ≤„ÄÅÊ±áÊÄªÊúÄÁªà‰∫§‰ªò„ÄÇÈÅáÂà∞ÈòªÂ°ûÊó∂Ë¶ÅÂÖàËØäÊñ≠ÂÜçË∞ÉÊï¥Á≠ñÁï•„ÄÇ",
            "frontend": "‰Ω†ÊòØÂâçÁ´ØËßíËâ≤„ÄÇË¥üË¥£È°µÈù¢ÁªìÊûÑ„ÄÅ‰∫§‰∫íÊµÅÁ®ã„ÄÅÂèØËßÜÂåñ‰∏éÂèØËØªÊÄß‰ºòÂåñÔºåÊåâÈ™åÊî∂Ê†áÂáÜ‰∫§‰ªòÂâçÁ´ØÁªìÊûú„ÄÇ",
            "backend": "‰Ω†ÊòØÂêéÁ´ØËßíËâ≤„ÄÇË¥üË¥£ÂêéÁ´Ø‰∏öÂä°„ÄÅÊï∞ÊçÆ/Êé•Âè£/ËÑöÊú¨ÊâßË°å‰∏éÊïÖÈöúÊéíÊü•„ÄÇÈÅáÂà∞ÂèçÁà¨ÊàñÂ§±Ë¥•Êó∂ÂøÖÈ°ªÂÖàËØäÊñ≠ÂéüÂõ†ÔºåÂÜçÂàáÊç¢Á≠ñÁï•„ÄÇ",
            "reviewer": "‰Ω†ÊòØÂ§çÊ†∏ËßíËâ≤„ÄÇÂè™ÂÅöÈ™åÊî∂Â§çÊ†∏Ôºå‰∏çÊõø‰ª£ÂÆûÁé∞„ÄÇËã•‰∏çÈÄöËøáÂøÖÈ°ªÁªôÂá∫ÂèØÊâßË°åÁöÑÊâìÂõûÊÑèËßÅ„ÄÇ",
        }
        for role_code, prompt in role_prompts.items():
            conn.execute(
                """
                UPDATE roles
                SET system_prompt = CASE WHEN system_prompt IS NULL OR system_prompt='' THEN ? ELSE system_prompt END,
                    updated_at=?
                WHERE code=?
                """,
                (prompt, now_str(), role_code),
            )

        # ËßíËâ≤ÈªòËÆ§Ê®°ÂûãÔºàÂÖÅËÆ∏Âú®ËßíËâ≤‰∏≠ÂøÉÊâãÂä®Ë¶ÜÁõñÔºâ
        conn.execute(
            """
            UPDATE roles
            SET default_model = CASE WHEN default_model IS NULL OR default_model='' THEN 'gpt-5.3-codex' ELSE default_model END,
                updated_at=?
            WHERE code='Lead Agent'
            """,
            (now_str(),),
        )
        conn.execute(
            """
            UPDATE roles
            SET default_model = CASE WHEN default_model IS NULL OR default_model='' THEN 'MiniMax-M2.5' ELSE default_model END,
                updated_at=?
            WHERE code='frontend'
            """,
            (now_str(),),
        )
        conn.execute(
            """
            UPDATE roles
            SET default_model = CASE WHEN default_model IS NULL OR default_model='' THEN 'gpt-5.3-codex' ELSE default_model END,
                updated_at=?
            WHERE code='backend'
            """,
            (now_str(),),
        )
        conn.execute(
            """
            UPDATE roles
            SET default_model = CASE WHEN default_model IS NULL OR default_model='' THEN 'gpt-5.3-codex' ELSE default_model END,
                updated_at=?
            WHERE code='reviewer'
            """,
            (now_str(),),
        )

        # ÁªôÊú™ÈÖçÁΩÆËßíËâ≤Ê≥®ÂÖ•ÁéØÂ¢ÉÁ∫ßÈªòËÆ§ APIÔºàÂèØ‰∏∫Á©∫Ôºå‰∏çÂº∫Âà∂Ôºâ
        if ROLE_DEFAULT_API_BASE:
            conn.execute(
                """
                UPDATE roles
                SET api_base = CASE WHEN api_base IS NULL OR api_base='' THEN ? ELSE api_base END,
                    updated_at=?
                """,
                (ROLE_DEFAULT_API_BASE, now_str()),
            )
        if ROLE_DEFAULT_API_KEY:
            conn.execute(
                """
                UPDATE roles
                SET api_key = CASE WHEN api_key IS NULL OR api_key='' THEN ? ELSE api_key END,
                    updated_at=?
                """,
                (ROLE_DEFAULT_API_KEY, now_str()),
            )

        # ÈªòËÆ§Â∑•‰ΩúÊµÅÔºàÂΩìÂâç‰ªÖ‰øùÁïôÊô∫ËÉΩÂèåËßíËâ≤Ôºâ
        default_workflows = [
            (
                "intelligent_dual",
                "Êô∫ËÉΩ‰∏âËßíËâ≤ÔºàLead+ÂâçÁ´Ø+ÂêéÁ´Ø+Â§çÊ†∏Ôºâ",
                "LeadÂÖàËØÑ‰º∞Âπ∂ÂàÜÈÖçÔºåÂâçÂêéÁ´ØÊâßË°åÔºåÂ§çÊ†∏Â§±Ë¥•‰ºöÁªôÊÑèËßÅÂπ∂ÊâìÂõû",
                json.dumps(["ÈúÄÊ±ÇËØÑ‰º∞‰∏éÂàÜÈÖç", "ÂâçÁ´ØÂÆûÁé∞", "ÂêéÁ´ØÂÆûÁé∞", "Â§çÊ†∏", "ËÅîÂêà‰∫§‰ªò"], ensure_ascii=False),
                "general",
                "Lead Agent",
                "",
            ),
        ]
        for code, name, desc, stages, task_type, assignee, cmd in default_workflows:
            conn.execute(
                """
                INSERT OR IGNORE INTO workflows(
                    code, name, description, stages_json, default_task_type, default_assignee, command_template, enabled, created_at, updated_at
                ) VALUES(?,?,?,?,?,?,?,1,?,?)
                """,
                (code, name, desc, stages, task_type, assignee, cmd, now_str(), now_str()),
            )

        stage_role_defaults = {
            "intelligent_dual": {"ÈúÄÊ±ÇËØÑ‰º∞‰∏éÂàÜÈÖç": "Lead Agent", "ÂâçÁ´ØÂÆûÁé∞": "frontend", "ÂêéÁ´ØÂÆûÁé∞": "backend", "Â§çÊ†∏": "reviewer", "ËÅîÂêà‰∫§‰ªò": "Lead Agent"},
        }
        for wf_code, mapping in stage_role_defaults.items():
            conn.execute(
                """
                UPDATE workflows
                SET stage_roles_json = ?,
                    updated_at=?
                WHERE code=?
                """,
                (json.dumps(mapping, ensure_ascii=False), now_str(), wf_code),
            )

        workflow_stage_defaults = {
            "intelligent_dual": ["ÈúÄÊ±ÇËØÑ‰º∞‰∏éÂàÜÈÖç", "ÂâçÁ´ØÂÆûÁé∞", "ÂêéÁ´ØÂÆûÁé∞", "Â§çÊ†∏", "ËÅîÂêà‰∫§‰ªò"],
        }
        workflow_assignee_defaults = {
            "intelligent_dual": "Lead Agent",
        }
        for wf_code, stages in workflow_stage_defaults.items():
            conn.execute(
                """
                UPDATE workflows
                SET stages_json=?,
                    default_assignee=?,
                    updated_at=?
                WHERE code=?
                """,
                (
                    json.dumps(stages, ensure_ascii=False),
                    workflow_assignee_defaults.get(wf_code, "Lead Agent"),
                    now_str(),
                    wf_code,
                ),
            )


def get_setting(key: str, default_value: str = "") -> str:
    with db_conn() as conn:
        row = conn.execute("SELECT value FROM app_settings WHERE key=?", (key,)).fetchone()
    if not row:
        return default_value
    return row["value"]


def set_setting(key: str, value: str):
    with db_conn() as conn:
        conn.execute(
            """
            INSERT INTO app_settings(key, value, updated_at)
            VALUES(?,?,?)
            ON CONFLICT(key) DO UPDATE SET value=excluded.value, updated_at=excluded.updated_at
            """,
            (key, str(value), now_str()),
        )


def sync_runtime_settings():
    raw = get_setting("max_concurrent", str(DEFAULT_MAX_CONCURRENT))
    try:
        val = max(1, min(16, int(raw)))
    except Exception:
        val = DEFAULT_MAX_CONCURRENT
    set_setting("max_concurrent", str(val))
    limiter.set_limit(val)


def get_roles(enabled_only: bool = False):
    q = "SELECT * FROM roles"
    if enabled_only:
        q += " WHERE enabled=1"
    q += " ORDER BY CASE WHEN code='Lead Agent' THEN 0 ELSE 1 END, id ASC"
    with db_conn() as conn:
        rows = conn.execute(q).fetchall()

    out = []
    for r in rows:
        d = dict(r)
        d["api_ready"] = bool((d.get("api_base") or "").strip() and (d.get("api_key") or "").strip() and (d.get("default_model") or "").strip())
        d["api_key_masked"] = mask_secret(d.get("api_key") or "")
        out.append(d)
    return out


def get_workflow_by_code(code: str):
    if not code:
        return None
    with db_conn() as conn:
        return conn.execute("SELECT * FROM workflows WHERE code=?", (code,)).fetchone()


def get_role_by_code(code: str):
    if not code:
        return None
    with db_conn() as conn:
        return conn.execute("SELECT * FROM roles WHERE code=?", (code,)).fetchone()


def get_reviewer_role():
    # Êñ∞Êû∂ÊûÑ‰ºòÂÖà reviewerÔºåÂÖºÂÆπÊóß @verifier
    r = get_role_by_code("reviewer")
    if r:
        return r, "reviewer"
    r = get_role_by_code("@verifier")
    if r:
        return r, "@verifier"
    return None, "reviewer"


def mask_secret(secret: str) -> str:
    s = (secret or "").strip()
    if not s:
        return ""
    if len(s) <= 8:
        return "*" * len(s)
    return s[:4] + "..." + s[-4:]


def parse_stages(stages_json: str):
    raw = (stages_json or "").strip()
    if not raw:
        return []
    try:
        data = json.loads(raw)
        if isinstance(data, list):
            return [str(x) for x in data]
    except Exception:
        pass
    return [x.strip() for x in re.split(r"[,Ôºå\n]+", raw) if x.strip()]


def parse_stage_roles(stage_roles_json: str):
    raw = (stage_roles_json or "").strip()
    if not raw:
        return {}
    try:
        data = json.loads(raw)
        if isinstance(data, dict):
            return {str(k): str(v) for k, v in data.items() if str(k).strip() and str(v).strip()}
    except Exception:
        pass

    out = {}
    for part in re.split(r"[,Ôºå\n]+", raw):
        p = part.strip()
        if not p:
            continue
        if ":" in p:
            k, v = p.split(":", 1)
        elif "=" in p:
            k, v = p.split("=", 1)
        else:
            continue
        k = k.strip()
        v = v.strip()
        if k and v:
            out[k] = v
    return out


def get_workflows(enabled_only: bool = False):
    q = "SELECT * FROM workflows"
    if enabled_only:
        q += " WHERE enabled=1"
    q += " ORDER BY id ASC"
    with db_conn() as conn:
        rows = conn.execute(q).fetchall()

    out = []
    for r in rows:
        d = dict(r)
        d["stages"] = parse_stages(d.get("stages_json"))
        d["stage_roles"] = parse_stage_roles(d.get("stage_roles_json"))
        out.append(d)
    return out


def append_log(task_id: int, line: str):
    rid = task_run_context.get(task_id)
    text = (line or "")
    if rid and not text.startswith("[run:"):
        text = f"[run:{rid}] {text}"
    with db_conn() as conn:
        conn.execute(
            "INSERT INTO task_logs(task_id, ts, line) VALUES(?,?,?)",
            (task_id, now_str(), text[:4000]),
        )


def update_task(task_id: int, **fields):
    if not fields:
        return
    fields["updated_at"] = now_str()
    keys = list(fields.keys())
    vals = [fields[k] for k in keys]
    clause = ", ".join([f"{k}=?" for k in keys])
    with db_conn() as conn:
        conn.execute(f"UPDATE tasks SET {clause} WHERE id=?", vals + [task_id])


def get_task(task_id: int):
    with db_conn() as conn:
        return conn.execute("SELECT * FROM tasks WHERE id=?", (task_id,)).fetchone()


def save_role_message(task_id: int, role_code: str, stage: str, turn: str, content: str):
    with db_conn() as conn:
        conn.execute(
            "INSERT INTO role_session_messages(task_id, role_code, stage, turn, content, created_at) VALUES(?,?,?,?,?,?)",
            (task_id, role_code, stage, turn, (content or "")[:12000], now_str()),
        )


def load_role_messages(task_id: int, role_code: str, limit: int = 8):
    with db_conn() as conn:
        rows = conn.execute(
            "SELECT turn, content FROM role_session_messages WHERE task_id=? AND role_code=? ORDER BY id DESC LIMIT ?",
            (task_id, role_code, max(1, int(limit))),
        ).fetchall()
    return list(reversed(rows))


def parse_task_sections(description: str):
    text = (description or "").strip()
    out = {"task": "", "delivery": "", "extra": text}
    if not text:
        return out

    m_task = re.search(r"„Äê‰ªªÂä°ÊèèËø∞„Äë\n([\s\S]*?)(?:\n\n„Äê|$)", text)
    m_delivery = re.search(r"„ÄêÊúüÊúõ‰∫§‰ªò„Äë\n([\s\S]*?)(?:\n\n„Äê|$)", text)
    m_extra = re.search(r"„ÄêË°•ÂÖÖËØ¥Êòé„Äë\n([\s\S]*?)$", text)

    if m_task:
        out["task"] = m_task.group(1).strip()
    if m_delivery:
        out["delivery"] = m_delivery.group(1).strip()
    if m_extra:
        out["extra"] = m_extra.group(1).strip()
    return out


def build_default_acceptance_contract(task_title: str, sections: dict) -> dict:
    task_goal = (sections.get("task") or task_title or "").strip()
    delivery_hint = (sections.get("delivery") or "").strip()
    must_answer = [
        f"Âõ¥Áªï‰ªªÂä°ÁõÆÊ†áÁªôÂá∫ÂèØÈ™åËØÅÁªìËÆ∫Ôºö{task_goal}" if task_goal else "Âõ¥Áªï‰ªªÂä°ÁõÆÊ†áÁªôÂá∫ÂèØÈ™åËØÅÁªìËÆ∫",
        "ÁªôÂá∫ÂÖ≥ÈîÆÊï∞Â≠ó/Âà§Êñ≠‰æùÊçÆÔºåÂπ∂ËØ¥ÊòéÊù•Ê∫êÊàñËÆ°ÁÆóÊñπÂºè",
        "ÁªôÂá∫ÂèØÂ§çÁé∞Ë∑ØÂæÑÔºàÂëΩ‰ª§„ÄÅÂèÇÊï∞„ÄÅÊï∞ÊçÆÊù•Ê∫êÊàñÂ§ÑÁêÜÊ≠•È™§Ôºâ",
    ]
    if delivery_hint:
        must_answer.append(f"Ë¶ÜÁõñÁî®Êà∑ÊúüÊúõ‰∫§‰ªòÔºö{delivery_hint}")

    return {
        "must_answer": must_answer,
        "evidence_requirements": [
            "Ëá≥Â∞ëÂåÖÂê´ÂèØÊ†∏È™åÁöÑÂÖ≥ÈîÆËØÅÊçÆÔºàÊù•Ê∫êÁâáÊÆµ„ÄÅÁªüËÆ°ÊòéÁªÜ„ÄÅÊàñ‰∫ßÁâ©ÁâáÊÆµÔºâ",
            "ÈúÄË¶ÅËØ¥ÊòéÁªìËÆ∫‰∏éËØÅÊçÆÁöÑÂØπÂ∫îÂÖ≥Á≥ª",
        ],
        "delivery_form": "‰∫§‰ªòÂΩ¢ÂºèÂèØËá™Áî±ÈÄâÊã©Ôºàmd/json/csv/txt/zipÁ≠âÔºâÔºå‰∏çÂº∫Âà∂Âõ∫ÂÆöÊñá‰ª∂Âêç",
        "forbidden": [
            "Âè™ÁªôÂëΩ‰ª§ÊàñËÑöÊú¨ÁâáÊÆµÔºå‰∏çÁªôÊâßË°åÁªìÊûú",
            "Âè™ÂÅöËØäÊñ≠‰∏çÊî∂ÊïõÂà∞ÁªìËÆ∫",
        ],
    }


def normalize_acceptance_contract(contract: dict, task_title: str, sections: dict) -> dict:
    base = build_default_acceptance_contract(task_title, sections)
    if not isinstance(contract, dict):
        return base

    out = dict(base)
    for k in ["must_answer", "evidence_requirements", "forbidden"]:
        v = contract.get(k)
        if isinstance(v, list):
            vv = [str(x).strip() for x in v if str(x).strip()]
            if vv:
                out[k] = vv

    if isinstance(contract.get("delivery_form"), str) and contract.get("delivery_form").strip():
        out["delivery_form"] = contract.get("delivery_form").strip()

    return out


def contract_to_text(contract: dict) -> str:
    c = contract or {}
    lines = ["„Äê‰ªªÂä°È™åÊî∂Â•ëÁ∫¶„Äë"]
    ma = c.get("must_answer") or []
    er = c.get("evidence_requirements") or []
    fb = c.get("forbidden") or []
    if ma:
        lines.append("- ÂøÖÈ°ªÂõûÁ≠îÔºö")
        lines.extend([f"  - {x}" for x in ma])
    if er:
        lines.append("- ËØÅÊçÆË¶ÅÊ±ÇÔºö")
        lines.extend([f"  - {x}" for x in er])
    if c.get("delivery_form"):
        lines.append(f"- ‰∫§‰ªòÂΩ¢ÂºèÔºö{c.get('delivery_form')}")
    if fb:
        lines.append("- Á¶ÅÊ≠¢Ë°å‰∏∫Ôºö")
        lines.extend([f"  - {x}" for x in fb])
    return "\n".join(lines)


def ensure_not_stopped(task_id: int):
    if task_id not in running_processes:
        raise RuntimeError("‰ªªÂä°Ë¢´ÊâãÂä®ÂÅúÊ≠¢")


def _extract_content_from_chat_response(data: dict) -> str:
    choices = data.get("choices") or []
    if not choices:
        return ""
    msg = (choices[0] or {}).get("message") or {}
    content = msg.get("content")
    if isinstance(content, list):
        parts = []
        for item in content:
            if isinstance(item, dict):
                if item.get("type") == "text":
                    parts.append(item.get("text") or "")
                elif "text" in item:
                    parts.append(str(item.get("text")))
            else:
                parts.append(str(item))
        return "\n".join([p for p in parts if p]).strip()
    return (content or "").strip()


def call_role_llm(role, messages):
    api_base = (role["api_base"] or ROLE_DEFAULT_API_BASE or "").strip()
    api_key = (role["api_key"] or ROLE_DEFAULT_API_KEY or "").strip()
    model = (role["default_model"] or "").strip()

    if not api_base:
        raise RuntimeError(f"ËßíËâ≤ {role['code']} Êú™ÈÖçÁΩÆ api_base")
    if not api_key:
        raise RuntimeError(f"ËßíËâ≤ {role['code']} Êú™ÈÖçÁΩÆ api_key")
    if not model:
        raise RuntimeError(f"ËßíËâ≤ {role['code']} Êú™ÈÖçÁΩÆÊ®°Âûã")

    base = api_base.rstrip("/")
    url = (base + "/chat/completions") if base.endswith("/v1") else (base + "/v1/chat/completions")
    payload = {
        "model": model,
        "messages": messages,
        "temperature": float(role["temperature"] if role["temperature"] is not None else 0.3),
        "max_tokens": int(role["max_tokens"] if role["max_tokens"] is not None else 1200),
    }

    # GPT/Codex ËßíËâ≤ÈªòËÆ§ÂºÄÂêØÊ∑±Â∫¶ÊÄùËÄÉÂèÇÊï∞ÔºàMiniMaxÁ≠âÊ®°Âûã‰∏çÊ≥®ÂÖ•Ôºâ
    ml = model.lower()
    if ml.startswith("gpt-") or ("codex" in ml):
        effort = ROLE_REASONING_EFFORT if ROLE_REASONING_EFFORT in ("low", "medium", "high") else "high"
        payload["reasoning"] = {"effort": effort}
        payload["thinking"] = effort
    body = json.dumps(payload, ensure_ascii=False).encode("utf-8")

    req = urllib.request.Request(
        url,
        data=body,
        method="POST",
        headers={
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        },
    )

    timeout = max(30, ROLE_DEFAULT_TIMEOUT)
    try:
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            raw = resp.read().decode("utf-8", errors="ignore")
    except urllib.error.HTTPError as e:
        detail = e.read().decode("utf-8", errors="ignore") if hasattr(e, "read") else str(e)
        raise RuntimeError(f"ËßíËâ≤ {role['code']} Ê®°ÂûãËØ∑Ê±ÇÂ§±Ë¥•: HTTP {getattr(e, 'code', '?')} {detail[:200]}")
    except Exception as e:
        raise RuntimeError(f"ËßíËâ≤ {role['code']} Ê®°ÂûãËØ∑Ê±ÇÂºÇÂ∏∏: {e}")

    try:
        data = json.loads(raw)
    except Exception:
        raise RuntimeError(f"ËßíËâ≤ {role['code']} ËøîÂõûÈùûJSON: {raw[:200]}")

    text = _extract_content_from_chat_response(data)
    if not text:
        raise RuntimeError(f"ËßíËâ≤ {role['code']} ËøîÂõûÁ©∫ÂÜÖÂÆπ")
    return text


def is_verifier_stage(stage: str, role_code: str) -> bool:
    s = (stage or "")
    r = (role_code or "")
    return r in ("reviewer", "@verifier") or any(k in s for k in ["È™åËØÅ", "Â§çÊ†∏", "È™åÊî∂", "review"])


def parse_verifier_feedback(text: str) -> dict:
    raw = (text or "").strip()
    out = {
        "decision": "UNKNOWN",
        "reason": "",
        "issues": [],
        "send_back_role": "",
        "rework_instructions": "",
    }
    if not raw:
        return out

    # ‰ºòÂÖàËß£Êûê JSON
    m = re.search(r"\{[\s\S]*\}", raw)
    if m:
        try:
            data = json.loads(m.group(0))
            dec = str(data.get("decision", "")).strip().upper()
            if dec in ("PASS", "FAIL"):
                out["decision"] = dec
            out["reason"] = str(data.get("reason", "")).strip()
            issues = data.get("issues") or []
            if isinstance(issues, list):
                out["issues"] = [str(x).strip() for x in issues if str(x).strip()]
            out["send_back_role"] = str(data.get("send_back_role", "")).strip()
            out["rework_instructions"] = str(data.get("rework_instructions", "")).strip()
            return out
        except Exception:
            pass

    upper = raw.upper()
    if "FAIL" in upper or "‰∏çÈÄöËøá" in raw or "ÊâìÂõû" in raw:
        out["decision"] = "FAIL"
    elif "PASS" in upper or "ÈÄöËøá" in raw:
        out["decision"] = "PASS"

    role_hit = re.search(r"(@[a-zA-Z0-9_\-]+)", raw)
    if role_hit:
        out["send_back_role"] = role_hit.group(1)

    lines = [ln.strip("- ‚Ä¢\t ") for ln in raw.splitlines() if ln.strip()]
    if lines:
        out["reason"] = lines[0][:300]
        out["issues"] = lines[1:6]
        out["rework_instructions"] = "Ôºõ".join(lines[1:4])[:800]
    return out


def parse_role_action(text: str) -> dict:
    raw = (text or "").strip()
    out = {"action": "final", "content": raw, "command": "", "reason": ""}
    if not raw:
        return out

    m = re.search(r"\{[\s\S]*\}", raw)
    if not m:
        return out

    try:
        data = json.loads(m.group(0))
    except Exception:
        return out

    action = str(data.get("action") or "").strip().lower()
    if action == "run_command":
        out["action"] = "run_command"
        out["command"] = str(data.get("command") or data.get("cmd") or "").strip()
        out["reason"] = str(data.get("reason") or "").strip()
        return out

    if action == "final":
        out["action"] = "final"
        out["content"] = str(data.get("content") or raw).strip()
        return out

    return out


def list_output_file_names(output_dir: str) -> set:
    if not os.path.isdir(output_dir):
        return set()
    out = set()
    for name in os.listdir(output_dir):
        full = os.path.join(output_dir, name)
        if os.path.isfile(full):
            out.add(name)
    return out


def is_system_generated_output(name: str) -> bool:
    n = (name or "").strip()
    return n.startswith("Ê≠•È™§") or n in ("Â§öAgent_ÊúÄÁªà‰∫§‰ªò.md", "Â§öAgent_‰ºöËØùÂÆ°ËÆ°.json")


def task_requires_real_artifacts(task_text: str) -> bool:
    t = (task_text or "")
    keys = ["Áà¨Âèñ", "ÈááÈõÜ", "ÂÖ≥ÈîÆËØç", "ÊñáÂåÖ", "Êä•Âëä", "ÂØºÂá∫", "csv", "json", "zip", "ÈôÑ‰ª∂"]
    return any(k in t for k in keys)


def is_safe_role_command(command: str) -> tuple[bool, str]:
    cmd = (command or "").strip()
    if not cmd:
        return False, "ÂëΩ‰ª§‰∏∫Á©∫"
    if len(cmd) > 800:
        return False, "ÂëΩ‰ª§ËøáÈïøÔºà>800Ôºâ"
    if "\n" in cmd or "\r" in cmd:
        return False, "ÂëΩ‰ª§‰∏çËÉΩÂåÖÂê´Êç¢Ë°å"

    blocked = [
        "rm -rf /",
        "shutdown",
        "reboot",
        "mkfs",
        "fdisk",
        "poweroff",
        ":(){",
        "halt",
        "systemctl stop",
        "systemctl disable",
    ]
    lower = cmd.lower()
    for b in blocked:
        if b in lower:
            return False, f"ÂëΩ‰∏≠È´òÂç±ÂëΩ‰ª§ÁâáÊÆµ: {b}"
    return True, "ok"


def execute_role_command(command: str, task_id: int, base_dir: str, input_dir: str, output_dir: str, timeout_sec: int = 240) -> dict:
    env = os.environ.copy()
    env.update(
        {
            "TASK_ID": str(task_id),
            "TASK_ARTIFACT_DIR": base_dir,
            "TASK_INPUT_DIR": input_dir,
            "TASK_OUTPUT_DIR": output_dir,
        }
    )

    proc = subprocess.Popen(
        command,
        shell=True,
        cwd=WORKDIR,
        executable="/bin/bash",
        env=env,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
    )
    try:
        out, _ = proc.communicate(timeout=max(30, int(timeout_sec)))
        rc = proc.returncode
        timed_out = False
    except subprocess.TimeoutExpired:
        proc.kill()
        out, _ = proc.communicate()
        rc = 124
        timed_out = True

    out = (out or "")[-6000:]
    return {"rc": rc, "output": out, "timedOut": timed_out}


def run_role_stage_with_tools(
    task_id: int,
    stage: str,
    role,
    messages: list,
    base_dir: str,
    input_dir: str,
    output_dir: str,
    max_tool_rounds: int = ROLE_MAX_TOOL_ROUNDS,
):
    tool_round = 0
    tool_events = []

    while True:
        ensure_not_stopped(task_id)
        assistant_text = call_role_llm(role, messages)
        save_role_message(task_id, role["code"], stage, "assistant", assistant_text)

        action = parse_role_action(assistant_text)
        if action["action"] == "run_command" and tool_round < max_tool_rounds:
            cmd = action.get("command", "")
            ok, reason = is_safe_role_command(cmd)
            if not ok:
                result = {"rc": 1, "output": f"[TOOL_BRIDGE] ÊãíÁªùÊâßË°åÔºö{reason}", "timedOut": False}
            else:
                result = execute_role_command(cmd, task_id, base_dir, input_dir, output_dir)

            tool_events.append(
                {
                    "round": tool_round + 1,
                    "command": cmd,
                    "rc": result["rc"],
                    "timedOut": result["timedOut"],
                }
            )
            append_log(
                task_id,
                f"[{role['code']}] Â∑•ÂÖ∑ÊâßË°å round={tool_round+1}/{max_tool_rounds} rc={result['rc']} timedOut={result['timedOut']} cmd={cmd}",
            )

            tool_feedback = (
                "Â∑•ÂÖ∑ÊâßË°åÁªìÊûúÂ¶Ç‰∏ãÔºåËØ∑Âü∫‰∫éÁªìÊûúÁªßÁª≠„ÄÇ\n"
                f"ÂëΩ‰ª§: {cmd}\n"
                f"ËøîÂõûÁ†Å: {result['rc']}\n"
                f"ÊòØÂê¶Ë∂ÖÊó∂: {result['timedOut']}\n"
                f"ËæìÂá∫ÁâáÊÆµ:\n{result['output']}\n\n"
                "Ëã•ËøòÈúÄË¶ÅÊâßË°åÂ∑•ÂÖ∑ÔºåÂèØÁªßÁª≠ËøîÂõû run_command JSONÔºõËã•Â∑≤ÂÆåÊàêÔºåËØ∑ËøîÂõû final JSON„ÄÇ"
            )
            messages.append({"role": "assistant", "content": assistant_text})
            messages.append({"role": "user", "content": tool_feedback})
            save_role_message(task_id, role["code"], stage, "user", tool_feedback)
            tool_round += 1
            continue

        final_content = action.get("content") if action.get("action") == "final" else assistant_text
        return final_content, tool_events


def find_stage_index_by_role(stages: list, stage_roles: dict, role_code: str, before_idx: int, fallback_idx: int = 0) -> int:
    rc = (role_code or "").strip()
    if not rc:
        return fallback_idx
    for i in range(max(0, before_idx - 1), -1, -1):
        st = stages[i]
        if (stage_roles.get(st) or "").strip() == rc:
            return i
    return fallback_idx


def parse_dispatch_plan(text: str, allowed_stages: list, enabled_role_codes: set) -> dict:
    raw = (text or "").strip()
    out = {
        "assignments": {},
        "active_stages": None,  # None=‰∏çÊîπÔºålist=ÊîπÂÜô
        "skipped_stages": [],
        "acceptance_contract": None,
        "collision_rounds": None,
    }
    if not raw:
        return out

    payload = None
    m = re.search(r"\{[\s\S]*\}", raw)
    if m:
        try:
            payload = json.loads(m.group(0))
        except Exception:
            payload = None

    if not isinstance(payload, dict):
        return out

    assignments = payload.get("assignments") or payload.get("dispatch") or []
    if isinstance(assignments, list):
        for item in assignments:
            if not isinstance(item, dict):
                continue
            stage = str(item.get("stage") or "").strip()
            role = str(item.get("role") or item.get("assignee") or "").strip()
            if stage in allowed_stages and role in enabled_role_codes:
                out["assignments"][stage] = role

    # ÂÖºÂÆπÁõ¥Êé• map
    if not out["assignments"]:
        for k, v in payload.items():
            ks = str(k).strip()
            vs = str(v).strip() if isinstance(v, (str, int, float)) else ""
            if ks in allowed_stages and vs in enabled_role_codes:
                out["assignments"][ks] = vs

    active_raw = payload.get("active_stages")
    if isinstance(active_raw, list):
        active = [str(x).strip() for x in active_raw if str(x).strip() in allowed_stages]
        out["active_stages"] = active

    skip_raw = payload.get("skip_stages") or payload.get("skipped_stages")
    if isinstance(skip_raw, list):
        skips = [str(x).strip() for x in skip_raw if str(x).strip() in allowed_stages]
        out["skipped_stages"] = skips
        if out["active_stages"] is None:
            out["active_stages"] = [s for s in allowed_stages if s not in skips]

    contract_raw = payload.get("acceptance_contract")
    if isinstance(contract_raw, dict):
        out["acceptance_contract"] = contract_raw

    rounds_raw = payload.get("collision_rounds")
    if isinstance(rounds_raw, (int, float, str)):
        try:
            rr = int(float(rounds_raw))
            out["collision_rounds"] = max(0, min(6, rr))
        except Exception:
            pass

    return out


def run_stage_collision(
    task_id: int,
    stage: str,
    role,
    reviewer_role,
    sections: dict,
    contract_text: str,
    previous_output: str,
    handoff_note: str,
    current_output: str,
    base_dir: str,
    input_dir: str,
    output_dir: str,
    rounds: int,
):
    if not reviewer_role or rounds <= 0:
        return current_output, [], []

    reviewer_code = reviewer_role["code"]
    output = current_output
    extra_tool_events = []
    collision_records = []

    for i in range(1, rounds + 1):
        ensure_not_stopped(task_id)
        review_stage = f"{stage}-ÂØπÊäóËØÑÂÆ°"
        review_prompt = (
            "‰Ω†ÊòØÂØπÊäóËØÑÂÆ°ËßíËâ≤„ÄÇÁõÆÊ†á‰∏çÊòØÂ§çËø∞ÔºåËÄåÊòØÊâæÂá∫ÂΩìÂâçËæìÂá∫Á¶ª‚ÄòÂèØÈ™åÊî∂‰∫§‰ªò‚ÄôËøòÂ∑Æ‰ªÄ‰πà„ÄÇ"
            "ËØ∑‰∏•Ê†ºËøîÂõû JSONÔºö"
            '{"decision":"PASS|FAIL","reason":"...","issues":["..."],"send_back_role":"ÂΩìÂâçËßíËâ≤code","rework_instructions":"..."}'
            "„ÄÇFAIL Êó∂ÂøÖÈ°ªÁªôÂá∫ÂèØÊâßË°å‰øÆÊîπË¶ÅÊ±Ç„ÄÇ\n"
            f"‰ªªÂä°ÁõÆÊ†áÔºö{sections.get('task') or ''}\n"
            f"ÊúüÊúõ‰∫§‰ªòÔºö{sections.get('delivery') or ''}\n"
            f"{contract_text}\n\n"
            f"ÂΩìÂâçÈò∂ÊÆµËæìÂá∫Ôºö\n{output}\n"
        )
        review_msgs = [
            {"role": "system", "content": (reviewer_role["system_prompt"] or "‰Ω†ÊòØ‰∏•ËãõËØÑÂÆ°„ÄÇ")},
            {"role": "user", "content": review_prompt},
        ]
        save_role_message(task_id, reviewer_code, review_stage, "user", review_prompt)
        review_output = call_role_llm(reviewer_role, review_msgs)
        save_role_message(task_id, reviewer_code, review_stage, "assistant", review_output)
        decision = parse_verifier_feedback(review_output)
        dec = decision.get("decision", "UNKNOWN")

        collision_item = {
            "round": i,
            "reviewer": reviewer_code,
            "decision": decision,
        }
        collision_records.append(collision_item)
        append_log(task_id, f"[{reviewer_code}] ÂØπÊäóËØÑÂÆ° Á¨¨{i}/{rounds}ËΩÆÔºö{dec} | reason={decision.get('reason','')[:120]}")

        if dec == "PASS":
            break

        revise_instruction = (
            "‰Ω†Êî∂Âà∞ËØÑÂÆ°ÊåëÊàòÔºåËØ∑Âè™ÈíàÂØπÁº∫Âè£Ë°•ÈΩêÂèØÈ™åÊî∂ÁªìÊûú„ÄÇ"
            "ÂÖÅËÆ∏ÁªßÁª≠‰ΩøÁî® run_commandÔºõËã•ÂÆåÊàêËØ∑ËøîÂõû final„ÄÇ"
            "‰∏çË¶ÅÈáçÂ§çËØäÊñ≠Ôºå‰ºòÂÖàËæìÂá∫Êñ∞Â¢ûËØÅÊçÆ‰∏éÊñ∞Â¢ûÁªìËÆ∫„ÄÇ\n"
            f"ËØÑÂÆ°ÂéüÂõ†Ôºö{decision.get('reason','')}\n"
            f"ËØÑÂÆ°ÈóÆÈ¢òÔºö{'Ôºõ'.join(decision.get('issues') or [])}\n"
            f"‰øÆÊîπË¶ÅÊ±ÇÔºö{decision.get('rework_instructions','ËØ∑Ë°•ÈΩêÁº∫Âè£ÂêéÊèê‰∫§„ÄÇ')}\n"
            f"{contract_text}"
        )

        history = load_role_messages(task_id, role["code"], limit=ROLE_HISTORY_LIMIT)
        msgs = [{"role": "system", "content": (role["system_prompt"] or f"‰Ω†ÊòØ{role['code']}") }]
        for h in history:
            turn = (h["turn"] or "").strip().lower()
            if turn in ("user", "assistant", "system"):
                msgs.append({"role": turn, "content": h["content"] or ""})
        revise_prompt = (
            f"‰Ω†ÂΩìÂâçË¥üË¥£Èò∂ÊÆµÔºö{stage}\n"
            f"‰ªªÂä°ÊèèËø∞Ôºö{sections.get('task') or ''}\n"
            f"ÊúüÊúõ‰∫§‰ªòÔºö{sections.get('delivery') or ''}\n"
            f"‰∏ä‰∏Ä‰∏™Èò∂ÊÆµËæìÂá∫ÔºàÂèØÂøΩÁï•ÔºâÔºö\n{previous_output}\n\n"
            f"ËøîÂ∑•/‰∫§Êé•ËØ¥ÊòéÔºàÂèØÂøΩÁï•ÔºâÔºö\n{handoff_note}\n\n"
            f"ÂΩìÂâçÈò∂ÊÆµÂ∑≤ÊúâËæìÂá∫Ôºö\n{output}\n\n"
            f"Êú¨ËΩÆÊåëÊàò‰∏é‰øÆÊîπË¶ÅÊ±ÇÔºö\n{revise_instruction}"
        )
        msgs.append({"role": "user", "content": revise_prompt})
        save_role_message(task_id, role["code"], stage, "user", revise_prompt)

        new_output, new_tools = run_role_stage_with_tools(
            task_id=task_id,
            stage=stage,
            role=role,
            messages=msgs,
            base_dir=base_dir,
            input_dir=input_dir,
            output_dir=output_dir,
            max_tool_rounds=ROLE_MAX_TOOL_ROUNDS,
        )
        output = new_output
        extra_tool_events.extend(new_tools)
        collision_item["toolEvents"] = new_tools
        collision_item["revisedChars"] = len(new_output)
        append_log(task_id, f"[{role['code']}] ÂØπÊäóËØÑÂÆ°Âêé‰øÆËÆ¢ÂÆåÊàêÔºàÁ¨¨{i}/{rounds}ËΩÆÔºâÔºåËæìÂá∫ÈïøÂ∫¶={len(new_output)}")

    return output, extra_tool_events, collision_records


def run_multi_agent_workflow(task_id: int, task, wf, base_dir: str, input_dir: str, output_dir: str):
    stages = parse_stages(wf["stages_json"])
    stage_roles = parse_stage_roles(wf["stage_roles_json"])
    if not stages:
        raise RuntimeError("Â∑•‰ΩúÊµÅÊ≤°ÊúâÈÖçÁΩÆÈò∂ÊÆµ")

    sections = parse_task_sections(task["description"] or "")
    previous_output = ""
    handoff_note = ""
    rework_round = 0
    stage_idx = 0
    execution_no = 0
    max_rework_rounds = ROLE_MAX_REWORK_ROUNDS
    max_stage_review_retries = ROLE_STAGE_REVIEW_MAX_RETRIES
    max_iterations = len(stages) * (max_rework_rounds + max_stage_review_retries + 4) + 12
    iterations = 0
    stage_retry_counts = {s: 0 for s in stages}

    enabled_role_codes = {r["code"] for r in get_roles(enabled_only=True)}
    active_stage_set = set(stages)
    acceptance_contract = build_default_acceptance_contract(task["title"] or "", sections)
    collision_rounds = ROLE_CROSS_REVIEW_ROUNDS
    last_execution_output = ""
    last_execution_stage = ""
    last_execution_role = ""
    lead_acceptance_result = None

    audit = {
        "taskId": task_id,
        "workflow": wf["code"],
        "maxReworkRounds": max_rework_rounds,
        "maxStageReviewRetries": max_stage_review_retries,
        "reworkRoundsUsed": 0,
        "stages": [],
        "dynamicAssignments": {},
        "acceptanceContract": acceptance_contract,
        "collisionRounds": collision_rounds,
        "startedAt": now_str(),
    }

    while stage_idx < len(stages):
        iterations += 1
        if iterations > max_iterations:
            raise RuntimeError(f"Ë∂ÖËøáÊúÄÂ§ßËø≠‰ª£ÈôêÂà∂Ôºà{max_iterations}ÔºâÔºåÂ∑≤Ëá™Âä®ÁªàÊ≠¢ÈÅøÂÖçÂæ™ÁéØ")

        ensure_not_stopped(task_id)
        stage = stages[stage_idx]

        # Âä®ÊÄÅÂàÜÂèëÂêéÂèØË∑≥ËøáÈùûÂøÖË¶ÅÈò∂ÊÆµ
        if (stage_idx > 0) and (stage not in active_stage_set):
            append_log(task_id, f"[Lead Agent] Ë∑≥ËøáÈò∂ÊÆµ{stage_idx+1}Ôºö{stage}ÔºàÊú¨ËΩÆÊú™ÂàÜÈÖçÔºâ")
            audit["stages"].append(
                {
                    "executionNo": None,
                    "index": stage_idx + 1,
                    "stage": stage,
                    "role": stage_roles.get(stage) or "-",
                    "model": "-",
                    "status": "SKIPPED",
                    "reason": "Âä®ÊÄÅÂàÜÂèëÊú™Á∫≥ÂÖ•Êú¨ËΩÆÊâßË°å",
                    "finishedAt": now_str(),
                }
            )
            stage_idx += 1
            continue

        role_code = stage_roles.get(stage) or (wf["default_assignee"] or "") or (task["assignee"] or "Lead Agent")
        role = get_role_by_code(role_code)
        if not role:
            raise RuntimeError(f"Èò∂ÊÆµ {stage} Êâæ‰∏çÂà∞ËßíËâ≤: {role_code}")
        if int(role["enabled"] or 0) != 1:
            raise RuntimeError(f"Èò∂ÊÆµ {stage} ËßíËâ≤Êú™ÂêØÁî®: {role_code}")

        stage_retry = stage_retry_counts.get(stage, 0)
        append_log(task_id, f"[Lead Agent] Èò∂ÊÆµ{stage_idx+1}/{len(stages)}Ôºö{stage} -> {role_code}ÔºàËøîÂ∑•ËΩÆÊ¨°={rework_round}ÔºåÊú¨Èò∂ÊÆµÈáçËØï={stage_retry}/{max_stage_review_retries}Ôºâ")

        history = load_role_messages(task_id, role_code, limit=ROLE_HISTORY_LIMIT)
        sys_prompt = (role["system_prompt"] or "").strip()
        if not sys_prompt:
            sys_prompt = f"‰Ω†ÊòØ{role['name']}Ôºà{role['code']}ÔºâÔºåËÅåË¥£Ôºö{role['description'] or 'ÂÆåÊàêË¢´ÂàÜÈÖçÈò∂ÊÆµÂπ∂ËæìÂá∫ÂèØÊâßË°åÁªìÊûú'}„ÄÇ"

        verifier_mode = is_verifier_stage(stage, role_code)
        dispatch_stage = ("ÂàÜÂèë" in stage) or (stage_idx == 0 and any(k in stage for k in ["ËØÑ‰º∞", "ÊãÜËß£", "ËßÑÂàí"]))
        lead_dispatch_mode = bool(dispatch_stage)
        lead_acceptance_mode = (
            role_code == "Lead Agent"
            and (not lead_dispatch_mode)
            and any(k in stage for k in ["ËÅîÂêà‰∫§‰ªò", "È™åÊî∂", "‰∫§‰ªò"])
        )
        if verifier_mode:
            stage_instruction = (
                "‰Ω†Âè™Ë¥üË¥£ÂΩìÂâçÂ§çÊ†∏Èò∂ÊÆµÔºå‰∏çË¥üË¥£ÂºÄÂèëÂÆûÁé∞„ÄÇËØ∑‰∏•Ê†º‰æùÊçÆ‰ªªÂä°Ë¶ÅÊ±ÇÂà§ÂÆöÊòØÂê¶ÈÄöËøá„ÄÇ"
                "ÂøÖÈ°ªËøîÂõû JSONÔºö"
                '{"decision":"PASS|FAIL","reason":"...","issues":["..."],"send_back_role":"frontend Êàñ backend","rework_instructions":"..."}'
                "„ÄÇÂ¶ÇÊûúÈÄöËøáÔºåissuesÂèØ‰∏∫Á©∫Ôºåsend_back_roleÂèØÁ©∫„ÄÇ"
            )
        elif lead_dispatch_mode:
            stage_instruction = (
                "‰Ω†ÊòØÂΩìÂâçÊÄªÊéßÂàÜÂèëÈò∂ÊÆµÔºöÂÖàËØÑ‰º∞ÈúÄÊ±ÇÂ§çÊùÇÂ∫¶„ÄÅÈòªÂ°ûÈ£éÈô©‰∏éÊâßË°åÊàêÊú¨ÔºåÂÜçÊåâÂêéÁª≠ËßíËâ≤ÂàÜÂèë‰ªªÂä°„ÄÇ"
                "ËØ∑ËæìÂá∫‚ÄúÂàÜÂèëÊ∏ÖÂçï‚ÄùÔºåËá≥Â∞ëÂåÖÂê´ÔºöËßíËâ≤„ÄÅËØ•ËßíËâ≤ÁõÆÊ†á„ÄÅËæìÂÖ•„ÄÅËæìÂá∫„ÄÅÈ™åÊî∂Ê†áÂáÜ„ÄÇ"
                "‰∏çË¶ÅÊõøÊâßË°åËßíËâ≤ÂÆåÊàêÂÆûÁé∞ÔºåÂè™ÂÅöËØÑ‰º∞„ÄÅÊãÜËß£ÂíåÂàÜÂèë„ÄÇ"
                "Âπ∂Âú®ÁªìÂ∞æÈôÑ‰∏ä JSONÔºàassignments + active_stages + acceptance_contract + collision_roundsÔºâÁî®‰∫éÂä®ÊÄÅÂàÜÂèëÔºå‰æãÂ¶ÇÔºö"
                '{"assignments":[{"stage":"ÂâçÁ´ØÂÆûÁé∞","role":"frontend"},{"stage":"ÂêéÁ´ØÂÆûÁé∞","role":"backend"}],"active_stages":["ÂâçÁ´ØÂÆûÁé∞","ÂêéÁ´ØÂÆûÁé∞","Â§çÊ†∏","ËÅîÂêà‰∫§‰ªò"],"skip_stages":[],"acceptance_contract":{"must_answer":["ÂøÖÈ°ªÂõûÁ≠îÁöÑÈóÆÈ¢ò"],"evidence_requirements":["ËØÅÊçÆË¶ÅÊ±Ç"],"delivery_form":"‰∫§‰ªòÂΩ¢Âºè‰∏çÈôê"},"collision_rounds":3}'
                "„ÄÇstage ÂøÖÈ°ªÊòØÁé∞ÊúâÈò∂ÊÆµÂêçÔºårole ÂøÖÈ°ªÊòØÂèØÁî®ËßíËâ≤ code„ÄÇ"
                "Ëã•ÊüêÈò∂ÊÆµÊú¨ËΩÆ‰∏çÈúÄË¶ÅÊâßË°åÔºåËØ∑ÊòéÁ°ÆÂÜôÂÖ• skip_stages„ÄÇ"
                "acceptance_contract Âè™ÂÆö‰πâÈ™åÊî∂Áª¥Â∫¶Ôºå‰∏çË¶ÅÂÜôÊ≠ªÂÖ∑‰ΩìÊñá‰ª∂Âêç„ÄÇ"
            )
        elif lead_acceptance_mode:
            stage_instruction = (
                "‰Ω†ÊòØLeadÊúÄÁªàÈ™åÊî∂Èò∂ÊÆµÔºöÂøÖÈ°ªÂØπÂâçÂ∫èÊâßË°å‰∏éÂ§çÊ†∏ÁªìÊûúÂÅöÊúÄÁªàË£ÅÂÜ≥„ÄÇ"
                "ËØ∑‰æùÊçÆ‰ªªÂä°È™åÊî∂Â•ëÁ∫¶Âà§Êñ≠Ôºå‰∏çË¶ÅÂÜôÊ≠ªÂÖ∑‰ΩìÊñá‰ª∂Âêç„ÄÇ"
                "Â¶ÇÈÄöËøáÔºåËØ∑ËøîÂõû JSONÔºö"
                '{"decision":"PASS","reason":"...","issues":[],"send_back_role":"","rework_instructions":""}'
                "„ÄÇ"
                "Â¶Ç‰∏çÈÄöËøáÔºåÂøÖÈ°ªËøîÂõû JSONÔºö"
                '{"decision":"FAIL","reason":"...","issues":["..."],"send_back_role":"frontend Êàñ backend","rework_instructions":"ÊòéÁ°ÆÂèØÊâßË°åÁöÑ‰øÆÊîπË¶ÅÊ±Ç"}'
                "„ÄÇFAIL Êó∂ÂøÖÈ°ªÁªôÂá∫ÂèØÊâßË°åÁöÑÊâìÂõûÊÑèËßÅ„ÄÇ"
            )
        else:
            stage_instruction = (
                "‰Ω†Âè™Ë¥üË¥£ÂΩìÂâçÈò∂ÊÆµÔºå‰∏çË¶ÅÊõø‰∏ã‰∏ÄÈò∂ÊÆµÂÅöÂÜ≥ÂÆö„ÄÇ"
                "ËæìÂá∫Êú¨Èò∂ÊÆµÂèØÁõ¥Êé•‰∫§Êé•Áªô‰∏ãÈò∂ÊÆµÁöÑÁªìÊûúÔºà‰∏≠Êñá„ÄÅÁªìÊûÑÂåñ„ÄÅÂèØÊâßË°åÔºâ„ÄÇ"
                "Â¶ÇÊûúÊâßË°åÈÅáÂà∞Êã¶Êà™/Â§±Ë¥•ÔºåÂøÖÈ°ªÂÖàÁªôÂá∫ËØäÊñ≠ÔºåÂÜçÂàáÊç¢Á≠ñÁï•ÂêéÁªßÁª≠ÊâßË°åÔºå‰∏çË¶ÅÊú∫Ê¢∞ÈáçÂ§çÂêå‰∏ÄÂëΩ‰ª§„ÄÇ"
                "Â¶ÇÊûú‰ªªÂä°Ê∂âÂèäÁà¨Âèñ/ÈááÈõÜ/ÂÖ≥ÈîÆËØç/ÊñáÂåÖÔºåÂøÖÈ°ªÈÄöËøá run_command ‰∫ßÂá∫ÁúüÂÆûÊñá‰ª∂Âà∞ $TASK_OUTPUT_DIR„ÄÇ"
                "Â¶ÇÊûúÈúÄË¶ÅÂÆûÈôÖÊâßË°åÂ∑•ÂÖ∑/ËÑöÊú¨ÔºåËØ∑Âè™ËæìÂá∫ JSONÔºö"
                '{"action":"run_command","command":"python3 scripts/xxx.py ...","reason":"‰∏∫‰ªÄ‰πàË¶ÅÊâßË°å"}'
                "„ÄÇÁ≥ªÁªü‰ºöÊâßË°åÂêéÊääÁªìÊûúÂõû‰º†Áªô‰Ω†„ÄÇ"
                "ÂΩìÈò∂ÊÆµÂÆåÊàêÊó∂ÔºåËØ∑ËæìÂá∫ JSONÔºö"
                '{"action":"final","content":"‰Ω†ÁöÑÈò∂ÊÆµ‰∫§‰ªòÂÜÖÂÆπ"}'
            )

        task_text_all = "\n".join([
            sections.get("task") or "",
            sections.get("delivery") or "",
            sections.get("extra") or "",
            task["title"] or "",
        ])
        command_hint = ""
        if any(k in task_text_all for k in ["Â∞èËØ¥", "ÂÖ≥ÈîÆËØç", "ÊñáÂåÖ", "Áà¨Âèñ", "ÈááÈõÜ"]):
            command_hint = (
                "\n\nÂèØÁõ¥Êé•ÊâßË°åÁöÑÂèÇËÄÉÂëΩ‰ª§ÔºàÂ¶ÇÈÄÇÈÖçÊú¨‰ªªÂä°ËØ∑‰ºòÂÖà‰ΩøÁî®ÔºâÔºö\n"
                f"cd {WORKDIR} && python3 scripts/xhs_novel_multiagent_pipeline.py "
                "--keywords 'Â∞èËØ¥Êé®Êñá,Â∞èËØ¥Êé®Ëçê,ÁΩëÊñá,Ë®ÄÊÉÖÂ∞èËØ¥,ÊÇ¨ÁñëÂ∞èËØ¥,ÂÆåÁªìÂ∞èËØ¥,‰π¶ËçíÊé®Ëçê,Áï™ËåÑÂ∞èËØ¥,ÁàΩÊñáÂ∞èËØ¥,Êé®ÁêÜÂ∞èËØ¥' "
                "--cookie-file $TASK_INPUT_DIR/xhs_cookies.json "
                "--output-dir $TASK_OUTPUT_DIR --max-rounds 3 --min-usable 8 --min-recent-7d 7 --min-domain-ratio 0.75 --max-noise-ratio 0.35 --pack-format zip"
            )

        contract_text = contract_to_text(acceptance_contract)

        user_prompt = (
            f"‰Ω†ÂΩìÂâçË¥üË¥£Èò∂ÊÆµÔºö{stage}\n"
            f"‰ªªÂä°Ê†áÈ¢òÔºö{task['title']}\n"
            f"‰ªªÂä°ÊèèËø∞Ôºö{sections.get('task') or task['description'] or ''}\n"
            f"ÊúüÊúõ‰∫§‰ªòÔºö{sections.get('delivery') or ''}\n"
            f"Ë°•ÂÖÖËØ¥ÊòéÔºö{sections.get('extra') or ''}\n"
            f"‰∏ä‰∏Ä‰∏™Èò∂ÊÆµËæìÂá∫ÔºàËã•‰∏∫Á©∫ÂèØÂøΩÁï•ÔºâÔºö\n{previous_output}\n\n"
            f"ËøîÂ∑•/‰∫§Êé•ËØ¥ÊòéÔºàËã•‰∏∫Á©∫ÂèØÂøΩÁï•ÔºâÔºö\n{handoff_note}\n\n"
            f"{contract_text}\n\n"
            f"Èò∂ÊÆµËßÑÂàôÔºö{stage_instruction}"
            f"{command_hint}"
        )

        messages = [{"role": "system", "content": sys_prompt}]
        for h in history:
            turn = (h["turn"] or "").strip().lower()
            if turn in ("user", "assistant", "system"):
                messages.append({"role": turn, "content": h["content"] or ""})
        messages.append({"role": "user", "content": user_prompt})

        stage_files_before = list_output_file_names(output_dir)
        stage_started_at = now_str()
        stage_t0 = time.perf_counter()
        save_role_message(task_id, role_code, stage, "user", user_prompt)
        output, tool_events = run_role_stage_with_tools(
            task_id=task_id,
            stage=stage,
            role=role,
            messages=messages,
            base_dir=base_dir,
            input_dir=input_dir,
            output_dir=output_dir,
            max_tool_rounds=ROLE_MAX_TOOL_ROUNDS,
        )
        stage_duration_sec = round(time.perf_counter() - stage_t0, 2)
        stage_files_after = list_output_file_names(output_dir)
        produced_files = sorted(list(stage_files_after - stage_files_before))
        produced_non_system = [x for x in produced_files if not is_system_generated_output(x)]
        existing_non_system = [x for x in sorted(stage_files_after) if not is_system_generated_output(x)]

        execution_no += 1
        stage_file = os.path.join(
            output_dir,
            f"Ê≠•È™§{execution_no}_Èò∂ÊÆµ{stage_idx+1}_{stage}_{role_code.replace('@', 'at_').replace(' ', '_')}.md",
        )
        with open(stage_file, "w", encoding="utf-8") as f:
            f.write(f"# Ê≠•È™§{execution_no}ÔΩúÈò∂ÊÆµ{stage_idx+1}Ôºö{stage}\n\n")
            f.write(f"ËßíËâ≤Ôºö{role['name']}Ôºà{role['code']}Ôºâ\n")
            f.write(f"ËøîÂ∑•ËΩÆÊ¨°Ôºö{rework_round}\n\n")
            f.write(output + "\n")

        stage_audit = {
            "executionNo": execution_no,
            "index": stage_idx + 1,
            "stage": stage,
            "role": role_code,
            "model": role["default_model"],
            "reworkRound": rework_round,
            "startedAt": stage_started_at,
            "durationSec": stage_duration_sec,
            "toolEvents": tool_events,
            "producedFiles": produced_files,
            "producedNonSystemFiles": produced_non_system,
            "existingNonSystemFiles": existing_non_system,
            "outputFile": os.path.basename(stage_file),
            "outputChars": len(output),
            "finishedAt": now_str(),
        }

        # Âä®ÊÄÅÂàÜÂèëÔºöLead Âú®‚ÄúÈúÄÊ±ÇÊé•Êî∂‰∏éÂàÜÂèë‚ÄùÈò∂ÊÆµÂèØÂä®ÊÄÅÊîπÂÜôÂêéÁª≠Èò∂ÊÆµËßíËâ≤ + Èò∂ÊÆµÊøÄÊ¥ªËÆ°Âàí
        if lead_dispatch_mode:
            allowed_following_stages = stages[stage_idx + 1 :]
            plan = parse_dispatch_plan(output, allowed_following_stages, enabled_role_codes)
            dynamic = plan.get("assignments") or {}
            if dynamic:
                stage_roles.update(dynamic)
                audit["dynamicAssignments"].update(dynamic)
                stage_audit["dynamicAssignments"] = dynamic
                append_log(task_id, f"[Lead Agent] Âä®ÊÄÅÂàÜÂèëÁîüÊïàÔºö{json.dumps(dynamic, ensure_ascii=False)}")

            contract_raw = plan.get("acceptance_contract")
            if isinstance(contract_raw, dict):
                acceptance_contract = normalize_acceptance_contract(contract_raw, task["title"] or "", sections)
                audit["acceptanceContract"] = acceptance_contract
                stage_audit["acceptanceContract"] = acceptance_contract
                append_log(task_id, "[Lead Agent] Â∑≤Êõ¥Êñ∞‰ªªÂä°È™åÊî∂Â•ëÁ∫¶ÔºàÂä®ÊÄÅÁîüÊàêÔºâ")

            rounds_raw = plan.get("collision_rounds")
            if isinstance(rounds_raw, int):
                collision_rounds = max(0, min(6, rounds_raw))
                audit["collisionRounds"] = collision_rounds
                stage_audit["collisionRounds"] = collision_rounds
                append_log(task_id, f"[Lead Agent] Â∑≤ËÆæÁΩÆËßíËâ≤Á¢∞ÊíûËΩÆÊ¨°Ôºö{collision_rounds}")

            active_stages = plan.get("active_stages")
            if isinstance(active_stages, list):
                # ÂÆà‰ΩèÊú´Á´ØË¥®Êéß/‰∫§‰ªòÁ±ªÈò∂ÊÆµÔºåÈÅøÂÖçË¢´ËØØË∑≥Ëøá
                safety_stages = [s for s in allowed_following_stages if ("È™åËØÅ" in s or "Â§çÊ†∏" in s or "‰∫§‰ªò" in s)]
                active_final = list(dict.fromkeys(active_stages + safety_stages))

                # Èò≤ÂëÜÔºöËã•LeadÊääÊâÄÊúâÊâßË°åÈò∂ÊÆµÈÉΩË∑≥ËøáÔºåËá™Âä®Ë°•ÂõûËá≥Â∞ë‰∏Ä‰∏™ÊâßË°åÈò∂ÊÆµÔºåÈÅøÂÖç‚ÄúÂè™Â§çÊ†∏‰∏çÊâßË°å‚ÄùÊ≠ªÂæ™ÁéØ
                exec_candidates = [
                    s
                    for s in allowed_following_stages
                    if any(k in s for k in ["ÂâçÁ´Ø", "ÂêéÁ´Ø", "ÊâßË°å", "ÈááÈõÜ", "ÂºÄÂèë", "ÊñáÂåÖ"])
                ]
                if exec_candidates and all(s not in active_final for s in exec_candidates):
                    preferred = None
                    for p in ["ÂêéÁ´ØÂÆûÁé∞", "ÊâßË°å", "ÂºÄÂèë", "ÈááÈõÜ", "ÂâçÁ´ØÂÆûÁé∞"]:
                        if p in exec_candidates:
                            preferred = p
                            break
                    if not preferred:
                        preferred = exec_candidates[0]
                    active_final = list(dict.fromkeys(active_final + [preferred]))
                    stage_audit["autoAddedExecutionStage"] = preferred
                    append_log(task_id, f"[Lead Agent] Ê£ÄÊµãÂà∞ÊâßË°åÈò∂ÊÆµË¢´ÂÖ®ÈÉ®Ë∑≥ËøáÔºåÂ∑≤Ëá™Âä®Ë°•ÂõûÔºö{preferred}")

                active_stage_set = {stages[0], *active_final}
                skipped = [s for s in allowed_following_stages if s not in active_stage_set]
                stage_audit["activeStages"] = active_final
                stage_audit["skippedStages"] = skipped
                append_log(task_id, f"[Lead Agent] Èò∂ÊÆµÊâßË°åËÆ°ÂàíÔºöactive={active_final} | skipped={skipped}")
            elif not dynamic:
                append_log(task_id, "[Lead Agent] Êú™Ëß£ÊûêÂà∞ÊúâÊïàÂä®ÊÄÅÂàÜÂèëJSONÔºåÊ≤øÁî®Â∑•‰ΩúÊµÅÈªòËÆ§ÂàÜÈÖç")

        # Â§öËßíËâ≤Á¢∞ÊíûÔºöÊâßË°åÈò∂ÊÆµÂÖàÂÅö reviewer ÂØπÊäóËØÑÂÆ°ÔºåÂÜçÁî±ÂΩìÂâçËßíËâ≤‰øÆËÆ¢ÔºàÂèØÂ§öËΩÆÔºâ
        if (not verifier_mode) and (not lead_dispatch_mode) and (not lead_acceptance_mode) and collision_rounds > 0:
            reviewer_role, reviewer_code = get_reviewer_role()
            if reviewer_role and int(reviewer_role["enabled"] or 0) == 1:
                output, extra_tools, collision_records = run_stage_collision(
                    task_id=task_id,
                    stage=stage,
                    role=role,
                    reviewer_role=reviewer_role,
                    sections=sections,
                    contract_text=contract_text,
                    previous_output=previous_output,
                    handoff_note=handoff_note,
                    current_output=output,
                    base_dir=base_dir,
                    input_dir=input_dir,
                    output_dir=output_dir,
                    rounds=collision_rounds,
                )
                if extra_tools:
                    tool_events.extend(extra_tools)
                    stage_audit["toolEvents"] = tool_events
                if collision_records:
                    stage_audit["collisionRecords"] = collision_records

                # Á¢∞ÊíûËΩÆÊ¨°ÂêéÈáçÊñ∞ËÆ°ÁÆó‰∫ßÁâ©‰∏éËæìÂá∫ÁªüËÆ°
                stage_files_after = list_output_file_names(output_dir)
                produced_files = sorted(list(stage_files_after - stage_files_before))
                produced_non_system = [x for x in produced_files if not is_system_generated_output(x)]
                existing_non_system = [x for x in sorted(stage_files_after) if not is_system_generated_output(x)]
                stage_audit["producedFiles"] = produced_files
                stage_audit["producedNonSystemFiles"] = produced_non_system
                stage_audit["existingNonSystemFiles"] = existing_non_system
                stage_audit["outputChars"] = len(output)

                with open(stage_file, "w", encoding="utf-8") as f:
                    f.write(f"# Ê≠•È™§{execution_no}ÔΩúÈò∂ÊÆµ{stage_idx+1}Ôºö{stage}\n\n")
                    f.write(f"ËßíËâ≤Ôºö{role['name']}Ôºà{role['code']}Ôºâ\n")
                    f.write(f"ËøîÂ∑•ËΩÆÊ¨°Ôºö{rework_round}\n")
                    f.write(f"ÂØπÊäóËØÑÂÆ°ËΩÆÊ¨°Ôºö{len(collision_records)}\n\n")
                    f.write(output + "\n")

        # ÊØè‰∏™ÊâßË°åËßíËâ≤ÂÆåÊàêÂêéÈÉΩÂÅöÈò∂ÊÆµË¥®ÊéßÔºàÁî± reviewer Â§çÊ†∏Ôºâ
        if (not verifier_mode) and (not lead_dispatch_mode) and (not lead_acceptance_mode):
            auto_fail_reason = ""
            if tool_events and all(int(e.get("rc", 1)) != 0 for e in tool_events):
                auto_fail_reason = "ÊâßË°å‰∫ÜÂ∑•ÂÖ∑ÂëΩ‰ª§‰ΩÜÂÖ®ÈÉ®Â§±Ë¥•ÔºàrcÈùû0ÔºâÔºåËØ∑ÂÖà‰øÆÂ§çÂëΩ‰ª§/ÁéØÂ¢ÉÂêéÂÜçÊèê‰∫§„ÄÇ"

            needs_artifacts = task_requires_real_artifacts(task_text_all)
            if (not auto_fail_reason) and needs_artifacts and (stage in ["ÊâßË°å", "ÈááÈõÜ", "ÂºÄÂèë", "ÊñáÂåÖ", "‰∫§‰ªò", "ËÅîÂêà‰∫§‰ªò"]) and len(existing_non_system) == 0:
                auto_fail_reason = "‰ªªÂä°Ë¶ÅÊ±ÇÂåÖÂê´ÂèØÈ™åÊî∂‰∫ßÁâ©ÔºàÁà¨Âèñ/ÂÖ≥ÈîÆËØç/ÊñáÂåÖÁ≠âÔºâÔºå‰ΩÜÂΩìÂâçËæìÂá∫ÁõÆÂΩïÊó†ÂèØÈ™åÊî∂ÁúüÂÆûÊñá‰ª∂„ÄÇ"

            quality = None
            review_output = ""
            if auto_fail_reason:
                quality = {
                    "decision": "FAIL",
                    "reason": auto_fail_reason,
                    "issues": ["Áº∫Â∞ëÁúüÂÆû‰∫ßÁâ©Êñá‰ª∂ÊàñÂ∑•ÂÖ∑ÊâßË°åÂ§±Ë¥•"],
                    "send_back_role": role_code,
                    "rework_instructions": "ËØ∑ÈÄöËøá run_command ÁúüÂÆûÊâßË°åÂπ∂‰∫ßÂá∫Êñá‰ª∂Âà∞ $TASK_OUTPUT_DIRÔºåÂÜçÊèê‰∫§ final„ÄÇ",
                }
                stage_audit["qualityGate"] = {"raw": "", "decision": quality, "autoRule": "artifact_or_tool_guard"}
                append_log(task_id, f"[reviewer] Èò∂ÊÆµË¥®ÊéßÁªìËÆ∫ÔºöFAIL | stage={stage} | reason={auto_fail_reason}")
            else:
                reviewer_role, reviewer_code = get_reviewer_role()
                if reviewer_role and int(reviewer_role["enabled"] or 0) == 1:
                    review_stage = f"{stage}-Èò∂ÊÆµË¥®Êéß"
                    review_prompt = (
                        "‰Ω†ÊòØÈò∂ÊÆµË¥®ÊéßÂ§çÊ†∏„ÄÇËØ∑Âè™ÂØπÂΩìÂâçÈò∂ÊÆµËæìÂá∫ËøõË°åÈ™åÊî∂Ôºå‰∏çË¶ÅÈáçÂÜôÂÆûÁé∞„ÄÇ"
                        f"ÂΩìÂâçÈò∂ÊÆµÔºö{stage}ÔºåÊâßË°åËßíËâ≤Ôºö{role_code}„ÄÇ\n"
                        f"‰ªªÂä°ÁõÆÊ†áÔºö{sections.get('task') or task['description'] or ''}\n"
                        f"ÊúüÊúõ‰∫§‰ªòÔºö{sections.get('delivery') or ''}\n"
                        f"{contract_text}\n"
                        f"Êú¨Èò∂ÊÆµËæìÂá∫Ôºö\n{output}\n\n"
                        f"Êú¨Èò∂ÊÆµÊñ∞Â¢û‰∫ßÂá∫ÔºàÈùûÁ≥ªÁªüÁîüÊàêÔºâÔºö{produced_non_system}\n"
                        f"ÂΩìÂâçÂèØÈ™åÊî∂‰∫ßÁâ©ÔºàÈùûÁ≥ªÁªüÁîüÊàêÔºâÔºö{existing_non_system}\n"
                        "Ê≥®ÊÑèÔºö‰∏çË¶ÅÊääÂõ∫ÂÆöÊñá‰ª∂ÂêçÂΩìÊàêÁ°¨Á∫¶ÊùüÔºåÊåâÈ™åÊî∂Â•ëÁ∫¶Âà§Êñ≠ÊòØÂê¶Êª°Ë∂≥‰ªªÂä°„ÄÇ"
                        "ËØ∑ËøîÂõû JSONÔºö"
                        '{"decision":"PASS|FAIL","reason":"...","issues":["..."],"send_back_role":"ÂΩìÂâçËßíËâ≤code","rework_instructions":"..."}'
                        "„ÄÇËã• FAILÔºåsend_back_role ‰ºòÂÖàÂ°´ÂΩìÂâçËßíËâ≤„ÄÇ"
                    )
                    review_msgs = [
                        {
                            "role": "system",
                            "content": (reviewer_role["system_prompt"] or "‰Ω†ÊòØ‰∏•Ê†ºË¥®ÊéßÂ§çÊ†∏ËßíËâ≤„ÄÇ"),
                        },
                        {"role": "user", "content": review_prompt},
                    ]
                    save_role_message(task_id, reviewer_code, review_stage, "user", review_prompt)
                    review_output = call_role_llm(reviewer_role, review_msgs)
                    save_role_message(task_id, reviewer_code, review_stage, "assistant", review_output)
                    quality = parse_verifier_feedback(review_output)
                    stage_audit["qualityGate"] = {"raw": review_output, "decision": quality}

                    q_dec = quality.get("decision", "UNKNOWN")
                    append_log(task_id, f"[{reviewer_code}] Èò∂ÊÆµË¥®ÊéßÁªìËÆ∫Ôºö{q_dec} | stage={stage} | reason={quality.get('reason','')[:120]}")
                else:
                    quality = {"decision": "SKIP", "reason": "reviewer‰∏çÂèØÁî®ÔºåË∑≥ËøáÈò∂ÊÆµË¥®Êéß"}
                    stage_audit["qualityGate"] = {"decision": quality}

            q_dec = (quality or {}).get("decision", "UNKNOWN")
            if q_dec != "PASS" and q_dec != "SKIP":
                if stage_retry >= max_stage_review_retries:
                    stage_audit["terminatedByStageReview"] = True
                    audit["stages"].append(stage_audit)
                    raise RuntimeError(f"Èò∂ÊÆµ {stage} Ë¥®ÊéßÊú™ÈÄöËøáÔºå‰∏îÂ∑≤ËææÊú¨Èò∂ÊÆµÊúÄÂ§ßÈáçËØï {max_stage_review_retries}")

                stage_retry_counts[stage] = stage_retry + 1
                handoff_note = (
                    f"Èò∂ÊÆµË¥®ÊéßÊú™ÈÄöËøáÔºà{stage}ÔºåÁ¨¨{stage_retry_counts[stage]}Ê¨°ÈáçËØïÔºâ„ÄÇ"
                    f"ÂéüÂõ†Ôºö{(quality or {}).get('reason','')}„ÄÇ"
                    f"ÈóÆÈ¢òÔºö{'Ôºõ'.join((quality or {}).get('issues') or [])}„ÄÇ"
                    f"‰øÆÊîπË¶ÅÊ±ÇÔºö{(quality or {}).get('rework_instructions','ËØ∑Ê†πÊçÆË¥®ÊéßÊÑèËßÅ‰øÆÊîπÂêéÈáçÊñ∞Êèê‰∫§Êú¨Èò∂ÊÆµ„ÄÇ')}"
                )
                append_log(
                    task_id,
                    f"[Lead Agent] Èò∂ÊÆµË¥®ÊéßÊú™ÈÄöËøáÔºåÊâìÂõûÂΩìÂâçÈò∂ÊÆµÈáçÂÅöÔºö{stage}Ôºà{stage_retry_counts[stage]}/{max_stage_review_retries}Ôºâ",
                )
                previous_output = output
                audit["stages"].append(stage_audit)
                continue
            else:
                stage_retry_counts[stage] = 0

        # Â∑•‰ΩúÊµÅ‰∏≠ÁöÑ‚ÄúÈ™åËØÅ/Â§çÊ†∏‚ÄùÊ≠£ÂºèÈò∂ÊÆµÔºöÂèØËß¶ÂèëË∑®Èò∂ÊÆµÊâìÂõû
        if verifier_mode:
            decision = parse_verifier_feedback(output)
            stage_audit["reviewDecision"] = decision
            dec = decision.get("decision", "UNKNOWN")
            append_log(task_id, f"[{role_code}] Â§çÊ†∏ÁªìËÆ∫Ôºö{dec} | reason={decision.get('reason','')[:120]}")

            if dec != "PASS":
                if rework_round >= max_rework_rounds:
                    stage_audit["terminatedByMaxRework"] = True
                    audit["stages"].append(stage_audit)
                    audit["reworkRoundsUsed"] = rework_round
                    raise RuntimeError(f"Â§çÊ†∏Êú™ÈÄöËøáÔºåÂ∑≤ËææÊúÄÂ§ßËøîÂ∑•ËΩÆÊ¨° {max_rework_rounds}Ôºå‰ªªÂä°ÁªàÊ≠¢")

                target_role = (decision.get("send_back_role") or "").strip()
                target_idx = find_stage_index_by_role(stages, stage_roles, target_role, stage_idx, fallback_idx=max(0, stage_idx - 1))
                rework_round += 1
                audit["reworkRoundsUsed"] = rework_round
                handoff_note = (
                    f"Â§çÊ†∏‰∏çÈÄöËøáÔºàÁ¨¨{rework_round}ËΩÆËøîÂ∑•Ôºâ„ÄÇ"
                    f"ÂéüÂõ†Ôºö{decision.get('reason','')}„ÄÇ"
                    f"ÈóÆÈ¢òÔºö{'Ôºõ'.join(decision.get('issues') or [])}„ÄÇ"
                    f"‰øÆÊîπË¶ÅÊ±ÇÔºö{decision.get('rework_instructions','ËØ∑Ê†πÊçÆÂ§çÊ†∏ÊÑèËßÅ‰øÆÊîπÂêéÊèê‰∫§„ÄÇ')}"
                )
                append_log(
                    task_id,
                    f"[Lead Agent] Â§çÊ†∏Êú™ÈÄöËøáÔºåÊâìÂõûÂà∞Èò∂ÊÆµ{target_idx+1}Ôºà{stages[target_idx]}ÔºâÔºåËøîÂ∑•ËΩÆÊ¨°={rework_round}/{max_rework_rounds}",
                )
                previous_output = output
                audit["stages"].append(stage_audit)
                stage_idx = target_idx
                continue

        # Lead ÊúÄÁªàÈ™åÊî∂Èò∂ÊÆµÔºöLead ‰πüÊúâÊâìÂõûÊùÉÈôê
        if lead_acceptance_mode:
            decision = parse_verifier_feedback(output)
            lead_acceptance_result = decision
            stage_audit["leadAcceptance"] = decision
            dec = decision.get("decision", "UNKNOWN")
            append_log(task_id, f"[Lead Agent] È™åÊî∂ÁªìËÆ∫Ôºö{dec} | reason={decision.get('reason','')[:120]}")

            if dec != "PASS":
                if rework_round >= max_rework_rounds:
                    stage_audit["terminatedByMaxRework"] = True
                    audit["stages"].append(stage_audit)
                    audit["reworkRoundsUsed"] = rework_round
                    raise RuntimeError(f"LeadÈ™åÊî∂Êú™ÈÄöËøáÔºåÂ∑≤ËææÊúÄÂ§ßËøîÂ∑•ËΩÆÊ¨° {max_rework_rounds}Ôºå‰ªªÂä°ÁªàÊ≠¢")

                target_role = (decision.get("send_back_role") or "").strip()
                target_idx = find_stage_index_by_role(stages, stage_roles, target_role, stage_idx, fallback_idx=max(0, stage_idx - 1))
                rework_round += 1
                audit["reworkRoundsUsed"] = rework_round
                handoff_note = (
                    f"LeadÈ™åÊî∂‰∏çÈÄöËøáÔºàÁ¨¨{rework_round}ËΩÆËøîÂ∑•Ôºâ„ÄÇ"
                    f"ÂéüÂõ†Ôºö{decision.get('reason','')}„ÄÇ"
                    f"ÈóÆÈ¢òÔºö{'Ôºõ'.join(decision.get('issues') or [])}„ÄÇ"
                    f"‰øÆÊîπË¶ÅÊ±ÇÔºö{decision.get('rework_instructions','ËØ∑Ê†πÊçÆLeadÈ™åÊî∂ÊÑèËßÅ‰øÆÊîπÂêéÊèê‰∫§„ÄÇ')}"
                )
                append_log(
                    task_id,
                    f"[Lead Agent] È™åÊî∂Êú™ÈÄöËøáÔºåÊâìÂõûÂà∞Èò∂ÊÆµ{target_idx+1}Ôºà{stages[target_idx]}ÔºâÔºåËøîÂ∑•ËΩÆÊ¨°={rework_round}/{max_rework_rounds}",
                )
                previous_output = output
                audit["stages"].append(stage_audit)
                stage_idx = target_idx
                continue

        if (not verifier_mode) and (not lead_dispatch_mode) and (not lead_acceptance_mode):
            last_execution_output = output
            last_execution_stage = stage
            last_execution_role = role_code

        previous_output = output
        handoff_note = ""
        audit["stages"].append(stage_audit)
        append_log(task_id, f"[{role_code}] Èò∂ÊÆµÂÆåÊàêÔºåËæìÂá∫ÈïøÂ∫¶={len(output)}ÔºåËÄóÊó∂={stage_duration_sec}s")
        stage_idx += 1

    final_non_system_files = [x for x in sorted(list_output_file_names(output_dir)) if not is_system_generated_output(x)]
    final_body = previous_output

    if lead_acceptance_result and (lead_acceptance_result.get("decision") == "PASS") and last_execution_output:
        reason = lead_acceptance_result.get("reason") or "ÈÄöËøáÊúÄÁªàÈ™åÊî∂„ÄÇ"
        issues = lead_acceptance_result.get("issues") or []
        final_body = (
            "## Lead ÊúÄÁªàÈ™åÊî∂\n"
            f"- ÁªìËÆ∫ÔºöPASS\n"
            f"- ÂéüÂõ†Ôºö{reason}\n"
            + (f"- Ê≥®ÊÑè‰∫ãÈ°πÔºö{'Ôºõ'.join(issues)}\n" if issues else "")
            + "\n## Ê†∏ÂøÉ‰∫§‰ªòÊ≠£Êñá\n"
            f"ÔºàÊù•Ê∫êÔºöÈò∂ÊÆµ„Äê{last_execution_stage}„ÄëËßíËâ≤„Äê{last_execution_role}„ÄëÔºâ\n\n"
            f"{last_execution_output}\n"
        )

    final_file = os.path.join(output_dir, "Â§öAgent_ÊúÄÁªà‰∫§‰ªò.md")
    with open(final_file, "w", encoding="utf-8") as f:
        f.write(f"# Â§öAgentÊúÄÁªà‰∫§‰ªò\n\n‰ªªÂä°Ôºö{task['title']}\n\n")
        if final_non_system_files:
            f.write("## ÂèØÈ™åÊî∂‰∫ßÁâ©Ê∏ÖÂçï\n")
            for fn in final_non_system_files:
                f.write(f"- {fn}\n")
            f.write("\n")
        f.write(final_body + "\n")

    audit["finishedAt"] = now_str()
    audit["finalFile"] = os.path.basename(final_file)
    audit_file = os.path.join(output_dir, "Â§öAgent_‰ºöËØùÂÆ°ËÆ°.json")
    with open(audit_file, "w", encoding="utf-8") as f:
        json.dump(audit, f, ensure_ascii=False, indent=2)

    append_log(task_id, f"[Lead Agent] Â§öAgentÁã¨Á´ã‰ºöËØùÂÆåÊàêÔºåÊúÄÁªà‰∫§‰ªòÔºö{os.path.basename(final_file)}")


def login_required(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        if not session.get("logged_in"):
            return redirect(url_for("login"))
        return fn(*args, **kwargs)

    return wrapper


@app.errorhandler(413)
def payload_too_large(_):
    flash("‰∏ä‰º†Êñá‰ª∂ËøáÂ§ßÔºàÂçïÊ¨°ËØ∑Ê±Ç‰∏äÈôê 200MBÔºâÔºåËØ∑ÂéãÁº©ÂêéÈáçËØï„ÄÇ")
    return redirect(url_for("dashboard")), 413


def run_task(task_id: int):
    task = get_task(task_id)
    if not task:
        running_processes.pop(task_id, None)
        task_run_context.pop(task_id, None)
        return

    with limiter.acquire():
        update_task(task_id, status="running", started_at=now_str(), return_code=None)
        base_dir, input_dir, output_dir = task_artifact_dirs(task_id)

        run_id = build_task_run_id(task_id)
        task_run_context[task_id] = run_id

        removed_outputs = clear_dir_contents(output_dir)
        cleared_msgs = clear_role_session_messages(task_id)

        append_log(task_id, f"[SYSTEM] Êú¨Ê¨°ËøêË°åID: {run_id}")
        append_log(task_id, f"[SYSTEM] ‰ªªÂä°ÂêØÂä®ÔºåÂΩìÂâçÂπ∂Âèë‰∏äÈôê={limiter.get_limit()}")
        append_log(task_id, f"[SYSTEM] ‰ªªÂä°‰∫ßÁâ©ÁõÆÂΩï: {base_dir}")
        append_log(task_id, f"[SYSTEM] ËæìÂÖ•ÈôÑ‰ª∂ÁõÆÂΩï: {input_dir}")
        append_log(task_id, f"[SYSTEM] ËæìÂá∫‰∫ßÁâ©ÁõÆÂΩï: {output_dir}")
        append_log(task_id, f"[SYSTEM] Â∑≤Ê∏ÖÁêÜ‰∏ä‰∏ÄËΩÆËæìÂá∫Êñá‰ª∂: {removed_outputs} È°π")
        if cleared_msgs > 0:
            append_log(task_id, f"[SYSTEM] Â∑≤Ê∏ÖÁêÜ‰∏ä‰∏ÄËΩÆËßíËâ≤‰ºöËØùÊ∂àÊÅØ: {cleared_msgs} Êù°")

        cmd = (task["command"] or "").strip()
        if not cmd:
            wf_code = (task["workflow_code"] or "").strip() if "workflow_code" in task.keys() else ""
            if wf_code:
                try:
                    wf = get_workflow_by_code(wf_code)
                    if not wf:
                        raise RuntimeError(f"Êú™ÊâæÂà∞Â∑•‰ΩúÊµÅ: {wf_code}")
                    append_log(task_id, f"[SYSTEM] ÂêØÂä®Â§öAgentÁã¨Á´ã‰ºöËØùÊµÅÁ®ãÔºö{wf_code}")
                    run_multi_agent_workflow(task_id, task, wf, base_dir, input_dir, output_dir)
                    update_task(task_id, status="done", finished_at=now_str(), return_code=0)
                    append_log(task_id, "[SYSTEM] ‰ªªÂä°ÂÆåÊàêÔºàÂ§öAgentÁã¨Á´ã‰ºöËØùÔºâ")
                except Exception as e:
                    update_task(task_id, status="failed", finished_at=now_str(), return_code=1)
                    append_log(task_id, f"[SYSTEM] Â§öAgentÊµÅÁ®ãÂ§±Ë¥•Ôºö{e}")
                finally:
                    running_processes.pop(task_id, None)
                    task_run_context.pop(task_id, None)
                return

            # Êó†Â∑•‰ΩúÊµÅÊó∂‰øùÁïôÊºîÁ§∫ÊµÅÁ®ã
            try:
                for step in [
                    "Lead Agent Ê≠£Âú®ÊãÜËß£‰ªªÂä°...",
                    "Developer Agent Ê≠£Âú®ÊâßË°å‰ªªÂä°...",
                    "Tester Agent Ê≠£Âú®Â§çÊ†∏ÁªìÊûú...",
                    "Verifier Agent Ê≠£Âú®ÂÅöÊúÄÁªàÊ†∏È™å...",
                    "Lead Agent Ê≠£Âú®Ê±áÊÄª‰∫§‰ªò...",
                ]:
                    ensure_not_stopped(task_id)
                    append_log(task_id, step)
                    time.sleep(2)
                update_task(task_id, status="done", finished_at=now_str(), return_code=0)
                append_log(task_id, "[SYSTEM] ‰ªªÂä°ÂÆåÊàêÔºàÊºîÁ§∫Ê®°ÂºèÔºâ")
            except Exception as e:
                update_task(task_id, status="failed", finished_at=now_str(), return_code=1)
                append_log(task_id, f"[SYSTEM] ‰ªªÂä°Â§±Ë¥•Ôºö{e}")
            finally:
                running_processes.pop(task_id, None)
                task_run_context.pop(task_id, None)
            return

        try:
            append_log(task_id, f"[SYSTEM] ÊâßË°åÂëΩ‰ª§: {cmd}")
            env = os.environ.copy()
            env.update(
                {
                    "TASK_ID": str(task_id),
                    "TASK_RUN_ID": run_id,
                    "TASK_ARTIFACT_DIR": base_dir,
                    "TASK_INPUT_DIR": input_dir,
                    "TASK_OUTPUT_DIR": output_dir,
                }
            )
            proc = subprocess.Popen(
                cmd,
                shell=True,
                cwd=WORKDIR,
                executable="/bin/bash",
                env=env,
                start_new_session=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
            )
            running_processes[task_id] = proc

            for line in iter(proc.stdout.readline, ""):
                if not line:
                    break
                append_log(task_id, line.rstrip())

            rc = proc.wait()
            update_task(
                task_id,
                status="done" if rc == 0 else "failed",
                finished_at=now_str(),
                return_code=rc,
            )
            append_log(task_id, f"[SYSTEM] ‰ªªÂä°ÁªìÊùüÔºårc={rc}")
        except Exception as e:
            update_task(task_id, status="failed", finished_at=now_str(), return_code=1)
            append_log(task_id, f"[SYSTEM] ÊâßË°åÂºÇÂ∏∏Ôºö{e}")
        finally:
            running_processes.pop(task_id, None)
            task_run_context.pop(task_id, None)


def start_task(task_id: int):
    if task_id in running_processes:
        return False, "‰ªªÂä°Â∑≤Âú®ËøêË°åÊàñÊéíÈòü‰∏≠"
    task = get_task(task_id)
    if not task:
        return False, "‰ªªÂä°‰∏çÂ≠òÂú®"
    if task["status"] == "running":
        return False, "‰ªªÂä°Áä∂ÊÄÅÂ∑≤ÊòØ running"

    running_processes[task_id] = None
    t = threading.Thread(target=run_task, args=(task_id,), daemon=True)
    t.start()
    return True, "Â∑≤ÂêØÂä®ÔºàÂ¶ÇÂπ∂ÂèëÂ∑≤Êª°‰ºöËá™Âä®ÊéíÈòüÔºâ"


@app.before_request
def _attach_globals():
    g.max_concurrent = limiter.get_limit()
    g.active_workers = limiter.get_running()
    g.artifact_root = ARTIFACT_ROOT
    g.workdir = WORKDIR


@app.route("/healthz")
def healthz():
    return {
        "ok": True,
        "time": now_str(),
        "maxConcurrent": limiter.get_limit(),
        "activeWorkers": limiter.get_running(),
    }


@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = request.form.get("username", "")
        password = request.form.get("password", "")
        if username == ADMIN_USERNAME and password == ADMIN_PASSWORD:
            session["logged_in"] = True
            session["username"] = username
            return redirect(url_for("dashboard"))
        flash("Ë¥¶Âè∑ÊàñÂØÜÁ†ÅÈîôËØØ")
    return render_template("login.html")


@app.route("/logout")
def logout():
    session.clear()
    return redirect(url_for("login"))


@app.route("/")
@login_required
def dashboard():
    with db_conn() as conn:
        tasks = conn.execute(
            "SELECT * FROM tasks ORDER BY CASE status WHEN 'running' THEN 0 WHEN 'pending' THEN 1 ELSE 2 END, id DESC"
        ).fetchall()

        stats = {
            "pending": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='pending'").fetchone()["c"],
            "running": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='running'").fetchone()["c"],
            "done": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='done'").fetchone()["c"],
            "failed": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='failed'").fetchone()["c"],
        }

    phase_order = ["ÂæÖÂ§ÑÁêÜ", "ÊâßË°å‰∏≠", "ÂæÖÁ°ÆËÆ§"]
    tasks_by_phase = {k: [] for k in phase_order}
    for t in tasks:
        phase = infer_business_phase(t)
        tasks_by_phase.setdefault(phase, []).append(t)

    roles = get_roles(enabled_only=False)
    workflows = get_workflows(enabled_only=False)

    queue_count = max(0, len(running_processes) - limiter.get_running())
    return render_template(
        "dashboard.html",
        tasks=tasks,
        stats=stats,
        tasks_by_phase=tasks_by_phase,
        phase_order=phase_order,
        roles=roles,
        workflows=workflows,
        running_count=len(running_processes),
        queue_count=queue_count,
    )


@app.route("/artifacts")
@login_required
def artifacts_page():
    files = list_artifacts()
    return render_template("artifacts.html", files=files, artifact_root=ARTIFACT_ROOT)


@app.route("/artifacts/download/<path:rel_path>")
@login_required
def artifacts_download(rel_path: str):
    safe_full = safe_join_under(ARTIFACT_ROOT, rel_path)
    if not safe_full:
        abort(400)
    if not os.path.isfile(safe_full):
        abort(404)
    return send_from_directory(ARTIFACT_ROOT, rel_path, as_attachment=True)


@app.post("/artifacts/clear")
@login_required
def artifacts_clear_note():
    flash("ÂΩìÂâçÁâàÊú¨‰∏∫ÂÆâÂÖ®Ëµ∑ËßÅÊú™ÂºÄÊîæÁΩëÈ°µÂà†Èô§Êñá‰ª∂ÔºõËØ∑Âú®ÊúçÂä°Âô®‰∏äÊâãÂä®Ê∏ÖÁêÜ‰∫ßÁâ©ÁõÆÂΩï„ÄÇ")
    return redirect(url_for("artifacts_page"))


@app.post("/settings/concurrency")
@login_required
def set_concurrency():
    raw = (request.form.get("max_concurrent") or "").strip()
    try:
        val = int(raw)
    except Exception:
        flash("Âπ∂Âèë‰∏äÈôêÂøÖÈ°ªÊòØÊï∞Â≠óÔºà1-16Ôºâ")
        return redirect(url_for("dashboard"))

    if val < 1 or val > 16:
        flash("Âπ∂Âèë‰∏äÈôêËåÉÂõ¥ÂøÖÈ°ªÂú® 1-16")
        return redirect(url_for("dashboard"))

    set_setting("max_concurrent", str(val))
    limiter.set_limit(val)
    flash(f"Âπ∂Âèë‰∏äÈôêÂ∑≤Êõ¥Êñ∞‰∏∫ {val}ÔºàÂç≥Êó∂ÁîüÊïàÔºåÊó†ÈúÄÈáçÂêØÔºâ")
    return redirect(url_for("dashboard"))


@app.post("/roles")
@login_required
def create_role():
    code = (request.form.get("code") or "").strip()
    name = (request.form.get("name") or "").strip()
    description = (request.form.get("description") or "").strip()
    default_model = (request.form.get("default_model") or "").strip() or "gpt-5.3-codex"
    api_base = (request.form.get("api_base") or "").strip()
    api_key = (request.form.get("api_key") or "").strip()
    system_prompt = (request.form.get("system_prompt") or "").strip()
    enabled = 1 if (request.form.get("enabled") or "1") == "1" else 0

    if not code or not name:
        flash("ËßíËâ≤ÂàõÂª∫Â§±Ë¥•Ôºöcode Âíå name ‰∏çËÉΩ‰∏∫Á©∫")
        return redirect(url_for("dashboard"))

    try:
        with db_conn() as conn:
            conn.execute(
                """
                INSERT INTO roles(code, name, description, default_model, api_base, api_key, system_prompt, enabled, created_at, updated_at)
                VALUES(?,?,?,?,?,?,?,?,?,?)
                """,
                (code, name, description, default_model, api_base, api_key, system_prompt, enabled, now_str(), now_str()),
            )
        flash(f"ËßíËâ≤Â∑≤ÂàõÂª∫Ôºö{name}Ôºà{code}Ôºâ")
    except sqlite3.IntegrityError:
        flash("ËßíËâ≤ÂàõÂª∫Â§±Ë¥•Ôºöcode Â∑≤Â≠òÂú®")
    except Exception as e:
        flash(f"ËßíËâ≤ÂàõÂª∫Â§±Ë¥•Ôºö{e}")

    return redirect(url_for("dashboard"))


@app.post("/roles/<int:role_id>/toggle")
@login_required
def toggle_role(role_id: int):
    with db_conn() as conn:
        row = conn.execute("SELECT enabled, name FROM roles WHERE id=?", (role_id,)).fetchone()
        if not row:
            flash("ËßíËâ≤‰∏çÂ≠òÂú®")
            return redirect(url_for("dashboard"))
        nxt = 0 if int(row["enabled"] or 0) == 1 else 1
        conn.execute("UPDATE roles SET enabled=?, updated_at=? WHERE id=?", (nxt, now_str(), role_id))
    flash(f"ËßíËâ≤Â∑≤{'ÂêØÁî®' if nxt == 1 else 'ÂÅúÁî®'}Ôºö{row['name']}")
    return redirect(url_for("dashboard"))


@app.post("/roles/<int:role_id>/config")
@login_required
def update_role_config(role_id: int):
    default_model = (request.form.get("default_model") or "").strip()
    api_base = (request.form.get("api_base") or "").strip()
    api_key = (request.form.get("api_key") or "").strip()
    system_prompt = (request.form.get("system_prompt") or "").strip()
    temperature = (request.form.get("temperature") or "").strip()
    max_tokens = (request.form.get("max_tokens") or "").strip()

    with db_conn() as conn:
        row = conn.execute("SELECT * FROM roles WHERE id=?", (role_id,)).fetchone()
        if not row:
            flash("ËßíËâ≤‰∏çÂ≠òÂú®")
            return redirect(url_for("dashboard"))

        fields = {
            "default_model": default_model or row["default_model"],
            "api_base": api_base or row["api_base"],
            "system_prompt": system_prompt if system_prompt else (row["system_prompt"] or ""),
            "updated_at": now_str(),
        }

        # api_key ‰∏∫Á©∫Êó∂‰øùÊåÅÂéüÂÄº
        fields["api_key"] = api_key if api_key else (row["api_key"] or "")

        try:
            fields["temperature"] = float(temperature) if temperature else (row["temperature"] if row["temperature"] is not None else 0.3)
        except Exception:
            fields["temperature"] = row["temperature"] if row["temperature"] is not None else 0.3

        try:
            fields["max_tokens"] = int(max_tokens) if max_tokens else (row["max_tokens"] if row["max_tokens"] is not None else 1200)
        except Exception:
            fields["max_tokens"] = row["max_tokens"] if row["max_tokens"] is not None else 1200

        conn.execute(
            """
            UPDATE roles
            SET default_model=?, api_base=?, api_key=?, system_prompt=?, temperature=?, max_tokens=?, updated_at=?
            WHERE id=?
            """,
            (
                fields["default_model"],
                fields["api_base"],
                fields["api_key"],
                fields["system_prompt"],
                fields["temperature"],
                fields["max_tokens"],
                fields["updated_at"],
                role_id,
            ),
        )

    flash(f"ËßíËâ≤ÈÖçÁΩÆÂ∑≤Êõ¥Êñ∞Ôºö{row['name']}")
    return redirect(url_for("dashboard"))


@app.post("/workflows")
@login_required
def create_workflow():
    code = (request.form.get("code") or "").strip()
    name = (request.form.get("name") or "").strip()
    description = (request.form.get("description") or "").strip()
    stages_text = (request.form.get("stages") or "").strip()
    stage_roles_text = (request.form.get("stage_roles") or "").strip()
    default_task_type = (request.form.get("default_task_type") or "general").strip()
    default_assignee = (request.form.get("default_assignee") or "Lead Agent").strip()
    command_template = (request.form.get("command_template") or "").strip()
    enabled = 1 if (request.form.get("enabled") or "1") == "1" else 0

    if not code or not name:
        flash("Â∑•‰ΩúÊµÅÂàõÂª∫Â§±Ë¥•Ôºöcode Âíå name ‰∏çËÉΩ‰∏∫Á©∫")
        return redirect(url_for("dashboard"))

    stages = [x.strip() for x in re.split(r"[,Ôºå\n]+", stages_text) if x.strip()]
    stage_roles = parse_stage_roles(stage_roles_text)
    stages_json = json.dumps(stages, ensure_ascii=False)
    stage_roles_json = json.dumps(stage_roles, ensure_ascii=False)

    try:
        with db_conn() as conn:
            conn.execute(
                """
                INSERT INTO workflows(code, name, description, stages_json, stage_roles_json, default_task_type, default_assignee, command_template, enabled, created_at, updated_at)
                VALUES(?,?,?,?,?,?,?,?,?,?,?)
                """,
                (
                    code,
                    name,
                    description,
                    stages_json,
                    stage_roles_json,
                    default_task_type,
                    default_assignee,
                    command_template,
                    enabled,
                    now_str(),
                    now_str(),
                ),
            )
        flash(f"Â∑•‰ΩúÊµÅÂ∑≤ÂàõÂª∫Ôºö{name}Ôºà{code}Ôºâ")
    except sqlite3.IntegrityError:
        flash("Â∑•‰ΩúÊµÅÂàõÂª∫Â§±Ë¥•Ôºöcode Â∑≤Â≠òÂú®")
    except Exception as e:
        flash(f"Â∑•‰ΩúÊµÅÂàõÂª∫Â§±Ë¥•Ôºö{e}")

    return redirect(url_for("dashboard"))


@app.post("/workflows/<int:workflow_id>/toggle")
@login_required
def toggle_workflow(workflow_id: int):
    with db_conn() as conn:
        row = conn.execute("SELECT enabled, name FROM workflows WHERE id=?", (workflow_id,)).fetchone()
        if not row:
            flash("Â∑•‰ΩúÊµÅ‰∏çÂ≠òÂú®")
            return redirect(url_for("dashboard"))
        nxt = 0 if int(row["enabled"] or 0) == 1 else 1
        conn.execute("UPDATE workflows SET enabled=?, updated_at=? WHERE id=?", (nxt, now_str(), workflow_id))
    flash(f"Â∑•‰ΩúÊµÅÂ∑≤{'ÂêØÁî®' if nxt == 1 else 'ÂÅúÁî®'}Ôºö{row['name']}")
    return redirect(url_for("dashboard"))


def derive_title(title_raw: str, brief: str, template_name: str) -> str:
    title = (title_raw or "").strip()
    if title:
        return title
    brief_line = re.sub(r"\s+", " ", (brief or "").strip())
    if brief_line:
        return (brief_line[:36] + "...") if len(brief_line) > 36 else brief_line
    mapping = {
        "intelligent_dual": "Êô∫ËÉΩ‰∏âËßíËâ≤‰ªªÂä°",
        "novel_multiagent": "Â∞èËØ¥Á±ªÁõÆÁàÜÊ¨æÊñáÂåÖ‰ªªÂä°",
        "xhs_virtual_keywords": "Â∞èÁ∫¢‰π¶È´òÈ¢ëËØç‰ªªÂä°",
        "custom_brief": "Âè£ËØ≠Âåñ‰ªªÂä°",
    }
    return mapping.get(template_name, "Êñ∞‰ªªÂä°")


def build_command_from_template(template_name: str, project_dir: str, task_brief: str) -> str:
    workdir = (project_dir or WORKDIR).strip() or WORKDIR

    if template_name == "novel_multiagent":
        keywords = "Â∞èËØ¥Êé®Êñá,Â∞èËØ¥Êé®Ëçê,ÁΩëÊñá,Ë®ÄÊÉÖÂ∞èËØ¥,ÊÇ¨ÁñëÂ∞èËØ¥,ÂÆåÁªìÂ∞èËØ¥,‰π¶ËçíÊé®Ëçê,Áï™ËåÑÂ∞èËØ¥,ÁàΩÊñáÂ∞èËØ¥,Êé®ÁêÜÂ∞èËØ¥"
        if "Â∞èÁ∫¢‰π¶" not in task_brief and "Â∞èËØ¥" in task_brief:
            keywords = "Â∞èËØ¥Êé®Ëçê,ÁΩëÊñáÊé®Ëçê,Ë®ÄÊÉÖÂ∞èËØ¥,ÊÇ¨ÁñëÂ∞èËØ¥,Êé®ÁêÜÂ∞èËØ¥,‰π¶ËçíÊé®Ëçê,ÂÆåÁªìÂ∞èËØ¥"
        return (
            f"cd {workdir} && python3 scripts/xhs_novel_multiagent_pipeline.py "
            f"--keywords '{keywords}' "
            "--cookie-file $TASK_INPUT_DIR/xhs_cookies.json "
            "--output-dir $TASK_OUTPUT_DIR "
            "--max-rounds 3 --min-usable 8 --min-recent-7d 7 --min-domain-ratio 0.75 --max-noise-ratio 0.35 "
            "--pack-format zip"
        )

    # ‰ºòÂÖà‰ΩøÁî®Â∑•‰ΩúÊµÅ‰∏≠ÂøÉÈÖçÁΩÆÁöÑÂëΩ‰ª§Ê®°Êùø
    wf = get_workflow_by_code(template_name)
    if wf and (wf["command_template"] or "").strip():
        return (wf["command_template"] or "").replace("__PROJECT_DIR__", workdir)

    if template_name == "xhs_virtual_keywords":
        return (
            f"cd {workdir} && python3 scripts/xhs_virtual_keywords.py "
            "--keywords 'ËôöÊãü‰∫ßÂìÅ,Êï∞Â≠ó‰∫ßÂìÅ,PPTÊ®°Êùø,ÁÆÄÂéÜÊ®°Êùø,ÊïôÁ®ãËØæÁ®ã,AIÊèêÁ§∫ËØç,Á¥†ÊùêÂåÖ,ËµÑÊñôÂåÖ' "
            "--cookie-file $TASK_INPUT_DIR/xhs_cookies.json "
            "--scrolls 4 --auto-related 2 --max-keywords 24 --domain general "
            "--strict --min-usable 4 "
            "--out-md $TASK_OUTPUT_DIR/xhs_virtual_keywords.md "
            "--out-json $TASK_OUTPUT_DIR/xhs_virtual_keywords.json"
        )

    return ""


@app.post("/tasks")
@login_required
def create_task():
    workflow_template = (request.form.get("workflow_template") or "intelligent_dual").strip()
    task_brief = (request.form.get("task_brief") or "").strip()
    delivery_expectation = (request.form.get("delivery_expectation") or "").strip()
    project_dir = (request.form.get("project_dir") or "").strip()
    raw_command = (request.form.get("command") or "").strip()

    # ÈáçÊûÑÂêéÈªòËÆ§‰∏çÂÅö‚ÄúÂº∫Âà∂Ëá™Âä®Ë∑ØÁî±‚ÄùÔºåËÆ©ÂèåËßíËâ≤Ëá™‰∏ªËØÑ‰º∞‰∏éÂàÜÈÖçÊâßË°åË∑ØÂæÑ
    auto_routed = False

    title = derive_title(request.form.get("title", ""), task_brief, workflow_template)
    if not title:
        flash("ËØ∑Ëá≥Â∞ëÂ°´ÂÜô‰ªªÂä°ÊèèËø∞ÊàñÊ†áÈ¢ò")
        return redirect(url_for("dashboard"))

    description_raw = (request.form.get("description", "") or "").strip()
    desc_parts = []
    if task_brief:
        desc_parts.append(f"„Äê‰ªªÂä°ÊèèËø∞„Äë\n{task_brief}")
    if delivery_expectation:
        desc_parts.append(f"„ÄêÊúüÊúõ‰∫§‰ªò„Äë\n{delivery_expectation}")
    if description_raw:
        desc_parts.append(f"„ÄêË°•ÂÖÖËØ¥Êòé„Äë\n{description_raw}")
    description = "\n\n".join(desc_parts).strip()

    wf = get_workflow_by_code(workflow_template)

    task_type = (request.form.get("task_type") or "general").strip()
    assignee = (request.form.get("assignee") or "Lead Agent").strip()
    priority = (request.form.get("priority") or "P2").strip()

    # Ëã•Êú™ÊâãÂ∑•ÊåáÂÆöÔºå‰ºòÂÖàÂ•óÁî®Â∑•‰ΩúÊµÅÈªòËÆ§ËßíËâ≤/Á±ªÂûã
    if wf:
        if task_type == "general" and (wf["default_task_type"] or "").strip():
            task_type = (wf["default_task_type"] or "general").strip()
        if assignee in ("", "Lead Agent", "backend") and (wf["default_assignee"] or "").strip():
            assignee = (wf["default_assignee"] or "Lead Agent").strip()

    command = raw_command
    if not command:
        command = build_command_from_template(workflow_template, project_dir, task_brief)

    with db_conn() as conn:
        cur = conn.execute(
            """
            INSERT INTO tasks(title, description, task_type, assignee, priority, status, command, workflow_code, created_at, updated_at)
            VALUES(?,?,?,?,?,'pending',?,?,?,?)
            """,
            (title, description, task_type, assignee, priority, command, workflow_template, now_str(), now_str()),
        )
        task_id = cur.lastrowid

    append_log(task_id, f"[SYSTEM] ‰ªªÂä°ÂàõÂª∫Ôºö{title}")
    append_log(task_id, f"[SYSTEM] Â∑•‰ΩúÊµÅÊ®°ÊùøÔºö{workflow_template}")
    if auto_routed:
        append_log(task_id, "[SYSTEM] Â∑≤Ê†πÊçÆ‰ªªÂä°ÂÜÖÂÆπËá™Âä®Ë∑ØÁî±Âà∞ novel_multiagent ‰∏ìÁî®ÊµÅÊ∞¥Á∫ø")
    if task_brief:
        append_log(task_id, f"[SYSTEM] Âè£ËØ≠Âåñ‰ªªÂä°ÊèèËø∞Ôºö{task_brief[:1200]}")
    if delivery_expectation:
        append_log(task_id, f"[SYSTEM] ÊúüÊúõ‰∫§‰ªòÔºö{delivery_expectation[:800]}")

    _, input_dir, _ = task_artifact_dirs(task_id)
    uploaded = 0
    for f in request.files.getlist("attachments"):
        if not f or not f.filename:
            continue
        safe_name = secure_filename(f.filename)
        if not safe_name:
            continue
        target = os.path.join(input_dir, safe_name)
        f.save(target)
        uploaded += 1
        append_log(task_id, f"[SYSTEM] Â∑≤‰∏ä‰º†ÈôÑ‰ª∂: {safe_name}")

    if uploaded > 0:
        flash(f"‰ªªÂä° #{task_id} ÂàõÂª∫ÊàêÂäüÔºåÂ∑≤‰∏ä‰º† {uploaded} ‰∏™ÈôÑ‰ª∂")
    else:
        flash(f"‰ªªÂä° #{task_id} ÂàõÂª∫ÊàêÂäü")
    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/start")
@login_required
def start_task_route(task_id: int):
    ok, msg = start_task(task_id)
    flash(f"‰ªªÂä° #{task_id}: {msg}")
    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/retry")
@login_required
def retry_task(task_id: int):
    task = get_task(task_id)
    if not task:
        flash("‰ªªÂä°‰∏çÂ≠òÂú®")
        return redirect(url_for("dashboard"))

    update_task(task_id, status="pending", finished_at=None, started_at=None, return_code=None)
    append_log(task_id, "[SYSTEM] ‰ªªÂä°ÈáçÁΩÆ‰∏∫ pending")
    flash(f"‰ªªÂä° #{task_id} Â∑≤ÈáçÁΩÆ")
    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/stop")
@login_required
def stop_task(task_id: int):
    proc = running_processes.get(task_id)
    if proc is None and task_id in running_processes:
        running_processes.pop(task_id, None)
        task_run_context.pop(task_id, None)
        update_task(task_id, status="failed", finished_at=now_str(), return_code=137)
        append_log(task_id, "[SYSTEM] ‰ªªÂä°Âú®ÂêØÂä®Èò∂ÊÆµË¢´ÂÅúÊ≠¢")
        flash(f"‰ªªÂä° #{task_id} Â∑≤ÂÅúÊ≠¢")
        return redirect(url_for("dashboard"))

    if not proc:
        flash("‰ªªÂä°Êú™ËøêË°å")
        return redirect(url_for("dashboard"))

    try:
        try:
            pgid = os.getpgid(proc.pid)
            os.killpg(pgid, signal.SIGTERM)
            append_log(task_id, f"[SYSTEM] Â∑≤ÂèëÈÄÅÂÅúÊ≠¢‰ø°Âè∑Âà∞ËøõÁ®ãÁªÑ pgid={pgid}")
        except Exception:
            proc.terminate()
        update_task(task_id, status="failed", finished_at=now_str(), return_code=143)
        append_log(task_id, "[SYSTEM] ÊâãÂä®ÂÅúÊ≠¢‰ªªÂä°")
        flash(f"‰ªªÂä° #{task_id} Â∑≤ÂÅúÊ≠¢")
    except Exception as e:
        flash(f"ÂÅúÊ≠¢Â§±Ë¥•: {e}")

    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/delete")
@login_required
def delete_task(task_id: int):
    task = get_task(task_id)
    if not task:
        flash("‰ªªÂä°‰∏çÂ≠òÂú®")
        return redirect(url_for("dashboard"))

    if task_id in running_processes:
        flash(f"‰ªªÂä° #{task_id} Ê≠£Âú®ËøêË°åÊàñÊéíÈòü‰∏≠ÔºåËØ∑ÂÖàÂÅúÊ≠¢ÂêéÂÜçÂà†Èô§")
        return redirect(url_for("dashboard"))

    try:
        with db_conn() as conn:
            conn.execute("DELETE FROM task_logs WHERE task_id=?", (task_id,))
            conn.execute("DELETE FROM role_session_messages WHERE task_id=?", (task_id,))
            conn.execute("DELETE FROM tasks WHERE id=?", (task_id,))

        task_dir = os.path.join(ARTIFACT_ROOT, f"task_{task_id}")
        if os.path.isdir(task_dir):
            shutil.rmtree(task_dir, ignore_errors=True)

        flash(f"‰ªªÂä° #{task_id} Â∑≤Âà†Èô§ÔºàÂê´Êó•ÂøóÂíå‰ªªÂä°ÈôÑ‰ª∂/‰∫ßÁâ©Ôºâ")
    except Exception as e:
        flash(f"Âà†Èô§‰ªªÂä°Â§±Ë¥•: {e}")

    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/upload")
@login_required
def task_upload(task_id: int):
    task = get_task(task_id)
    if not task:
        flash("‰ªªÂä°‰∏çÂ≠òÂú®")
        return redirect(url_for("dashboard"))

    _, input_dir, _ = task_artifact_dirs(task_id)
    uploaded = 0
    for f in request.files.getlist("attachments"):
        if not f or not f.filename:
            continue
        safe_name = secure_filename(f.filename)
        if not safe_name:
            continue
        target = os.path.join(input_dir, safe_name)
        f.save(target)
        uploaded += 1
        append_log(task_id, f"[SYSTEM] Â∑≤ËøΩÂä†‰∏ä‰º†ÈôÑ‰ª∂: {safe_name}")

    if uploaded == 0:
        flash("Êú™Ê£ÄÊµãÂà∞ÂèØ‰∏ä‰º†Êñá‰ª∂")
    else:
        flash(f"‰ªªÂä° #{task_id} ÈôÑ‰ª∂‰∏ä‰º†ÂÆåÊàêÔºö{uploaded} ‰∏™")
    return redirect(url_for("task_detail", task_id=task_id))


@app.route("/tasks/<int:task_id>/download/<path:rel_path>")
@login_required
def task_artifact_download(task_id: int, rel_path: str):
    task = get_task(task_id)
    if not task:
        abort(404)
    base, _, _ = task_artifact_dirs(task_id)
    safe_full = safe_join_under(base, rel_path)
    if not safe_full:
        abort(400)
    if not os.path.isfile(safe_full):
        abort(404)
    return send_from_directory(base, rel_path, as_attachment=True)


@app.route("/tasks/<int:task_id>")
@login_required
def task_detail(task_id: int):
    task = get_task(task_id)
    if not task:
        return "Task not found", 404

    with db_conn() as conn:
        logs = conn.execute(
            "SELECT ts, line FROM task_logs WHERE task_id=? ORDER BY id ASC", (task_id,)
        ).fetchall()

    base, input_dir, output_dir = task_artifact_dirs(task_id)
    input_files = list_task_files(task_id, "input")
    output_files = list_task_files(task_id, "output")
    delivery = build_delivery_overview(task, output_files, logs)
    multiagent = load_multiagent_summary(output_dir)

    return render_template(
        "task_detail.html",
        task=task,
        logs=logs,
        delivery=delivery,
        multiagent=multiagent,
        base_dir=base,
        input_dir=input_dir,
        output_dir=output_dir,
        input_files=input_files,
        output_files=output_files,
    )


@app.route("/api/tasks")
@login_required
def api_tasks():
    with db_conn() as conn:
        rows = conn.execute("SELECT * FROM tasks ORDER BY id DESC LIMIT 200").fetchall()
    return jsonify([dict(r) for r in rows])


if __name__ == "__main__":
    init_db()
    sync_runtime_settings()
    app.run(host="127.0.0.1", port=3100, debug=False)
else:
    init_db()
    sync_runtime_settings()
