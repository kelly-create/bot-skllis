#!/usr/bin/env python3
import json
import os
import re
import sqlite3
import subprocess
import threading
import time
import shutil
import urllib.error
import urllib.request
from contextlib import contextmanager
from datetime import datetime, timedelta
from functools import wraps

from flask import Flask, abort, flash, g, jsonify, redirect, render_template, request, send_from_directory, session, url_for
from werkzeug.utils import secure_filename

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.getenv("ATC_DB_PATH", os.path.join(BASE_DIR, "data", "tasks.db"))
ADMIN_USERNAME = os.getenv("ATC_ADMIN_USERNAME", "root")
ADMIN_PASSWORD = os.getenv("ATC_ADMIN_PASSWORD", "k5348988")
APP_SECRET = os.getenv("ATC_APP_SECRET", "change-me-now")
WORKDIR = os.getenv("ATC_WORKDIR", BASE_DIR)
DEFAULT_MAX_CONCURRENT = int(os.getenv("ATC_MAX_CONCURRENT", "4"))
ARTIFACT_ROOT = os.getenv("ATC_ARTIFACT_ROOT", os.path.join(BASE_DIR, "artifacts"))
ROLE_DEFAULT_API_BASE = os.getenv("ATC_ROLE_DEFAULT_API_BASE", "").strip()
ROLE_DEFAULT_API_KEY = os.getenv("ATC_ROLE_DEFAULT_API_KEY", "").strip()
ROLE_DEFAULT_TIMEOUT = int(os.getenv("ATC_ROLE_TIMEOUT_SECONDS", "180"))
ROLE_MAX_REWORK_ROUNDS = max(0, min(5, int(os.getenv("ATC_MAX_REWORK_ROUNDS", "2"))))
ROLE_STAGE_REVIEW_MAX_RETRIES = max(0, min(5, int(os.getenv("ATC_STAGE_REVIEW_MAX_RETRIES", "2"))))

os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
os.makedirs(ARTIFACT_ROOT, exist_ok=True)

app = Flask(__name__)
app.secret_key = APP_SECRET
app.config["MAX_CONTENT_LENGTH"] = 200 * 1024 * 1024  # 200MB

running_processes = {}


class ConcurrencyLimiter:
    def __init__(self, limit: int):
        self._limit = max(1, int(limit))
        self._running = 0
        self._lock = threading.Lock()
        self._cond = threading.Condition(self._lock)

    @contextmanager
    def acquire(self):
        with self._cond:
            while self._running >= self._limit:
                self._cond.wait(timeout=1)
            self._running += 1
        try:
            yield
        finally:
            with self._cond:
                self._running -= 1
                self._cond.notify_all()

    def set_limit(self, limit: int):
        with self._cond:
            self._limit = max(1, int(limit))
            self._cond.notify_all()

    def get_limit(self) -> int:
        with self._lock:
            return self._limit

    def get_running(self) -> int:
        with self._lock:
            return self._running


limiter = ConcurrencyLimiter(DEFAULT_MAX_CONCURRENT)


def now_str():
    return datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")


def to_beijing_time(ts_text: str) -> str:
    raw = (ts_text or "").strip()
    if not raw:
        return "-"
    try:
        if raw.endswith(" UTC"):
            dt = datetime.strptime(raw, "%Y-%m-%d %H:%M:%S UTC")
        else:
            dt = datetime.strptime(raw, "%Y-%m-%d %H:%M:%S")
        dt_bj = dt + timedelta(hours=8)
        return dt_bj.strftime("%Y-%m-%d %H:%M:%S åŒ—äº¬æ—¶é—´")
    except Exception:
        return raw


def epoch_to_beijing(ts_epoch: float) -> str:
    try:
        dt_bj = datetime.utcfromtimestamp(ts_epoch) + timedelta(hours=8)
        return dt_bj.strftime("%Y-%m-%d %H:%M:%S åŒ—äº¬æ—¶é—´")
    except Exception:
        return "-"


app.jinja_env.filters["bjt"] = to_beijing_time


def format_size(num_bytes: int) -> str:
    size = float(num_bytes)
    for unit in ["B", "KB", "MB", "GB", "TB"]:
        if size < 1024 or unit == "TB":
            return f"{size:.1f}{unit}" if unit != "B" else f"{int(size)}B"
        size /= 1024


def list_artifacts(max_items: int = 300):
    out = []
    for root, _, files in os.walk(ARTIFACT_ROOT):
        for name in files:
            full = os.path.join(root, name)
            rel = os.path.relpath(full, ARTIFACT_ROOT)
            try:
                st = os.stat(full)
            except FileNotFoundError:
                continue
            out.append(
                {
                    "name": name,
                    "rel_path": rel,
                    "size": st.st_size,
                    "size_human": format_size(st.st_size),
                    "mtime": epoch_to_beijing(st.st_mtime),
                    "ts": st.st_mtime,
                }
            )
    out.sort(key=lambda x: x["ts"], reverse=True)
    return out[:max_items]


def task_artifact_dirs(task_id: int):
    base = os.path.join(ARTIFACT_ROOT, f"task_{task_id}")
    in_dir = os.path.join(base, "input")
    out_dir = os.path.join(base, "output")
    os.makedirs(in_dir, exist_ok=True)
    os.makedirs(out_dir, exist_ok=True)
    return base, in_dir, out_dir


def list_task_files(task_id: int, kind: str):
    base, in_dir, out_dir = task_artifact_dirs(task_id)
    target = in_dir if kind == "input" else out_dir
    out = []
    if not os.path.isdir(target):
        return out
    for name in os.listdir(target):
        full = os.path.join(target, name)
        if not os.path.isfile(full):
            continue
        st = os.stat(full)
        rel = os.path.relpath(full, base)
        out.append(
            {
                "name": name,
                "rel_path": rel,
                "size_human": format_size(st.st_size),
                "mtime": epoch_to_beijing(st.st_mtime),
                "ts": st.st_mtime,
            }
        )
    out.sort(key=lambda x: x["ts"], reverse=True)
    return out


def infer_business_phase(task) -> str:
    status = (task["status"] or "").strip().lower()
    if status in ("pending", "failed"):
        return "å¾…å¤„ç†"
    if status == "running":
        return "æ‰§è¡Œä¸­"
    if status == "done":
        return "å¾…ç¡®è®¤"
    return "å…¶ä»–"


def classify_output_files(output_files):
    packs, reports, audits, others = [], [], [], []
    for f in output_files:
        name = (f.get("name") or "").lower()
        is_pack = name.endswith(".zip") or name.endswith(".7z") or name.endswith(".tar.gz") or name.endswith(".tgz")
        is_audit = ("audit" in name) or ("å®¡è®¡" in name) or name.endswith(".log")
        is_report = name.endswith(".md") or name.endswith(".json") or name.endswith(".txt") or name.endswith(".csv") or name.endswith(".pdf")

        if is_pack:
            packs.append(f)
        elif is_audit:
            audits.append(f)
        elif is_report:
            reports.append(f)
        else:
            others.append(f)
    return {"packs": packs, "reports": reports, "audits": audits, "others": others}


def build_delivery_overview(task, output_files, logs):
    status = (task["status"] or "").strip().lower()
    rc = task["return_code"]
    if status == "done" and (rc in (0, "0", None) or rc == 0):
        headline = "âœ… ä»»åŠ¡å·²å®Œæˆï¼Œå¯ç›´æ¥æŸ¥çœ‹å¹¶ä¸‹è½½äº¤ä»˜ç‰©"
        next_action = "ä¼˜å…ˆä¸‹è½½â€œäº¤ä»˜å‹ç¼©åŒ…â€ï¼Œç¡®è®¤ç»“æœåå¯å½’æ¡£ä»»åŠ¡ã€‚"
        progress = 100
    elif status == "running":
        headline = "â³ ä»»åŠ¡æ‰§è¡Œä¸­ï¼Œæ­£åœ¨æŒç»­äº§å‡º"
        next_action = "å¯å…ˆæŸ¥çœ‹å®æ—¶æ—¥å¿—ï¼Œç­‰å¾…è¿›å…¥â€œå¾…ä½ ç¡®è®¤â€ã€‚"
        progress = 60
    elif status == "failed":
        headline = "âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œéœ€è¦è¿”å·¥"
        next_action = "æŸ¥çœ‹å¤±è´¥æ—¥å¿—å¹¶é‡ç½®ä»»åŠ¡ï¼Œå¿…è¦æ—¶è¡¥å……é™„ä»¶æˆ–è¯´æ˜ã€‚"
        progress = 100
    else:
        headline = "ğŸ“ ä»»åŠ¡å¾…æ‰§è¡Œ"
        next_action = "ç¡®è®¤ä»»åŠ¡æè¿°ä¸é™„ä»¶åï¼Œç‚¹å‡»â€œå¯åŠ¨â€ã€‚"
        progress = 12

    latest_line = ""
    for row in reversed(logs):
        line = (row["line"] or "").strip()
        if not line:
            continue
        latest_line = line
        if not line.startswith("[SYSTEM]"):
            break

    groups = classify_output_files(output_files)
    primary_pack = groups["packs"][0] if groups["packs"] else None

    return {
        "headline": headline,
        "next_action": next_action,
        "progress": progress,
        "latest_line": latest_line,
        "groups": groups,
        "primary_pack": primary_pack,
    }


def load_multiagent_summary(output_dir: str):
    audit_path = os.path.join(output_dir, "å¤šAgent_ä¼šè¯å®¡è®¡.json")
    if not os.path.isfile(audit_path):
        return None

    try:
        data = json.load(open(audit_path, "r", encoding="utf-8"))
    except Exception:
        return None

    dynamic = data.get("dynamicAssignments") or {}
    dispatch_items = [{"stage": k, "role": v} for k, v in dynamic.items()]

    review_pass = 0
    review_fail = 0
    quality_fail = 0
    called_roles = []
    role_seen = set()
    stage_tracks = []

    intake_role = "-"
    intake_model = "-"

    for s in data.get("stages") or []:
        role = s.get("role") or "-"
        if role not in role_seen:
            role_seen.add(role)
            called_roles.append(role)

        rd_obj = s.get("reviewDecision") or {}
        rd = rd_obj.get("decision", "")
        if rd == "PASS":
            review_pass += 1
        elif rd == "FAIL":
            review_fail += 1

        q_obj = (s.get("qualityGate") or {}).get("decision") or {}
        qd = q_obj.get("decision", "")
        if qd == "FAIL":
            quality_fail += 1

        if rd:
            track_status = f"å¤æ ¸{rd}"
            reason = rd_obj.get("reason", "")
            if rd == "FAIL" and rd_obj.get("send_back_role"):
                reason = f"æ‰“å› {rd_obj.get('send_back_role')}ï½œ{reason}"
        elif qd:
            track_status = f"è´¨æ§{qd}"
            reason = q_obj.get("reason", "")
        else:
            track_status = "å®Œæˆ"
            reason = ""

        stage_name = s.get("stage") or "-"
        model_name = s.get("model") or "-"
        if intake_role == "-" and any(k in stage_name for k in ["éœ€æ±‚æ¥æ”¶", "åˆ†å‘", "éœ€æ±‚åˆ†æ", "éœ€æ±‚ç†è§£"]):
            intake_role = role
            intake_model = model_name

        stage_tracks.append(
            {
                "executionNo": s.get("executionNo") or "-",
                "stage": stage_name,
                "role": role,
                "model": model_name,
                "reworkRound": s.get("reworkRound") or 0,
                "duration_sec": s.get("durationSec"),
                "status": track_status,
                "reason": (reason or "")[:180],
            }
        )

    if intake_role == "-" and stage_tracks:
        intake_role = stage_tracks[0].get("role") or "-"
        intake_model = stage_tracks[0].get("model") or "-"

    return {
        "workflow": data.get("workflow") or "-",
        "steps": len(data.get("stages") or []),
        "rework_used": data.get("reworkRoundsUsed") or 0,
        "rework_max": data.get("maxReworkRounds") or 0,
        "dispatch_items": dispatch_items,
        "review_pass": review_pass,
        "review_fail": review_fail,
        "quality_fail": quality_fail,
        "called_roles": called_roles,
        "stage_tracks": stage_tracks,
        "intake_role": intake_role,
        "intake_model": intake_model,
    }


def safe_join_under(root: str, rel_path: str):
    safe_full = os.path.realpath(os.path.join(root, rel_path))
    root_real = os.path.realpath(root)
    if not safe_full.startswith(root_real + os.sep) and safe_full != root_real:
        return None
    return safe_full


@contextmanager
def db_conn():
    conn = sqlite3.connect(DB_PATH, timeout=30)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
        conn.commit()
    finally:
        conn.close()


def ensure_column(conn, table: str, column: str, decl: str):
    cols = [r[1] for r in conn.execute(f"PRAGMA table_info({table})").fetchall()]
    if column not in cols:
        conn.execute(f"ALTER TABLE {table} ADD COLUMN {column} {decl}")


def init_db():
    with db_conn() as conn:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                description TEXT,
                task_type TEXT,
                assignee TEXT,
                priority TEXT DEFAULT 'P2',
                status TEXT DEFAULT 'pending',
                command TEXT,
                created_at TEXT,
                updated_at TEXT,
                started_at TEXT,
                finished_at TEXT,
                return_code INTEGER
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS task_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_id INTEGER NOT NULL,
                ts TEXT,
                line TEXT,
                FOREIGN KEY(task_id) REFERENCES tasks(id)
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS app_settings (
                key TEXT PRIMARY KEY,
                value TEXT,
                updated_at TEXT
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS roles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code TEXT UNIQUE NOT NULL,
                name TEXT NOT NULL,
                description TEXT,
                default_model TEXT,
                enabled INTEGER DEFAULT 1,
                created_at TEXT,
                updated_at TEXT
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS workflows (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code TEXT UNIQUE NOT NULL,
                name TEXT NOT NULL,
                description TEXT,
                stages_json TEXT,
                default_task_type TEXT,
                default_assignee TEXT,
                command_template TEXT,
                enabled INTEGER DEFAULT 1,
                created_at TEXT,
                updated_at TEXT
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS role_session_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_id INTEGER NOT NULL,
                role_code TEXT NOT NULL,
                stage TEXT,
                turn TEXT NOT NULL,
                content TEXT,
                created_at TEXT
            )
            """
        )

        # å†å²åº“å…¼å®¹ï¼šæŒ‰éœ€è¡¥å­—æ®µ
        ensure_column(conn, "tasks", "workflow_code", "TEXT")
        ensure_column(conn, "roles", "api_base", "TEXT")
        ensure_column(conn, "roles", "api_key", "TEXT")
        ensure_column(conn, "roles", "system_prompt", "TEXT")
        ensure_column(conn, "roles", "temperature", "REAL DEFAULT 0.3")
        ensure_column(conn, "roles", "max_tokens", "INTEGER DEFAULT 1200")
        ensure_column(conn, "workflows", "stage_roles_json", "TEXT")

        # é»˜è®¤å…¨å±€è§’è‰²ï¼ˆåˆ›å»ºä¸€æ¬¡ï¼Œåç»­å¯åœ¨é¡µé¢ç»´æŠ¤ï¼‰
        default_roles = [
            ("Lead Agent", "Lead Agent", "ä»»åŠ¡æ€»æ§ä¸ç¼–æ’", "gpt-5.3-codex"),
            ("@developer", "å¼€å‘ Agent", "å®ç°åŠŸèƒ½ã€æ”¹ä»£ç ã€ä¿®å¤é—®é¢˜", "gpt-5.3-codex"),
            ("@tester", "æµ‹è¯• Agent", "å›å½’æµ‹è¯•ã€è¾¹ç•ŒéªŒè¯ã€å¤ç°é—®é¢˜", "gpt-5.3-codex"),
            ("@verifier", "éªŒè¯ Agent", "æŒ‰éªŒæ”¶æ ‡å‡†åšæœ€ç»ˆæ ¸å¯¹", "gpt-5.3-codex"),
            ("@release", "å‘å¸ƒ Agent", "å‘å¸ƒã€å›æ»šã€å˜æ›´å®¡è®¡", "gpt-5.3-codex"),
            ("@research", "è°ƒç ” Agent", "ä¿¡æ¯æ£€ç´¢ã€æ•°æ®åˆ†æã€æŠ¥å‘Šæ²‰æ·€", "gpt-5.3-codex"),
        ]
        for code, name, desc, model in default_roles:
            conn.execute(
                """
                INSERT OR IGNORE INTO roles(code, name, description, default_model, enabled, created_at, updated_at)
                VALUES(?,?,?,?,1,?,?)
                """,
                (code, name, desc, model, now_str(), now_str()),
            )

        # é»˜è®¤è§’è‰²è¯ï¼ˆsystem promptï¼‰
        role_prompts = {
            "Lead Agent": "ä½ æ˜¯æ€»æ§è§’è‰²ã€‚è´Ÿè´£æ‹†è§£ä»»åŠ¡ã€å®šä¹‰é˜¶æ®µç›®æ ‡ã€ä¸²è”å„è§’è‰²è¾“å‡ºï¼Œæœ€ç»ˆç»™å‡ºå¯äº¤ä»˜ç»“æœä¸ç»“è®ºã€‚è¾“å‡ºè¦ç®€æ´ã€ç»“æ„åŒ–ã€‚",
            "@developer": "ä½ æ˜¯å¼€å‘è§’è‰²ã€‚èšç„¦å®ç°æ–¹æ¡ˆã€å…³é”®æ­¥éª¤ã€ä»£ç /æµç¨‹æ”¹åŠ¨ç‚¹ã€‚ä¸è¦æ³›æ³›è€Œè°ˆï¼Œç»™å‡ºå¯æ‰§è¡Œå†…å®¹ã€‚",
            "@tester": "ä½ æ˜¯æµ‹è¯•è§’è‰²ã€‚åŸºäºå¼€å‘è¾“å‡ºè®¾è®¡éªŒè¯ç‚¹ã€è¾¹ç•Œç”¨ä¾‹ã€å›å½’æ¸…å•ï¼Œå¹¶æ ‡è®°é£é™©ä¸ç¼ºé™·ã€‚",
            "@verifier": "ä½ æ˜¯éªŒè¯è§’è‰²ã€‚æŒ‰ä»»åŠ¡ç›®æ ‡ä¸äº¤ä»˜æ ‡å‡†åšæœ€ç»ˆæ ¸å¯¹ï¼Œæ˜ç¡®é€šè¿‡/ä¸é€šè¿‡å’Œç†ç”±ã€‚",
            "@release": "ä½ æ˜¯å‘å¸ƒäº¤ä»˜è§’è‰²ã€‚è´Ÿè´£æ•´ç†æœ€ç»ˆäº¤ä»˜ã€å‘å¸ƒæ­¥éª¤ã€å›æ»šè¦ç‚¹ä¸é£é™©æç¤ºã€‚",
            "@research": "ä½ æ˜¯è°ƒç ”åˆ†æè§’è‰²ã€‚è´Ÿè´£ä¿¡æ¯æç‚¼ã€ç»“æ„åŒ–æ€»ç»“ã€å…³é”®è¯æ®å’Œç»“è®ºã€‚",
            "@pm": "ä½ æ˜¯äº§å“ç»ç†è§’è‰²ã€‚è´Ÿè´£éœ€æ±‚æ¾„æ¸…ã€éªŒæ”¶æ ‡å‡†ã€ä¼˜å…ˆçº§ä¸èŒƒå›´è¾¹ç•Œã€‚",
        }
        for role_code, prompt in role_prompts.items():
            conn.execute(
                """
                UPDATE roles
                SET system_prompt = CASE WHEN system_prompt IS NULL OR system_prompt='' THEN ? ELSE system_prompt END,
                    updated_at=?
                WHERE code=?
                """,
                (prompt, now_str(), role_code),
            )

        # ç»™æœªé…ç½®è§’è‰²æ³¨å…¥ç¯å¢ƒçº§é»˜è®¤ APIï¼ˆå¯ä¸ºç©ºï¼Œä¸å¼ºåˆ¶ï¼‰
        if ROLE_DEFAULT_API_BASE:
            conn.execute(
                """
                UPDATE roles
                SET api_base = CASE WHEN api_base IS NULL OR api_base='' THEN ? ELSE api_base END,
                    updated_at=?
                """,
                (ROLE_DEFAULT_API_BASE, now_str()),
            )
        if ROLE_DEFAULT_API_KEY:
            conn.execute(
                """
                UPDATE roles
                SET api_key = CASE WHEN api_key IS NULL OR api_key='' THEN ? ELSE api_key END,
                    updated_at=?
                """,
                (ROLE_DEFAULT_API_KEY, now_str()),
            )

        # é»˜è®¤å…¨å±€å·¥ä½œæµæ¨¡æ¿ï¼ˆå¯å¤ç”¨ï¼Œä¸ç»‘å®šå•ä¸€ä¸šåŠ¡ï¼‰
        default_workflows = [
            (
                "custom_brief",
                "é€šç”¨å£è¯­ä»»åŠ¡",
                "å£è¯­åŒ–æè¿° + é™„ä»¶è¾“å…¥ï¼Œé€‚é…ä»»æ„ä»»åŠ¡",
                json.dumps(["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "æ‰§è¡Œ", "å¤æ ¸", "äº¤ä»˜"], ensure_ascii=False),
                "general",
                "Lead Agent",
                "",
            ),
            (
                "dev_test_verify",
                "å¼€å‘â†’æµ‹è¯•â†’éªŒè¯",
                "é¢å‘ä»£ç ä»»åŠ¡çš„æ ‡å‡†é—­ç¯",
                json.dumps(["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "å¼€å‘", "æµ‹è¯•", "éªŒè¯", "äº¤ä»˜"], ensure_ascii=False),
                "backend",
                "Lead Agent",
                "",
            ),
            (
                "research_report",
                "è°ƒç ”â†’æç‚¼â†’äº¤ä»˜",
                "é¢å‘ä¿¡æ¯åˆ†æä¸å†…å®¹ç”Ÿäº§ä»»åŠ¡",
                json.dumps(["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "è°ƒç ”", "æç‚¼", "å¤æ ¸", "äº¤ä»˜"], ensure_ascii=False),
                "research",
                "Lead Agent",
                "",
            ),
            (
                "novel_multiagent",
                "å°è¯´ç±»ç›®çˆ†æ¬¾æ–‡åŒ…ï¼ˆå¤šAgentï¼‰",
                "é‡‡é›†â†’æ¸…æ´—â†’å¤æ ¸â†’æ–‡åŒ…",
                json.dumps(["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "é‡‡é›†", "æ¸…æ´—", "å¤æ ¸", "æ–‡åŒ…"], ensure_ascii=False),
                "research",
                "Lead Agent",
                "",
            ),
            (
                "xhs_virtual_keywords",
                "å°çº¢ä¹¦é«˜é¢‘è¯åˆ†æ",
                "å…³é”®è¯é‡‡é›†ä¸é«˜é¢‘è¯æŠ¥å‘Š",
                json.dumps(["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "é‡‡é›†", "æ¸…æ´—", "å¤æ ¸", "äº¤ä»˜"], ensure_ascii=False),
                "research",
                "Lead Agent",
                "cd __PROJECT_DIR__ && python3 scripts/xhs_virtual_keywords.py --keywords 'è™šæ‹Ÿäº§å“,æ•°å­—äº§å“,PPTæ¨¡æ¿,ç®€å†æ¨¡æ¿,æ•™ç¨‹è¯¾ç¨‹,AIæç¤ºè¯,ç´ æåŒ…,èµ„æ–™åŒ…' --cookie-file $TASK_INPUT_DIR/xhs_cookies.json --scrolls 4 --auto-related 2 --max-keywords 24 --domain general --strict --min-usable 4 --out-md $TASK_OUTPUT_DIR/xhs_virtual_keywords.md --out-json $TASK_OUTPUT_DIR/xhs_virtual_keywords.json",
            ),
        ]
        for code, name, desc, stages, task_type, assignee, cmd in default_workflows:
            conn.execute(
                """
                INSERT OR IGNORE INTO workflows(
                    code, name, description, stages_json, default_task_type, default_assignee, command_template, enabled, created_at, updated_at
                ) VALUES(?,?,?,?,?,?,?,1,?,?)
                """,
                (code, name, desc, stages, task_type, assignee, cmd, now_str(), now_str()),
            )

        stage_role_defaults = {
            "custom_brief": {"éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘": "Lead Agent", "æ‰§è¡Œ": "@developer", "å¤æ ¸": "@verifier", "äº¤ä»˜": "Lead Agent"},
            "dev_test_verify": {"éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘": "Lead Agent", "å¼€å‘": "@developer", "æµ‹è¯•": "@tester", "éªŒè¯": "@verifier", "äº¤ä»˜": "@release"},
            "research_report": {"éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘": "Lead Agent", "è°ƒç ”": "@research", "æç‚¼": "@research", "å¤æ ¸": "@verifier", "äº¤ä»˜": "Lead Agent"},
            "novel_multiagent": {"éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘": "Lead Agent", "é‡‡é›†": "@research", "æ¸…æ´—": "@developer", "å¤æ ¸": "@verifier", "æ–‡åŒ…": "@release"},
            "xhs_virtual_keywords": {"éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘": "Lead Agent", "é‡‡é›†": "@research", "æ¸…æ´—": "@developer", "å¤æ ¸": "@verifier", "äº¤ä»˜": "Lead Agent"},
        }
        for wf_code, mapping in stage_role_defaults.items():
            conn.execute(
                """
                UPDATE workflows
                SET stage_roles_json = ?,
                    updated_at=?
                WHERE code=?
                """,
                (json.dumps(mapping, ensure_ascii=False), now_str(), wf_code),
            )

        workflow_stage_defaults = {
            "custom_brief": ["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "æ‰§è¡Œ", "å¤æ ¸", "äº¤ä»˜"],
            "dev_test_verify": ["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "å¼€å‘", "æµ‹è¯•", "éªŒè¯", "äº¤ä»˜"],
            "research_report": ["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "è°ƒç ”", "æç‚¼", "å¤æ ¸", "äº¤ä»˜"],
            "novel_multiagent": ["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "é‡‡é›†", "æ¸…æ´—", "å¤æ ¸", "æ–‡åŒ…"],
            "xhs_virtual_keywords": ["éœ€æ±‚æ¥æ”¶ä¸åˆ†å‘", "é‡‡é›†", "æ¸…æ´—", "å¤æ ¸", "äº¤ä»˜"],
        }
        for wf_code, stages in workflow_stage_defaults.items():
            conn.execute(
                """
                UPDATE workflows
                SET stages_json=?,
                    default_assignee='Lead Agent',
                    updated_at=?
                WHERE code=?
                """,
                (json.dumps(stages, ensure_ascii=False), now_str(), wf_code),
            )


def get_setting(key: str, default_value: str = "") -> str:
    with db_conn() as conn:
        row = conn.execute("SELECT value FROM app_settings WHERE key=?", (key,)).fetchone()
    if not row:
        return default_value
    return row["value"]


def set_setting(key: str, value: str):
    with db_conn() as conn:
        conn.execute(
            """
            INSERT INTO app_settings(key, value, updated_at)
            VALUES(?,?,?)
            ON CONFLICT(key) DO UPDATE SET value=excluded.value, updated_at=excluded.updated_at
            """,
            (key, str(value), now_str()),
        )


def sync_runtime_settings():
    raw = get_setting("max_concurrent", str(DEFAULT_MAX_CONCURRENT))
    try:
        val = max(1, min(16, int(raw)))
    except Exception:
        val = DEFAULT_MAX_CONCURRENT
    set_setting("max_concurrent", str(val))
    limiter.set_limit(val)


def get_roles(enabled_only: bool = False):
    q = "SELECT * FROM roles"
    if enabled_only:
        q += " WHERE enabled=1"
    q += " ORDER BY CASE WHEN code='Lead Agent' THEN 0 ELSE 1 END, id ASC"
    with db_conn() as conn:
        rows = conn.execute(q).fetchall()

    out = []
    for r in rows:
        d = dict(r)
        d["api_ready"] = bool((d.get("api_base") or "").strip() and (d.get("api_key") or "").strip() and (d.get("default_model") or "").strip())
        d["api_key_masked"] = mask_secret(d.get("api_key") or "")
        out.append(d)
    return out


def get_workflow_by_code(code: str):
    if not code:
        return None
    with db_conn() as conn:
        return conn.execute("SELECT * FROM workflows WHERE code=?", (code,)).fetchone()


def get_role_by_code(code: str):
    if not code:
        return None
    with db_conn() as conn:
        return conn.execute("SELECT * FROM roles WHERE code=?", (code,)).fetchone()


def mask_secret(secret: str) -> str:
    s = (secret or "").strip()
    if not s:
        return ""
    if len(s) <= 8:
        return "*" * len(s)
    return s[:4] + "..." + s[-4:]


def parse_stages(stages_json: str):
    raw = (stages_json or "").strip()
    if not raw:
        return []
    try:
        data = json.loads(raw)
        if isinstance(data, list):
            return [str(x) for x in data]
    except Exception:
        pass
    return [x.strip() for x in re.split(r"[,ï¼Œ\n]+", raw) if x.strip()]


def parse_stage_roles(stage_roles_json: str):
    raw = (stage_roles_json or "").strip()
    if not raw:
        return {}
    try:
        data = json.loads(raw)
        if isinstance(data, dict):
            return {str(k): str(v) for k, v in data.items() if str(k).strip() and str(v).strip()}
    except Exception:
        pass

    out = {}
    for part in re.split(r"[,ï¼Œ\n]+", raw):
        p = part.strip()
        if not p:
            continue
        if ":" in p:
            k, v = p.split(":", 1)
        elif "=" in p:
            k, v = p.split("=", 1)
        else:
            continue
        k = k.strip()
        v = v.strip()
        if k and v:
            out[k] = v
    return out


def get_workflows(enabled_only: bool = False):
    q = "SELECT * FROM workflows"
    if enabled_only:
        q += " WHERE enabled=1"
    q += " ORDER BY id ASC"
    with db_conn() as conn:
        rows = conn.execute(q).fetchall()

    out = []
    for r in rows:
        d = dict(r)
        d["stages"] = parse_stages(d.get("stages_json"))
        d["stage_roles"] = parse_stage_roles(d.get("stage_roles_json"))
        out.append(d)
    return out


def append_log(task_id: int, line: str):
    with db_conn() as conn:
        conn.execute(
            "INSERT INTO task_logs(task_id, ts, line) VALUES(?,?,?)",
            (task_id, now_str(), line[:4000]),
        )


def update_task(task_id: int, **fields):
    if not fields:
        return
    fields["updated_at"] = now_str()
    keys = list(fields.keys())
    vals = [fields[k] for k in keys]
    clause = ", ".join([f"{k}=?" for k in keys])
    with db_conn() as conn:
        conn.execute(f"UPDATE tasks SET {clause} WHERE id=?", vals + [task_id])


def get_task(task_id: int):
    with db_conn() as conn:
        return conn.execute("SELECT * FROM tasks WHERE id=?", (task_id,)).fetchone()


def save_role_message(task_id: int, role_code: str, stage: str, turn: str, content: str):
    with db_conn() as conn:
        conn.execute(
            "INSERT INTO role_session_messages(task_id, role_code, stage, turn, content, created_at) VALUES(?,?,?,?,?,?)",
            (task_id, role_code, stage, turn, (content or "")[:12000], now_str()),
        )


def load_role_messages(task_id: int, role_code: str, limit: int = 8):
    with db_conn() as conn:
        rows = conn.execute(
            "SELECT turn, content FROM role_session_messages WHERE task_id=? AND role_code=? ORDER BY id DESC LIMIT ?",
            (task_id, role_code, max(1, int(limit))),
        ).fetchall()
    return list(reversed(rows))


def parse_task_sections(description: str):
    text = (description or "").strip()
    out = {"task": "", "delivery": "", "extra": text}
    if not text:
        return out

    m_task = re.search(r"ã€ä»»åŠ¡æè¿°ã€‘\n([\s\S]*?)(?:\n\nã€|$)", text)
    m_delivery = re.search(r"ã€æœŸæœ›äº¤ä»˜ã€‘\n([\s\S]*?)(?:\n\nã€|$)", text)
    m_extra = re.search(r"ã€è¡¥å……è¯´æ˜ã€‘\n([\s\S]*?)$", text)

    if m_task:
        out["task"] = m_task.group(1).strip()
    if m_delivery:
        out["delivery"] = m_delivery.group(1).strip()
    if m_extra:
        out["extra"] = m_extra.group(1).strip()
    return out


def ensure_not_stopped(task_id: int):
    if task_id not in running_processes:
        raise RuntimeError("ä»»åŠ¡è¢«æ‰‹åŠ¨åœæ­¢")


def _extract_content_from_chat_response(data: dict) -> str:
    choices = data.get("choices") or []
    if not choices:
        return ""
    msg = (choices[0] or {}).get("message") or {}
    content = msg.get("content")
    if isinstance(content, list):
        parts = []
        for item in content:
            if isinstance(item, dict):
                if item.get("type") == "text":
                    parts.append(item.get("text") or "")
                elif "text" in item:
                    parts.append(str(item.get("text")))
            else:
                parts.append(str(item))
        return "\n".join([p for p in parts if p]).strip()
    return (content or "").strip()


def call_role_llm(role, messages):
    api_base = (role["api_base"] or ROLE_DEFAULT_API_BASE or "").strip()
    api_key = (role["api_key"] or ROLE_DEFAULT_API_KEY or "").strip()
    model = (role["default_model"] or "").strip()

    if not api_base:
        raise RuntimeError(f"è§’è‰² {role['code']} æœªé…ç½® api_base")
    if not api_key:
        raise RuntimeError(f"è§’è‰² {role['code']} æœªé…ç½® api_key")
    if not model:
        raise RuntimeError(f"è§’è‰² {role['code']} æœªé…ç½®æ¨¡å‹")

    base = api_base.rstrip("/")
    url = (base + "/chat/completions") if base.endswith("/v1") else (base + "/v1/chat/completions")
    payload = {
        "model": model,
        "messages": messages,
        "temperature": float(role["temperature"] if role["temperature"] is not None else 0.3),
        "max_tokens": int(role["max_tokens"] if role["max_tokens"] is not None else 1200),
    }
    body = json.dumps(payload, ensure_ascii=False).encode("utf-8")

    req = urllib.request.Request(
        url,
        data=body,
        method="POST",
        headers={
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        },
    )

    timeout = max(30, ROLE_DEFAULT_TIMEOUT)
    try:
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            raw = resp.read().decode("utf-8", errors="ignore")
    except urllib.error.HTTPError as e:
        detail = e.read().decode("utf-8", errors="ignore") if hasattr(e, "read") else str(e)
        raise RuntimeError(f"è§’è‰² {role['code']} æ¨¡å‹è¯·æ±‚å¤±è´¥: HTTP {getattr(e, 'code', '?')} {detail[:200]}")
    except Exception as e:
        raise RuntimeError(f"è§’è‰² {role['code']} æ¨¡å‹è¯·æ±‚å¼‚å¸¸: {e}")

    try:
        data = json.loads(raw)
    except Exception:
        raise RuntimeError(f"è§’è‰² {role['code']} è¿”å›éJSON: {raw[:200]}")

    text = _extract_content_from_chat_response(data)
    if not text:
        raise RuntimeError(f"è§’è‰² {role['code']} è¿”å›ç©ºå†…å®¹")
    return text


def is_verifier_stage(stage: str, role_code: str) -> bool:
    s = (stage or "")
    r = (role_code or "")
    return r == "@verifier" or any(k in s for k in ["éªŒè¯", "å¤æ ¸", "éªŒæ”¶", "review"])


def parse_verifier_feedback(text: str) -> dict:
    raw = (text or "").strip()
    out = {
        "decision": "UNKNOWN",
        "reason": "",
        "issues": [],
        "send_back_role": "",
        "rework_instructions": "",
    }
    if not raw:
        return out

    # ä¼˜å…ˆè§£æ JSON
    m = re.search(r"\{[\s\S]*\}", raw)
    if m:
        try:
            data = json.loads(m.group(0))
            dec = str(data.get("decision", "")).strip().upper()
            if dec in ("PASS", "FAIL"):
                out["decision"] = dec
            out["reason"] = str(data.get("reason", "")).strip()
            issues = data.get("issues") or []
            if isinstance(issues, list):
                out["issues"] = [str(x).strip() for x in issues if str(x).strip()]
            out["send_back_role"] = str(data.get("send_back_role", "")).strip()
            out["rework_instructions"] = str(data.get("rework_instructions", "")).strip()
            return out
        except Exception:
            pass

    upper = raw.upper()
    if "FAIL" in upper or "ä¸é€šè¿‡" in raw or "æ‰“å›" in raw:
        out["decision"] = "FAIL"
    elif "PASS" in upper or "é€šè¿‡" in raw:
        out["decision"] = "PASS"

    role_hit = re.search(r"(@[a-zA-Z0-9_\-]+)", raw)
    if role_hit:
        out["send_back_role"] = role_hit.group(1)

    lines = [ln.strip("- â€¢\t ") for ln in raw.splitlines() if ln.strip()]
    if lines:
        out["reason"] = lines[0][:300]
        out["issues"] = lines[1:6]
        out["rework_instructions"] = "ï¼›".join(lines[1:4])[:800]
    return out


def find_stage_index_by_role(stages: list, stage_roles: dict, role_code: str, before_idx: int, fallback_idx: int = 0) -> int:
    rc = (role_code or "").strip()
    if not rc:
        return fallback_idx
    for i in range(max(0, before_idx - 1), -1, -1):
        st = stages[i]
        if (stage_roles.get(st) or "").strip() == rc:
            return i
    return fallback_idx


def parse_dispatch_assignments(text: str, allowed_stages: list, enabled_role_codes: set) -> dict:
    raw = (text or "").strip()
    if not raw:
        return {}

    payload = None
    m = re.search(r"\{[\s\S]*\}", raw)
    if m:
        try:
            payload = json.loads(m.group(0))
        except Exception:
            payload = None

    out = {}
    if isinstance(payload, dict):
        assignments = payload.get("assignments") or payload.get("dispatch") or []
        if isinstance(assignments, list):
            for item in assignments:
                if not isinstance(item, dict):
                    continue
                stage = str(item.get("stage") or "").strip()
                role = str(item.get("role") or item.get("assignee") or "").strip()
                if stage in allowed_stages and role in enabled_role_codes:
                    out[stage] = role
        # å…¼å®¹ç›´æ¥ map
        if not out:
            for k, v in payload.items():
                ks = str(k).strip()
                vs = str(v).strip() if isinstance(v, (str, int, float)) else ""
                if ks in allowed_stages and vs in enabled_role_codes:
                    out[ks] = vs

    return out


def run_multi_agent_workflow(task_id: int, task, wf, output_dir: str):
    stages = parse_stages(wf["stages_json"])
    stage_roles = parse_stage_roles(wf["stage_roles_json"])
    if not stages:
        raise RuntimeError("å·¥ä½œæµæ²¡æœ‰é…ç½®é˜¶æ®µ")

    sections = parse_task_sections(task["description"] or "")
    previous_output = ""
    handoff_note = ""
    rework_round = 0
    stage_idx = 0
    execution_no = 0
    max_rework_rounds = ROLE_MAX_REWORK_ROUNDS
    max_stage_review_retries = ROLE_STAGE_REVIEW_MAX_RETRIES
    max_iterations = len(stages) * (max_rework_rounds + max_stage_review_retries + 4) + 12
    iterations = 0
    stage_retry_counts = {s: 0 for s in stages}

    enabled_role_codes = {r["code"] for r in get_roles(enabled_only=True)}

    audit = {
        "taskId": task_id,
        "workflow": wf["code"],
        "maxReworkRounds": max_rework_rounds,
        "maxStageReviewRetries": max_stage_review_retries,
        "reworkRoundsUsed": 0,
        "stages": [],
        "dynamicAssignments": {},
        "startedAt": now_str(),
    }

    while stage_idx < len(stages):
        iterations += 1
        if iterations > max_iterations:
            raise RuntimeError(f"è¶…è¿‡æœ€å¤§è¿­ä»£é™åˆ¶ï¼ˆ{max_iterations}ï¼‰ï¼Œå·²è‡ªåŠ¨ç»ˆæ­¢é¿å…å¾ªç¯")

        ensure_not_stopped(task_id)
        stage = stages[stage_idx]
        role_code = stage_roles.get(stage) or (wf["default_assignee"] or "") or (task["assignee"] or "Lead Agent")
        role = get_role_by_code(role_code)
        if not role:
            raise RuntimeError(f"é˜¶æ®µ {stage} æ‰¾ä¸åˆ°è§’è‰²: {role_code}")
        if int(role["enabled"] or 0) != 1:
            raise RuntimeError(f"é˜¶æ®µ {stage} è§’è‰²æœªå¯ç”¨: {role_code}")

        stage_retry = stage_retry_counts.get(stage, 0)
        append_log(task_id, f"[Lead Agent] é˜¶æ®µ{stage_idx+1}/{len(stages)}ï¼š{stage} -> {role_code}ï¼ˆè¿”å·¥è½®æ¬¡={rework_round}ï¼Œæœ¬é˜¶æ®µé‡è¯•={stage_retry}/{max_stage_review_retries}ï¼‰")

        history = load_role_messages(task_id, role_code, limit=10)
        sys_prompt = (role["system_prompt"] or "").strip()
        if not sys_prompt:
            sys_prompt = f"ä½ æ˜¯{role['name']}ï¼ˆ{role['code']}ï¼‰ï¼ŒèŒè´£ï¼š{role['description'] or 'å®Œæˆè¢«åˆ†é…é˜¶æ®µå¹¶è¾“å‡ºå¯æ‰§è¡Œç»“æœ'}ã€‚"

        verifier_mode = is_verifier_stage(stage, role_code)
        lead_dispatch_mode = (role_code == "Lead Agent" and ("åˆ†å‘" in stage or stage_idx == 0))
        if verifier_mode:
            stage_instruction = (
                "ä½ åªè´Ÿè´£å½“å‰å¤æ ¸é˜¶æ®µï¼Œä¸è´Ÿè´£å¼€å‘å®ç°ã€‚è¯·ä¸¥æ ¼ä¾æ®ä»»åŠ¡è¦æ±‚åˆ¤å®šæ˜¯å¦é€šè¿‡ã€‚"
                "å¿…é¡»è¿”å› JSONï¼š"
                '{"decision":"PASS|FAIL","reason":"...","issues":["..."],"send_back_role":"@developer æˆ– @tester","rework_instructions":"..."}'
                "ã€‚å¦‚æœé€šè¿‡ï¼Œissueså¯ä¸ºç©ºï¼Œsend_back_roleå¯ç©ºã€‚"
            )
        elif lead_dispatch_mode:
            stage_instruction = (
                "ä½ æ˜¯æ€»æ§åˆ†å‘é˜¶æ®µï¼šå…ˆæ¥æ”¶éœ€æ±‚ï¼Œå†æŒ‰åç»­è§’è‰²åˆ†å‘ä»»åŠ¡ã€‚"
                "è¯·è¾“å‡ºâ€œåˆ†å‘æ¸…å•â€ï¼Œè‡³å°‘åŒ…å«ï¼šè§’è‰²ã€è¯¥è§’è‰²ç›®æ ‡ã€è¾“å…¥ã€è¾“å‡ºã€éªŒæ”¶æ ‡å‡†ã€‚"
                "ä¸è¦æ›¿æ‰§è¡Œè§’è‰²å®Œæˆå®ç°ï¼Œåªåšæ‹†è§£å’Œåˆ†å‘ã€‚"
                "å¹¶åœ¨ç»“å°¾é™„ä¸Š JSONï¼ˆassignmentsï¼‰ç”¨äºåŠ¨æ€åˆ†å‘ï¼Œä¾‹å¦‚ï¼š"
                '{"assignments":[{"stage":"å¼€å‘","role":"@developer"},{"stage":"æµ‹è¯•","role":"@tester"}]}'
                "ã€‚stage å¿…é¡»æ˜¯ç°æœ‰é˜¶æ®µåï¼Œrole å¿…é¡»æ˜¯å¯ç”¨è§’è‰² codeã€‚"
            )
        else:
            stage_instruction = (
                "ä½ åªè´Ÿè´£å½“å‰é˜¶æ®µï¼Œä¸è¦æ›¿ä¸‹ä¸€é˜¶æ®µåšå†³å®šã€‚"
                "è¾“å‡ºæœ¬é˜¶æ®µå¯ç›´æ¥äº¤æ¥ç»™ä¸‹é˜¶æ®µçš„ç»“æœï¼ˆä¸­æ–‡ã€ç»“æ„åŒ–ã€å¯æ‰§è¡Œï¼‰ã€‚"
            )

        user_prompt = (
            f"ä½ å½“å‰è´Ÿè´£é˜¶æ®µï¼š{stage}\n"
            f"ä»»åŠ¡æ ‡é¢˜ï¼š{task['title']}\n"
            f"ä»»åŠ¡æè¿°ï¼š{sections.get('task') or task['description'] or ''}\n"
            f"æœŸæœ›äº¤ä»˜ï¼š{sections.get('delivery') or ''}\n"
            f"è¡¥å……è¯´æ˜ï¼š{sections.get('extra') or ''}\n"
            f"ä¸Šä¸€ä¸ªé˜¶æ®µè¾“å‡ºï¼ˆè‹¥ä¸ºç©ºå¯å¿½ç•¥ï¼‰ï¼š\n{previous_output}\n\n"
            f"è¿”å·¥/äº¤æ¥è¯´æ˜ï¼ˆè‹¥ä¸ºç©ºå¯å¿½ç•¥ï¼‰ï¼š\n{handoff_note}\n\n"
            f"é˜¶æ®µè§„åˆ™ï¼š{stage_instruction}"
        )

        messages = [{"role": "system", "content": sys_prompt}]
        for h in history:
            turn = (h["turn"] or "").strip().lower()
            if turn in ("user", "assistant", "system"):
                messages.append({"role": turn, "content": h["content"] or ""})
        messages.append({"role": "user", "content": user_prompt})

        stage_started_at = now_str()
        stage_t0 = time.perf_counter()
        save_role_message(task_id, role_code, stage, "user", user_prompt)
        output = call_role_llm(role, messages)
        save_role_message(task_id, role_code, stage, "assistant", output)
        stage_duration_sec = round(time.perf_counter() - stage_t0, 2)

        execution_no += 1
        stage_file = os.path.join(
            output_dir,
            f"æ­¥éª¤{execution_no}_é˜¶æ®µ{stage_idx+1}_{stage}_{role_code.replace('@', 'at_').replace(' ', '_')}.md",
        )
        with open(stage_file, "w", encoding="utf-8") as f:
            f.write(f"# æ­¥éª¤{execution_no}ï½œé˜¶æ®µ{stage_idx+1}ï¼š{stage}\n\n")
            f.write(f"è§’è‰²ï¼š{role['name']}ï¼ˆ{role['code']}ï¼‰\n")
            f.write(f"è¿”å·¥è½®æ¬¡ï¼š{rework_round}\n\n")
            f.write(output + "\n")

        stage_audit = {
            "executionNo": execution_no,
            "index": stage_idx + 1,
            "stage": stage,
            "role": role_code,
            "model": role["default_model"],
            "reworkRound": rework_round,
            "startedAt": stage_started_at,
            "durationSec": stage_duration_sec,
            "outputFile": os.path.basename(stage_file),
            "outputChars": len(output),
            "finishedAt": now_str(),
        }

        # åŠ¨æ€åˆ†å‘ï¼šLead åœ¨â€œéœ€æ±‚æ¥æ”¶ä¸åˆ†å‘â€é˜¶æ®µå¯åŠ¨æ€æ”¹å†™åç»­é˜¶æ®µè§’è‰²
        if lead_dispatch_mode:
            dynamic = parse_dispatch_assignments(output, stages[stage_idx + 1 :], enabled_role_codes)
            if dynamic:
                stage_roles.update(dynamic)
                audit["dynamicAssignments"].update(dynamic)
                stage_audit["dynamicAssignments"] = dynamic
                append_log(task_id, f"[Lead Agent] åŠ¨æ€åˆ†å‘ç”Ÿæ•ˆï¼š{json.dumps(dynamic, ensure_ascii=False)}")
            else:
                append_log(task_id, "[Lead Agent] æœªè§£æåˆ°æœ‰æ•ˆåŠ¨æ€åˆ†å‘JSONï¼Œæ²¿ç”¨å·¥ä½œæµé»˜è®¤åˆ†é…")

        # æ¯ä¸ªæ‰§è¡Œè§’è‰²å®Œæˆåéƒ½åšé˜¶æ®µè´¨æ§ï¼ˆç”± @verifier å¤æ ¸ï¼‰
        if (not verifier_mode) and (not lead_dispatch_mode):
            reviewer_role = get_role_by_code("@verifier")
            if reviewer_role and int(reviewer_role["enabled"] or 0) == 1:
                review_stage = f"{stage}-é˜¶æ®µè´¨æ§"
                review_prompt = (
                    "ä½ æ˜¯é˜¶æ®µè´¨æ§å¤æ ¸ã€‚è¯·åªå¯¹å½“å‰é˜¶æ®µè¾“å‡ºè¿›è¡ŒéªŒæ”¶ï¼Œä¸è¦é‡å†™å®ç°ã€‚"
                    f"å½“å‰é˜¶æ®µï¼š{stage}ï¼Œæ‰§è¡Œè§’è‰²ï¼š{role_code}ã€‚\n"
                    f"ä»»åŠ¡ç›®æ ‡ï¼š{sections.get('task') or task['description'] or ''}\n"
                    f"æœŸæœ›äº¤ä»˜ï¼š{sections.get('delivery') or ''}\n"
                    f"æœ¬é˜¶æ®µè¾“å‡ºï¼š\n{output}\n\n"
                    "è¯·è¿”å› JSONï¼š"
                    '{"decision":"PASS|FAIL","reason":"...","issues":["..."],"send_back_role":"å½“å‰è§’è‰²code","rework_instructions":"..."}'
                    "ã€‚è‹¥ FAILï¼Œsend_back_role ä¼˜å…ˆå¡«å½“å‰è§’è‰²ã€‚"
                )
                review_msgs = [
                    {
                        "role": "system",
                        "content": (reviewer_role["system_prompt"] or "ä½ æ˜¯ä¸¥æ ¼è´¨æ§å¤æ ¸è§’è‰²ã€‚"),
                    },
                    {"role": "user", "content": review_prompt},
                ]
                save_role_message(task_id, "@verifier", review_stage, "user", review_prompt)
                review_output = call_role_llm(reviewer_role, review_msgs)
                save_role_message(task_id, "@verifier", review_stage, "assistant", review_output)
                quality = parse_verifier_feedback(review_output)
                stage_audit["qualityGate"] = {"raw": review_output, "decision": quality}

                q_dec = quality.get("decision", "UNKNOWN")
                append_log(task_id, f"[@verifier] é˜¶æ®µè´¨æ§ç»“è®ºï¼š{q_dec} | stage={stage} | reason={quality.get('reason','')[:120]}")

                if q_dec != "PASS":
                    if stage_retry >= max_stage_review_retries:
                        stage_audit["terminatedByStageReview"] = True
                        audit["stages"].append(stage_audit)
                        raise RuntimeError(f"é˜¶æ®µ {stage} è´¨æ§æœªé€šè¿‡ï¼Œä¸”å·²è¾¾æœ¬é˜¶æ®µæœ€å¤§é‡è¯• {max_stage_review_retries}")

                    stage_retry_counts[stage] = stage_retry + 1
                    handoff_note = (
                        f"é˜¶æ®µè´¨æ§æœªé€šè¿‡ï¼ˆ{stage}ï¼Œç¬¬{stage_retry_counts[stage]}æ¬¡é‡è¯•ï¼‰ã€‚"
                        f"åŸå› ï¼š{quality.get('reason','')}ã€‚"
                        f"é—®é¢˜ï¼š{'ï¼›'.join(quality.get('issues') or [])}ã€‚"
                        f"ä¿®æ”¹è¦æ±‚ï¼š{quality.get('rework_instructions','è¯·æ ¹æ®è´¨æ§æ„è§ä¿®æ”¹åé‡æ–°æäº¤æœ¬é˜¶æ®µã€‚')}"
                    )
                    append_log(
                        task_id,
                        f"[Lead Agent] é˜¶æ®µè´¨æ§æœªé€šè¿‡ï¼Œæ‰“å›å½“å‰é˜¶æ®µé‡åšï¼š{stage}ï¼ˆ{stage_retry_counts[stage]}/{max_stage_review_retries}ï¼‰",
                    )
                    previous_output = output
                    audit["stages"].append(stage_audit)
                    continue
                else:
                    stage_retry_counts[stage] = 0
            else:
                stage_audit["qualityGate"] = {"decision": {"decision": "SKIP", "reason": "@verifierä¸å¯ç”¨ï¼Œè·³è¿‡é˜¶æ®µè´¨æ§"}}

        # å·¥ä½œæµä¸­çš„â€œéªŒè¯/å¤æ ¸â€æ­£å¼é˜¶æ®µï¼šå¯è§¦å‘è·¨é˜¶æ®µæ‰“å›
        if verifier_mode:
            decision = parse_verifier_feedback(output)
            stage_audit["reviewDecision"] = decision
            dec = decision.get("decision", "UNKNOWN")
            append_log(task_id, f"[{role_code}] å¤æ ¸ç»“è®ºï¼š{dec} | reason={decision.get('reason','')[:120]}")

            if dec != "PASS":
                if rework_round >= max_rework_rounds:
                    stage_audit["terminatedByMaxRework"] = True
                    audit["stages"].append(stage_audit)
                    audit["reworkRoundsUsed"] = rework_round
                    raise RuntimeError(f"å¤æ ¸æœªé€šè¿‡ï¼Œå·²è¾¾æœ€å¤§è¿”å·¥è½®æ¬¡ {max_rework_rounds}ï¼Œä»»åŠ¡ç»ˆæ­¢")

                target_role = (decision.get("send_back_role") or "").strip()
                target_idx = find_stage_index_by_role(stages, stage_roles, target_role, stage_idx, fallback_idx=max(0, stage_idx - 1))
                rework_round += 1
                audit["reworkRoundsUsed"] = rework_round
                handoff_note = (
                    f"å¤æ ¸ä¸é€šè¿‡ï¼ˆç¬¬{rework_round}è½®è¿”å·¥ï¼‰ã€‚"
                    f"åŸå› ï¼š{decision.get('reason','')}ã€‚"
                    f"é—®é¢˜ï¼š{'ï¼›'.join(decision.get('issues') or [])}ã€‚"
                    f"ä¿®æ”¹è¦æ±‚ï¼š{decision.get('rework_instructions','è¯·æ ¹æ®å¤æ ¸æ„è§ä¿®æ”¹åæäº¤ã€‚')}"
                )
                append_log(
                    task_id,
                    f"[Lead Agent] å¤æ ¸æœªé€šè¿‡ï¼Œæ‰“å›åˆ°é˜¶æ®µ{target_idx+1}ï¼ˆ{stages[target_idx]}ï¼‰ï¼Œè¿”å·¥è½®æ¬¡={rework_round}/{max_rework_rounds}",
                )
                previous_output = output
                audit["stages"].append(stage_audit)
                stage_idx = target_idx
                continue

        previous_output = output
        handoff_note = ""
        audit["stages"].append(stage_audit)
        append_log(task_id, f"[{role_code}] é˜¶æ®µå®Œæˆï¼Œè¾“å‡ºé•¿åº¦={len(output)}ï¼Œè€—æ—¶={stage_duration_sec}s")
        stage_idx += 1

    final_file = os.path.join(output_dir, "å¤šAgent_æœ€ç»ˆäº¤ä»˜.md")
    with open(final_file, "w", encoding="utf-8") as f:
        f.write(f"# å¤šAgentæœ€ç»ˆäº¤ä»˜\n\nä»»åŠ¡ï¼š{task['title']}\n\n")
        f.write(previous_output + "\n")

    audit["finishedAt"] = now_str()
    audit["finalFile"] = os.path.basename(final_file)
    audit_file = os.path.join(output_dir, "å¤šAgent_ä¼šè¯å®¡è®¡.json")
    with open(audit_file, "w", encoding="utf-8") as f:
        json.dump(audit, f, ensure_ascii=False, indent=2)

    append_log(task_id, f"[Lead Agent] å¤šAgentç‹¬ç«‹ä¼šè¯å®Œæˆï¼Œæœ€ç»ˆäº¤ä»˜ï¼š{os.path.basename(final_file)}")


def login_required(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        if not session.get("logged_in"):
            return redirect(url_for("login"))
        return fn(*args, **kwargs)

    return wrapper


@app.errorhandler(413)
def payload_too_large(_):
    flash("ä¸Šä¼ æ–‡ä»¶è¿‡å¤§ï¼ˆå•æ¬¡è¯·æ±‚ä¸Šé™ 200MBï¼‰ï¼Œè¯·å‹ç¼©åé‡è¯•ã€‚")
    return redirect(url_for("dashboard")), 413


def run_task(task_id: int):
    task = get_task(task_id)
    if not task:
        running_processes.pop(task_id, None)
        return

    with limiter.acquire():
        update_task(task_id, status="running", started_at=now_str(), return_code=None)
        base_dir, input_dir, output_dir = task_artifact_dirs(task_id)
        append_log(task_id, f"[SYSTEM] ä»»åŠ¡å¯åŠ¨ï¼Œå½“å‰å¹¶å‘ä¸Šé™={limiter.get_limit()}")
        append_log(task_id, f"[SYSTEM] ä»»åŠ¡äº§ç‰©ç›®å½•: {base_dir}")
        append_log(task_id, f"[SYSTEM] è¾“å…¥é™„ä»¶ç›®å½•: {input_dir}")
        append_log(task_id, f"[SYSTEM] è¾“å‡ºäº§ç‰©ç›®å½•: {output_dir}")

        cmd = (task["command"] or "").strip()
        if not cmd:
            wf_code = (task["workflow_code"] or "").strip() if "workflow_code" in task.keys() else ""
            if wf_code:
                try:
                    wf = get_workflow_by_code(wf_code)
                    if not wf:
                        raise RuntimeError(f"æœªæ‰¾åˆ°å·¥ä½œæµ: {wf_code}")
                    append_log(task_id, f"[SYSTEM] å¯åŠ¨å¤šAgentç‹¬ç«‹ä¼šè¯æµç¨‹ï¼š{wf_code}")
                    run_multi_agent_workflow(task_id, task, wf, output_dir)
                    update_task(task_id, status="done", finished_at=now_str(), return_code=0)
                    append_log(task_id, "[SYSTEM] ä»»åŠ¡å®Œæˆï¼ˆå¤šAgentç‹¬ç«‹ä¼šè¯ï¼‰")
                except Exception as e:
                    update_task(task_id, status="failed", finished_at=now_str(), return_code=1)
                    append_log(task_id, f"[SYSTEM] å¤šAgentæµç¨‹å¤±è´¥ï¼š{e}")
                finally:
                    running_processes.pop(task_id, None)
                return

            # æ— å·¥ä½œæµæ—¶ä¿ç•™æ¼”ç¤ºæµç¨‹
            try:
                for step in [
                    "Lead Agent æ­£åœ¨æ‹†è§£ä»»åŠ¡...",
                    "Developer Agent æ­£åœ¨æ‰§è¡Œä»»åŠ¡...",
                    "Tester Agent æ­£åœ¨å¤æ ¸ç»“æœ...",
                    "Verifier Agent æ­£åœ¨åšæœ€ç»ˆæ ¸éªŒ...",
                    "Lead Agent æ­£åœ¨æ±‡æ€»äº¤ä»˜...",
                ]:
                    ensure_not_stopped(task_id)
                    append_log(task_id, step)
                    time.sleep(2)
                update_task(task_id, status="done", finished_at=now_str(), return_code=0)
                append_log(task_id, "[SYSTEM] ä»»åŠ¡å®Œæˆï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰")
            except Exception as e:
                update_task(task_id, status="failed", finished_at=now_str(), return_code=1)
                append_log(task_id, f"[SYSTEM] ä»»åŠ¡å¤±è´¥ï¼š{e}")
            finally:
                running_processes.pop(task_id, None)
            return

        try:
            append_log(task_id, f"[SYSTEM] æ‰§è¡Œå‘½ä»¤: {cmd}")
            env = os.environ.copy()
            env.update(
                {
                    "TASK_ID": str(task_id),
                    "TASK_ARTIFACT_DIR": base_dir,
                    "TASK_INPUT_DIR": input_dir,
                    "TASK_OUTPUT_DIR": output_dir,
                }
            )
            proc = subprocess.Popen(
                cmd,
                shell=True,
                cwd=WORKDIR,
                executable="/bin/bash",
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
            )
            running_processes[task_id] = proc

            for line in iter(proc.stdout.readline, ""):
                if not line:
                    break
                append_log(task_id, line.rstrip())

            rc = proc.wait()
            update_task(
                task_id,
                status="done" if rc == 0 else "failed",
                finished_at=now_str(),
                return_code=rc,
            )
            append_log(task_id, f"[SYSTEM] ä»»åŠ¡ç»“æŸï¼Œrc={rc}")
        except Exception as e:
            update_task(task_id, status="failed", finished_at=now_str(), return_code=1)
            append_log(task_id, f"[SYSTEM] æ‰§è¡Œå¼‚å¸¸ï¼š{e}")
        finally:
            running_processes.pop(task_id, None)


def start_task(task_id: int):
    if task_id in running_processes:
        return False, "ä»»åŠ¡å·²åœ¨è¿è¡Œæˆ–æ’é˜Ÿä¸­"
    task = get_task(task_id)
    if not task:
        return False, "ä»»åŠ¡ä¸å­˜åœ¨"
    if task["status"] == "running":
        return False, "ä»»åŠ¡çŠ¶æ€å·²æ˜¯ running"

    running_processes[task_id] = None
    t = threading.Thread(target=run_task, args=(task_id,), daemon=True)
    t.start()
    return True, "å·²å¯åŠ¨ï¼ˆå¦‚å¹¶å‘å·²æ»¡ä¼šè‡ªåŠ¨æ’é˜Ÿï¼‰"


@app.before_request
def _attach_globals():
    g.max_concurrent = limiter.get_limit()
    g.active_workers = limiter.get_running()
    g.artifact_root = ARTIFACT_ROOT
    g.workdir = WORKDIR


@app.route("/healthz")
def healthz():
    return {
        "ok": True,
        "time": now_str(),
        "maxConcurrent": limiter.get_limit(),
        "activeWorkers": limiter.get_running(),
    }


@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = request.form.get("username", "")
        password = request.form.get("password", "")
        if username == ADMIN_USERNAME and password == ADMIN_PASSWORD:
            session["logged_in"] = True
            session["username"] = username
            return redirect(url_for("dashboard"))
        flash("è´¦å·æˆ–å¯†ç é”™è¯¯")
    return render_template("login.html")


@app.route("/logout")
def logout():
    session.clear()
    return redirect(url_for("login"))


@app.route("/")
@login_required
def dashboard():
    with db_conn() as conn:
        tasks = conn.execute(
            "SELECT * FROM tasks ORDER BY CASE status WHEN 'running' THEN 0 WHEN 'pending' THEN 1 ELSE 2 END, id DESC"
        ).fetchall()

        stats = {
            "pending": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='pending'").fetchone()["c"],
            "running": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='running'").fetchone()["c"],
            "done": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='done'").fetchone()["c"],
            "failed": conn.execute("SELECT COUNT(*) c FROM tasks WHERE status='failed'").fetchone()["c"],
        }

    phase_order = ["å¾…å¤„ç†", "æ‰§è¡Œä¸­", "å¾…ç¡®è®¤"]
    tasks_by_phase = {k: [] for k in phase_order}
    for t in tasks:
        phase = infer_business_phase(t)
        tasks_by_phase.setdefault(phase, []).append(t)

    roles = get_roles(enabled_only=False)
    workflows = get_workflows(enabled_only=False)

    queue_count = max(0, len(running_processes) - limiter.get_running())
    return render_template(
        "dashboard.html",
        tasks=tasks,
        stats=stats,
        tasks_by_phase=tasks_by_phase,
        phase_order=phase_order,
        roles=roles,
        workflows=workflows,
        running_count=len(running_processes),
        queue_count=queue_count,
    )


@app.route("/artifacts")
@login_required
def artifacts_page():
    files = list_artifacts()
    return render_template("artifacts.html", files=files, artifact_root=ARTIFACT_ROOT)


@app.route("/artifacts/download/<path:rel_path>")
@login_required
def artifacts_download(rel_path: str):
    safe_full = safe_join_under(ARTIFACT_ROOT, rel_path)
    if not safe_full:
        abort(400)
    if not os.path.isfile(safe_full):
        abort(404)
    return send_from_directory(ARTIFACT_ROOT, rel_path, as_attachment=True)


@app.post("/artifacts/clear")
@login_required
def artifacts_clear_note():
    flash("å½“å‰ç‰ˆæœ¬ä¸ºå®‰å…¨èµ·è§æœªå¼€æ”¾ç½‘é¡µåˆ é™¤æ–‡ä»¶ï¼›è¯·åœ¨æœåŠ¡å™¨ä¸Šæ‰‹åŠ¨æ¸…ç†äº§ç‰©ç›®å½•ã€‚")
    return redirect(url_for("artifacts_page"))


@app.post("/settings/concurrency")
@login_required
def set_concurrency():
    raw = (request.form.get("max_concurrent") or "").strip()
    try:
        val = int(raw)
    except Exception:
        flash("å¹¶å‘ä¸Šé™å¿…é¡»æ˜¯æ•°å­—ï¼ˆ1-16ï¼‰")
        return redirect(url_for("dashboard"))

    if val < 1 or val > 16:
        flash("å¹¶å‘ä¸Šé™èŒƒå›´å¿…é¡»åœ¨ 1-16")
        return redirect(url_for("dashboard"))

    set_setting("max_concurrent", str(val))
    limiter.set_limit(val)
    flash(f"å¹¶å‘ä¸Šé™å·²æ›´æ–°ä¸º {val}ï¼ˆå³æ—¶ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯ï¼‰")
    return redirect(url_for("dashboard"))


@app.post("/roles")
@login_required
def create_role():
    code = (request.form.get("code") or "").strip()
    name = (request.form.get("name") or "").strip()
    description = (request.form.get("description") or "").strip()
    default_model = (request.form.get("default_model") or "").strip() or "gpt-5.3-codex"
    api_base = (request.form.get("api_base") or "").strip()
    api_key = (request.form.get("api_key") or "").strip()
    system_prompt = (request.form.get("system_prompt") or "").strip()
    enabled = 1 if (request.form.get("enabled") or "1") == "1" else 0

    if not code or not name:
        flash("è§’è‰²åˆ›å»ºå¤±è´¥ï¼šcode å’Œ name ä¸èƒ½ä¸ºç©º")
        return redirect(url_for("dashboard"))

    try:
        with db_conn() as conn:
            conn.execute(
                """
                INSERT INTO roles(code, name, description, default_model, api_base, api_key, system_prompt, enabled, created_at, updated_at)
                VALUES(?,?,?,?,?,?,?,?,?,?)
                """,
                (code, name, description, default_model, api_base, api_key, system_prompt, enabled, now_str(), now_str()),
            )
        flash(f"è§’è‰²å·²åˆ›å»ºï¼š{name}ï¼ˆ{code}ï¼‰")
    except sqlite3.IntegrityError:
        flash("è§’è‰²åˆ›å»ºå¤±è´¥ï¼šcode å·²å­˜åœ¨")
    except Exception as e:
        flash(f"è§’è‰²åˆ›å»ºå¤±è´¥ï¼š{e}")

    return redirect(url_for("dashboard"))


@app.post("/roles/<int:role_id>/toggle")
@login_required
def toggle_role(role_id: int):
    with db_conn() as conn:
        row = conn.execute("SELECT enabled, name FROM roles WHERE id=?", (role_id,)).fetchone()
        if not row:
            flash("è§’è‰²ä¸å­˜åœ¨")
            return redirect(url_for("dashboard"))
        nxt = 0 if int(row["enabled"] or 0) == 1 else 1
        conn.execute("UPDATE roles SET enabled=?, updated_at=? WHERE id=?", (nxt, now_str(), role_id))
    flash(f"è§’è‰²å·²{'å¯ç”¨' if nxt == 1 else 'åœç”¨'}ï¼š{row['name']}")
    return redirect(url_for("dashboard"))


@app.post("/roles/<int:role_id>/config")
@login_required
def update_role_config(role_id: int):
    default_model = (request.form.get("default_model") or "").strip()
    api_base = (request.form.get("api_base") or "").strip()
    api_key = (request.form.get("api_key") or "").strip()
    system_prompt = (request.form.get("system_prompt") or "").strip()
    temperature = (request.form.get("temperature") or "").strip()
    max_tokens = (request.form.get("max_tokens") or "").strip()

    with db_conn() as conn:
        row = conn.execute("SELECT * FROM roles WHERE id=?", (role_id,)).fetchone()
        if not row:
            flash("è§’è‰²ä¸å­˜åœ¨")
            return redirect(url_for("dashboard"))

        fields = {
            "default_model": default_model or row["default_model"],
            "api_base": api_base or row["api_base"],
            "system_prompt": system_prompt if system_prompt else (row["system_prompt"] or ""),
            "updated_at": now_str(),
        }

        # api_key ä¸ºç©ºæ—¶ä¿æŒåŸå€¼
        fields["api_key"] = api_key if api_key else (row["api_key"] or "")

        try:
            fields["temperature"] = float(temperature) if temperature else (row["temperature"] if row["temperature"] is not None else 0.3)
        except Exception:
            fields["temperature"] = row["temperature"] if row["temperature"] is not None else 0.3

        try:
            fields["max_tokens"] = int(max_tokens) if max_tokens else (row["max_tokens"] if row["max_tokens"] is not None else 1200)
        except Exception:
            fields["max_tokens"] = row["max_tokens"] if row["max_tokens"] is not None else 1200

        conn.execute(
            """
            UPDATE roles
            SET default_model=?, api_base=?, api_key=?, system_prompt=?, temperature=?, max_tokens=?, updated_at=?
            WHERE id=?
            """,
            (
                fields["default_model"],
                fields["api_base"],
                fields["api_key"],
                fields["system_prompt"],
                fields["temperature"],
                fields["max_tokens"],
                fields["updated_at"],
                role_id,
            ),
        )

    flash(f"è§’è‰²é…ç½®å·²æ›´æ–°ï¼š{row['name']}")
    return redirect(url_for("dashboard"))


@app.post("/workflows")
@login_required
def create_workflow():
    code = (request.form.get("code") or "").strip()
    name = (request.form.get("name") or "").strip()
    description = (request.form.get("description") or "").strip()
    stages_text = (request.form.get("stages") or "").strip()
    stage_roles_text = (request.form.get("stage_roles") or "").strip()
    default_task_type = (request.form.get("default_task_type") or "general").strip()
    default_assignee = (request.form.get("default_assignee") or "Lead Agent").strip()
    command_template = (request.form.get("command_template") or "").strip()
    enabled = 1 if (request.form.get("enabled") or "1") == "1" else 0

    if not code or not name:
        flash("å·¥ä½œæµåˆ›å»ºå¤±è´¥ï¼šcode å’Œ name ä¸èƒ½ä¸ºç©º")
        return redirect(url_for("dashboard"))

    stages = [x.strip() for x in re.split(r"[,ï¼Œ\n]+", stages_text) if x.strip()]
    stage_roles = parse_stage_roles(stage_roles_text)
    stages_json = json.dumps(stages, ensure_ascii=False)
    stage_roles_json = json.dumps(stage_roles, ensure_ascii=False)

    try:
        with db_conn() as conn:
            conn.execute(
                """
                INSERT INTO workflows(code, name, description, stages_json, stage_roles_json, default_task_type, default_assignee, command_template, enabled, created_at, updated_at)
                VALUES(?,?,?,?,?,?,?,?,?,?,?)
                """,
                (
                    code,
                    name,
                    description,
                    stages_json,
                    stage_roles_json,
                    default_task_type,
                    default_assignee,
                    command_template,
                    enabled,
                    now_str(),
                    now_str(),
                ),
            )
        flash(f"å·¥ä½œæµå·²åˆ›å»ºï¼š{name}ï¼ˆ{code}ï¼‰")
    except sqlite3.IntegrityError:
        flash("å·¥ä½œæµåˆ›å»ºå¤±è´¥ï¼šcode å·²å­˜åœ¨")
    except Exception as e:
        flash(f"å·¥ä½œæµåˆ›å»ºå¤±è´¥ï¼š{e}")

    return redirect(url_for("dashboard"))


@app.post("/workflows/<int:workflow_id>/toggle")
@login_required
def toggle_workflow(workflow_id: int):
    with db_conn() as conn:
        row = conn.execute("SELECT enabled, name FROM workflows WHERE id=?", (workflow_id,)).fetchone()
        if not row:
            flash("å·¥ä½œæµä¸å­˜åœ¨")
            return redirect(url_for("dashboard"))
        nxt = 0 if int(row["enabled"] or 0) == 1 else 1
        conn.execute("UPDATE workflows SET enabled=?, updated_at=? WHERE id=?", (nxt, now_str(), workflow_id))
    flash(f"å·¥ä½œæµå·²{'å¯ç”¨' if nxt == 1 else 'åœç”¨'}ï¼š{row['name']}")
    return redirect(url_for("dashboard"))


def derive_title(title_raw: str, brief: str, template_name: str) -> str:
    title = (title_raw or "").strip()
    if title:
        return title
    brief_line = re.sub(r"\s+", " ", (brief or "").strip())
    if brief_line:
        return (brief_line[:36] + "...") if len(brief_line) > 36 else brief_line
    mapping = {
        "novel_multiagent": "å°è¯´ç±»ç›®çˆ†æ¬¾æ–‡åŒ…ä»»åŠ¡",
        "xhs_virtual_keywords": "å°çº¢ä¹¦é«˜é¢‘è¯ä»»åŠ¡",
        "custom_brief": "å£è¯­åŒ–ä»»åŠ¡",
    }
    return mapping.get(template_name, "æ–°ä»»åŠ¡")


def build_command_from_template(template_name: str, project_dir: str, task_brief: str) -> str:
    workdir = (project_dir or WORKDIR).strip() or WORKDIR

    if template_name == "novel_multiagent":
        keywords = "å°è¯´æ¨æ–‡,å°è¯´æ¨è,ç½‘æ–‡,è¨€æƒ…å°è¯´,æ‚¬ç–‘å°è¯´,å®Œç»“å°è¯´,ä¹¦è’æ¨è,ç•ªèŒ„å°è¯´,çˆ½æ–‡å°è¯´,æ¨ç†å°è¯´"
        if "å°çº¢ä¹¦" not in task_brief and "å°è¯´" in task_brief:
            keywords = "å°è¯´æ¨è,ç½‘æ–‡æ¨è,è¨€æƒ…å°è¯´,æ‚¬ç–‘å°è¯´,æ¨ç†å°è¯´,ä¹¦è’æ¨è,å®Œç»“å°è¯´"
        return (
            f"cd {workdir} && python3 scripts/xhs_novel_multiagent_pipeline.py "
            f"--keywords '{keywords}' "
            "--cookie-file $TASK_INPUT_DIR/xhs_cookies.json "
            "--output-dir $TASK_OUTPUT_DIR "
            "--max-rounds 3 --min-usable 8 --min-domain-ratio 0.75 --max-noise-ratio 0.35 "
            "--pack-format zip"
        )

    # ä¼˜å…ˆä½¿ç”¨å·¥ä½œæµä¸­å¿ƒé…ç½®çš„å‘½ä»¤æ¨¡æ¿
    wf = get_workflow_by_code(template_name)
    if wf and (wf["command_template"] or "").strip():
        return (wf["command_template"] or "").replace("__PROJECT_DIR__", workdir)

    if template_name == "xhs_virtual_keywords":
        return (
            f"cd {workdir} && python3 scripts/xhs_virtual_keywords.py "
            "--keywords 'è™šæ‹Ÿäº§å“,æ•°å­—äº§å“,PPTæ¨¡æ¿,ç®€å†æ¨¡æ¿,æ•™ç¨‹è¯¾ç¨‹,AIæç¤ºè¯,ç´ æåŒ…,èµ„æ–™åŒ…' "
            "--cookie-file $TASK_INPUT_DIR/xhs_cookies.json "
            "--scrolls 4 --auto-related 2 --max-keywords 24 --domain general "
            "--strict --min-usable 4 "
            "--out-md $TASK_OUTPUT_DIR/xhs_virtual_keywords.md "
            "--out-json $TASK_OUTPUT_DIR/xhs_virtual_keywords.json"
        )

    return ""


@app.post("/tasks")
@login_required
def create_task():
    workflow_template = (request.form.get("workflow_template") or "custom_brief").strip()
    task_brief = (request.form.get("task_brief") or "").strip()
    delivery_expectation = (request.form.get("delivery_expectation") or "").strip()
    project_dir = (request.form.get("project_dir") or "").strip()

    title = derive_title(request.form.get("title", ""), task_brief, workflow_template)
    if not title:
        flash("è¯·è‡³å°‘å¡«å†™ä»»åŠ¡æè¿°æˆ–æ ‡é¢˜")
        return redirect(url_for("dashboard"))

    description_raw = (request.form.get("description", "") or "").strip()
    desc_parts = []
    if task_brief:
        desc_parts.append(f"ã€ä»»åŠ¡æè¿°ã€‘\n{task_brief}")
    if delivery_expectation:
        desc_parts.append(f"ã€æœŸæœ›äº¤ä»˜ã€‘\n{delivery_expectation}")
    if description_raw:
        desc_parts.append(f"ã€è¡¥å……è¯´æ˜ã€‘\n{description_raw}")
    description = "\n\n".join(desc_parts).strip()

    wf = get_workflow_by_code(workflow_template)

    task_type = (request.form.get("task_type") or "general").strip()
    assignee = (request.form.get("assignee") or "Lead Agent").strip()
    priority = (request.form.get("priority") or "P2").strip()

    # è‹¥æœªæ‰‹å·¥æŒ‡å®šï¼Œä¼˜å…ˆå¥—ç”¨å·¥ä½œæµé»˜è®¤è§’è‰²/ç±»å‹
    if wf:
        if task_type == "general" and (wf["default_task_type"] or "").strip():
            task_type = (wf["default_task_type"] or "general").strip()
        if assignee == "Lead Agent" and (wf["default_assignee"] or "").strip():
            assignee = (wf["default_assignee"] or "Lead Agent").strip()

    command = (request.form.get("command") or "").strip()
    if not command:
        command = build_command_from_template(workflow_template, project_dir, task_brief)

    with db_conn() as conn:
        cur = conn.execute(
            """
            INSERT INTO tasks(title, description, task_type, assignee, priority, status, command, workflow_code, created_at, updated_at)
            VALUES(?,?,?,?,?,'pending',?,?,?,?)
            """,
            (title, description, task_type, assignee, priority, command, workflow_template, now_str(), now_str()),
        )
        task_id = cur.lastrowid

    append_log(task_id, f"[SYSTEM] ä»»åŠ¡åˆ›å»ºï¼š{title}")
    append_log(task_id, f"[SYSTEM] å·¥ä½œæµæ¨¡æ¿ï¼š{workflow_template}")
    if task_brief:
        append_log(task_id, f"[SYSTEM] å£è¯­åŒ–ä»»åŠ¡æè¿°ï¼š{task_brief[:1200]}")
    if delivery_expectation:
        append_log(task_id, f"[SYSTEM] æœŸæœ›äº¤ä»˜ï¼š{delivery_expectation[:800]}")

    _, input_dir, _ = task_artifact_dirs(task_id)
    uploaded = 0
    for f in request.files.getlist("attachments"):
        if not f or not f.filename:
            continue
        safe_name = secure_filename(f.filename)
        if not safe_name:
            continue
        target = os.path.join(input_dir, safe_name)
        f.save(target)
        uploaded += 1
        append_log(task_id, f"[SYSTEM] å·²ä¸Šä¼ é™„ä»¶: {safe_name}")

    if uploaded > 0:
        flash(f"ä»»åŠ¡ #{task_id} åˆ›å»ºæˆåŠŸï¼Œå·²ä¸Šä¼  {uploaded} ä¸ªé™„ä»¶")
    else:
        flash(f"ä»»åŠ¡ #{task_id} åˆ›å»ºæˆåŠŸ")
    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/start")
@login_required
def start_task_route(task_id: int):
    ok, msg = start_task(task_id)
    flash(f"ä»»åŠ¡ #{task_id}: {msg}")
    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/retry")
@login_required
def retry_task(task_id: int):
    task = get_task(task_id)
    if not task:
        flash("ä»»åŠ¡ä¸å­˜åœ¨")
        return redirect(url_for("dashboard"))

    update_task(task_id, status="pending", finished_at=None, started_at=None, return_code=None)
    append_log(task_id, "[SYSTEM] ä»»åŠ¡é‡ç½®ä¸º pending")
    flash(f"ä»»åŠ¡ #{task_id} å·²é‡ç½®")
    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/stop")
@login_required
def stop_task(task_id: int):
    proc = running_processes.get(task_id)
    if proc is None and task_id in running_processes:
        running_processes.pop(task_id, None)
        update_task(task_id, status="failed", finished_at=now_str(), return_code=137)
        append_log(task_id, "[SYSTEM] ä»»åŠ¡åœ¨å¯åŠ¨é˜¶æ®µè¢«åœæ­¢")
        flash(f"ä»»åŠ¡ #{task_id} å·²åœæ­¢")
        return redirect(url_for("dashboard"))

    if not proc:
        flash("ä»»åŠ¡æœªè¿è¡Œ")
        return redirect(url_for("dashboard"))

    try:
        proc.terminate()
        update_task(task_id, status="failed", finished_at=now_str(), return_code=143)
        append_log(task_id, "[SYSTEM] æ‰‹åŠ¨åœæ­¢ä»»åŠ¡")
        flash(f"ä»»åŠ¡ #{task_id} å·²åœæ­¢")
    except Exception as e:
        flash(f"åœæ­¢å¤±è´¥: {e}")

    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/delete")
@login_required
def delete_task(task_id: int):
    task = get_task(task_id)
    if not task:
        flash("ä»»åŠ¡ä¸å­˜åœ¨")
        return redirect(url_for("dashboard"))

    if task_id in running_processes:
        flash(f"ä»»åŠ¡ #{task_id} æ­£åœ¨è¿è¡Œæˆ–æ’é˜Ÿä¸­ï¼Œè¯·å…ˆåœæ­¢åå†åˆ é™¤")
        return redirect(url_for("dashboard"))

    try:
        with db_conn() as conn:
            conn.execute("DELETE FROM task_logs WHERE task_id=?", (task_id,))
            conn.execute("DELETE FROM role_session_messages WHERE task_id=?", (task_id,))
            conn.execute("DELETE FROM tasks WHERE id=?", (task_id,))

        task_dir = os.path.join(ARTIFACT_ROOT, f"task_{task_id}")
        if os.path.isdir(task_dir):
            shutil.rmtree(task_dir, ignore_errors=True)

        flash(f"ä»»åŠ¡ #{task_id} å·²åˆ é™¤ï¼ˆå«æ—¥å¿—å’Œä»»åŠ¡é™„ä»¶/äº§ç‰©ï¼‰")
    except Exception as e:
        flash(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}")

    return redirect(url_for("dashboard"))


@app.post("/tasks/<int:task_id>/upload")
@login_required
def task_upload(task_id: int):
    task = get_task(task_id)
    if not task:
        flash("ä»»åŠ¡ä¸å­˜åœ¨")
        return redirect(url_for("dashboard"))

    _, input_dir, _ = task_artifact_dirs(task_id)
    uploaded = 0
    for f in request.files.getlist("attachments"):
        if not f or not f.filename:
            continue
        safe_name = secure_filename(f.filename)
        if not safe_name:
            continue
        target = os.path.join(input_dir, safe_name)
        f.save(target)
        uploaded += 1
        append_log(task_id, f"[SYSTEM] å·²è¿½åŠ ä¸Šä¼ é™„ä»¶: {safe_name}")

    if uploaded == 0:
        flash("æœªæ£€æµ‹åˆ°å¯ä¸Šä¼ æ–‡ä»¶")
    else:
        flash(f"ä»»åŠ¡ #{task_id} é™„ä»¶ä¸Šä¼ å®Œæˆï¼š{uploaded} ä¸ª")
    return redirect(url_for("task_detail", task_id=task_id))


@app.route("/tasks/<int:task_id>/download/<path:rel_path>")
@login_required
def task_artifact_download(task_id: int, rel_path: str):
    task = get_task(task_id)
    if not task:
        abort(404)
    base, _, _ = task_artifact_dirs(task_id)
    safe_full = safe_join_under(base, rel_path)
    if not safe_full:
        abort(400)
    if not os.path.isfile(safe_full):
        abort(404)
    return send_from_directory(base, rel_path, as_attachment=True)


@app.route("/tasks/<int:task_id>")
@login_required
def task_detail(task_id: int):
    task = get_task(task_id)
    if not task:
        return "Task not found", 404

    with db_conn() as conn:
        logs = conn.execute(
            "SELECT ts, line FROM task_logs WHERE task_id=? ORDER BY id ASC", (task_id,)
        ).fetchall()

    base, input_dir, output_dir = task_artifact_dirs(task_id)
    input_files = list_task_files(task_id, "input")
    output_files = list_task_files(task_id, "output")
    delivery = build_delivery_overview(task, output_files, logs)
    multiagent = load_multiagent_summary(output_dir)

    return render_template(
        "task_detail.html",
        task=task,
        logs=logs,
        delivery=delivery,
        multiagent=multiagent,
        base_dir=base,
        input_dir=input_dir,
        output_dir=output_dir,
        input_files=input_files,
        output_files=output_files,
    )


@app.route("/api/tasks")
@login_required
def api_tasks():
    with db_conn() as conn:
        rows = conn.execute("SELECT * FROM tasks ORDER BY id DESC LIMIT 200").fetchall()
    return jsonify([dict(r) for r in rows])


if __name__ == "__main__":
    init_db()
    sync_runtime_settings()
    app.run(host="127.0.0.1", port=3100, debug=False)
else:
    init_db()
    sync_runtime_settings()
